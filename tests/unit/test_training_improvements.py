#!/usr/bin/env python
"""
æµ‹è¯•è®­ç»ƒæ”¹è¿›æ•ˆæœ
"""

import sys
sys.path.append('.')
from config import get_default_config
from data import DataManager
from factors import FactorEngine
from rl_agent import TradingEnvironment, CVaRPPOAgent, SafetyShield
import numpy as np
import logging

# è®¾ç½®ç®€å•æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def test_improvements():
    """æµ‹è¯•æ”¹è¿›æ•ˆæœ"""
    print("ğŸ§ª æµ‹è¯•è®­ç»ƒç³»ç»Ÿæ”¹è¿›...")
    
    # è·å–é…ç½®
    config = get_default_config()
    
    # åˆå§‹åŒ–ç»„ä»¶
    data_manager = DataManager(config['data'])
    factor_engine = FactorEngine(config['factors'])
    
    # è·å–å°æ ·æœ¬æ•°æ®è¿›è¡Œå¿«é€Ÿæµ‹è¯•
    print("ğŸ“Š è·å–æµ‹è¯•æ•°æ®...")
    instruments = data_manager._get_universe_stocks('2019-01-01', '2023-12-31')[:20]  # åªç”¨20åªè‚¡ç¥¨
    stock_data = data_manager.get_stock_data(
        instruments=instruments,
        start_time='2023-01-01',
        end_time='2023-03-31'  # 3ä¸ªæœˆæ•°æ®
    )
    
    if stock_data.empty:
        print("âŒ æ— æ³•è·å–æµ‹è¯•æ•°æ®")
        return False
    
    # å¤„ç†æ•°æ® - è½¬ç½®ä½¿å¾—ç´¢å¼•æ˜¯æ—¥æœŸï¼Œåˆ—æ˜¯è‚¡ç¥¨ä»£ç 
    price_data = stock_data['$close'].unstack().T  # è½¬ç½®ï¼šæ—¥æœŸä½œä¸ºç´¢å¼•ï¼Œè‚¡ç¥¨ä½œä¸ºåˆ—
    volume_data = stock_data['$volume'].unstack().T
    
    print(f"ğŸ“ˆ ä»·æ ¼æ•°æ®å½¢çŠ¶: {price_data.shape}")
    
    # è®¡ç®—å› å­
    factor_data = factor_engine.calculate_all_factors(price_data, volume_data)
    print(f"ğŸ”¢ å› å­æ•°æ®å½¢çŠ¶: {factor_data.shape}")
    
    # åˆ›å»ºç¯å¢ƒ
    env_config = config['environment']
    environment = TradingEnvironment(factor_data, price_data, env_config)
    
    # åˆ›å»ºæ™ºèƒ½ä½“
    agent_config = config['agent']
    state_dim = environment.observation_space.shape[0]
    action_dim = environment.action_space.shape[0]
    agent = CVaRPPOAgent(state_dim, action_dim, agent_config)
    
    # åˆ›å»ºå®‰å…¨ä¿æŠ¤å±‚
    shield_config = config['safety_shield']
    safety_shield = SafetyShield(shield_config)
    
    print(f"ğŸ¤– æ™ºèƒ½ä½“é…ç½®: çŠ¶æ€ç»´åº¦={state_dim}, åŠ¨ä½œç»´åº¦={action_dim}")
    print(f"ğŸ“š å­¦ä¹ ç‡: {agent_config['learning_rate']}")
    print(f"ğŸ›¡ï¸ å®‰å…¨çº¦æŸ: æœ€å¤§æ æ†={shield_config['max_leverage']}")
    
    # è¿è¡Œå‡ ä¸ªepisodeæµ‹è¯•
    print("\nğŸƒ è¿è¡Œæµ‹è¯•episode...")
    test_rewards = []
    constraint_counts = {'leverage': 0, 'drawdown': 0}
    
    for episode in range(5):  # åªæµ‹è¯•5ä¸ªepisode
        state, info = environment.reset()
        episode_reward = 0
        step_count = 0
        
        while True:
            # è·å–åŠ¨ä½œ
            action, log_prob, value, cvar_estimate = agent.get_action(state)
            
            # åº”ç”¨å®‰å…¨ä¿æŠ¤
            safe_action = safety_shield.shield_action(
                action, info, price_data, environment.portfolio_weights
            )
            
            # ç»Ÿè®¡çº¦æŸè§¦å‘
            if np.sum(np.abs(safe_action)) < np.sum(np.abs(action)) * 0.9:
                constraint_counts['leverage'] += 1
            
            # æ‰§è¡ŒåŠ¨ä½œ
            next_state, reward, terminated, truncated, info = environment.step(safe_action)
            
            # å­˜å‚¨ç»éªŒ
            agent.store_transition(state, safe_action, reward, value, log_prob, terminated or truncated, cvar_estimate)
            
            state = next_state
            episode_reward += reward
            step_count += 1
            
            if terminated or truncated:
                break
        
        test_rewards.append(episode_reward)
        print(f"  Episode {episode+1}: å¥–åŠ±={episode_reward:.4f}, æ­¥æ•°={step_count}")
    
    # æµ‹è¯•æ›´æ–°
    print("\nğŸ”„ æµ‹è¯•æ™ºèƒ½ä½“æ›´æ–°...")
    try:
        update_stats = agent.update()
        print(f"âœ… æ›´æ–°æˆåŠŸ: æŸå¤±={update_stats.get('total_loss', 0):.6f}")
        print(f"ğŸ“Š å­¦ä¹ ç‡: {update_stats.get('learning_rate', 0):.2e}")
    except Exception as e:
        print(f"âŒ æ›´æ–°å¤±è´¥: {e}")
        return False
    
    # è¾“å‡ºæµ‹è¯•ç»“æœ
    print(f"\nğŸ“‹ æµ‹è¯•ç»“æœæ€»ç»“:")
    print(f"  å¹³å‡å¥–åŠ±: {np.mean(test_rewards):.4f}")
    print(f"  å¥–åŠ±æ ‡å‡†å·®: {np.std(test_rewards):.4f}")
    print(f"  çº¦æŸè§¦å‘: æ æ†={constraint_counts['leverage']}æ¬¡")
    
    # è·å–å®‰å…¨ä¿æŠ¤å±‚ç»Ÿè®¡
    total_constraints = sum(safety_shield.risk_event_counts.values())
    print(f"  æ€»çº¦æŸè§¦å‘: {total_constraints}æ¬¡")
    
    # åˆ¤æ–­æ”¹è¿›æ•ˆæœ
    avg_reward = np.mean(test_rewards)
    if avg_reward > -5:  # å¦‚æœå¹³å‡å¥–åŠ±å¤§äº-5ï¼Œè®¤ä¸ºæ”¹è¿›æœ‰æ•ˆ
        print("âœ… è®­ç»ƒæ”¹è¿›æ•ˆæœè‰¯å¥½ï¼")
        return True
    else:
        print("âš ï¸ è®­ç»ƒæ”¹è¿›æ•ˆæœæœ‰é™ï¼Œå¯èƒ½éœ€è¦è¿›ä¸€æ­¥è°ƒæ•´")
        return False

if __name__ == "__main__":
    success = test_improvements()
    if success:
        print("\nğŸ‰ ç³»ç»Ÿä¼˜åŒ–å®Œæˆï¼Œå¯ä»¥å¼€å§‹æ­£å¼è®­ç»ƒï¼")
        print("ğŸ’¡ å»ºè®®è¿è¡Œ: python main.py --mode train")
    else:
        print("\nğŸ”§ ç³»ç»Ÿä»éœ€è¿›ä¸€æ­¥ä¼˜åŒ–")