#!/usr/bin/env python3
"""
å…¨é‡æµ‹è¯•è¿è¡Œå™¨

ä¸€é”®è¿è¡Œtestsç›®å½•ä¸‹çš„æ‰€æœ‰æµ‹è¯•ï¼Œæä¾›è¯¦ç»†çš„æµ‹è¯•æŠ¥å‘Šå’Œç»Ÿè®¡ä¿¡æ¯ã€‚
æ”¯æŒä¸åŒçš„è¿è¡Œæ¨¡å¼å’Œè¾“å‡ºæ ¼å¼ã€‚
"""

import os
import sys
import subprocess
import time
from pathlib import Path
from typing import Dict, List, Tuple, Optional
import argparse

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))


class TestRunner:
    """æµ‹è¯•è¿è¡Œå™¨ç±»"""
    
    def __init__(self, verbose: bool = True, fast_fail: bool = False, timeout: int = 600):
        """åˆå§‹åŒ–æµ‹è¯•è¿è¡Œå™¨
        
        Args:
            verbose: æ˜¯å¦è¾“å‡ºè¯¦ç»†ä¿¡æ¯
            fast_fail: æ˜¯å¦åœ¨ç¬¬ä¸€ä¸ªå¤±è´¥æ—¶åœæ­¢
            timeout: æµ‹è¯•è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        """
        self.verbose = verbose
        self.fast_fail = fast_fail
        self.timeout = timeout
        self.tests_dir = Path(__file__).parent
        self.results = {}
        
    def discover_test_modules(self) -> Dict[str, List[str]]:
        """å‘ç°æ‰€æœ‰æµ‹è¯•æ¨¡å—"""
        test_categories = {
            'core_functionality': [
                'dynamic_lowvol_filter/test_exceptions.py',
                'dynamic_lowvol_filter/test_backtest.py', 
                'dynamic_lowvol_filter/test_integration.py'
            ],
            'unit_tests': [],
            'integration_tests': [],
            'performance_tests': [
                'dynamic_lowvol_filter/test_performance.py',
                'dynamic_lowvol_filter/test_stability.py'
            ]
        }
        
        # å‘ç°å•å…ƒæµ‹è¯•
        unit_dir = self.tests_dir / 'unit'
        if unit_dir.exists():
            for test_file in unit_dir.glob('test_*.py'):
                test_categories['unit_tests'].append(f'unit/{test_file.name}')
        
        # å‘ç°é›†æˆæµ‹è¯•
        integration_dir = self.tests_dir / 'integration'
        if integration_dir.exists():
            for test_file in integration_dir.glob('test_*.py'):
                test_categories['integration_tests'].append(f'integration/{test_file.name}')
        
        # è¿‡æ»¤å­˜åœ¨çš„æ–‡ä»¶
        for category in test_categories:
            test_categories[category] = [
                test for test in test_categories[category]
                if (self.tests_dir / test).exists()
            ]
        
        return test_categories
    
    def run_pytest_command(self, test_files: List[str], extra_args: List[str] = None) -> Tuple[int, str, str]:
        """è¿è¡Œpytestå‘½ä»¤"""
        if extra_args is None:
            extra_args = []
            
        # æ„å»ºpytestå‘½ä»¤
        cmd = ['python', '-m', 'pytest'] + extra_args
        
        # æ·»åŠ æµ‹è¯•æ–‡ä»¶
        for test_file in test_files:
            cmd.append(str(self.tests_dir / test_file))
        
        if self.verbose:
            print(f"è¿è¡Œå‘½ä»¤: {' '.join(cmd)}")
        
        # è¿è¡Œå‘½ä»¤
        start_time = time.time()
        process = subprocess.Popen(
            cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
            cwd=str(project_root)
        )
        
        stdout, stderr = process.communicate(timeout=self.timeout)
        end_time = time.time()
        
        return process.returncode, stdout, stderr, end_time - start_time
    
    def run_test_category(self, category: str, test_files: List[str]) -> Dict:
        """è¿è¡Œç‰¹å®šç±»åˆ«çš„æµ‹è¯•"""
        if not test_files:
            return {
                'category': category,
                'status': 'skipped',
                'reason': 'No test files found',
                'duration': 0,
                'tests_run': 0,
                'failures': 0,
                'errors': 0
            }
        
        print(f"\n{'='*60}")
        print(f"è¿è¡Œ {category.upper()} æµ‹è¯•")
        print(f"{'='*60}")
        print(f"æµ‹è¯•æ–‡ä»¶: {', '.join(test_files)}")
        
        # è®¾ç½®pytestå‚æ•°
        pytest_args = ['--tb=short', '-v']
        if self.fast_fail:
            pytest_args.append('-x')
        
        # æ ¹æ®æµ‹è¯•ç±»åˆ«è°ƒæ•´å‚æ•°
        if category == 'performance_tests':
            pytest_args.extend(['--timeout=300'])  # æ€§èƒ½æµ‹è¯•ç”¨è¾ƒçŸ­è¶…æ—¶
        elif category == 'unit_tests':
            pytest_args.append('-q')  # å•å…ƒæµ‹è¯•ç”¨ç®€æ´è¾“å‡º
        
        returncode, stdout, stderr, duration = self.run_pytest_command(test_files, pytest_args)
        
        # è§£æç»“æœ
        result = self.parse_pytest_output(stdout, stderr, returncode, duration)
        result['category'] = category
        result['test_files'] = test_files
        
        # è¾“å‡ºç»“æœæ‘˜è¦
        status_symbol = "âœ…" if result['status'] == 'passed' else "âŒ" if result['status'] == 'failed' else "âš ï¸"
        print(f"\n{status_symbol} {category}: {result['tests_run']} ä¸ªæµ‹è¯•è¿è¡Œï¼Œ{result['failures']} ä¸ªå¤±è´¥ï¼Œ{result['errors']} ä¸ªé”™è¯¯")
        print(f"   è€—æ—¶: {duration:.2f}ç§’")
        
        if result['status'] == 'failed' and stderr:
            print(f"   é”™è¯¯ä¿¡æ¯: {stderr[:200]}...")
        
        return result
    
    def parse_pytest_output(self, stdout: str, stderr: str, returncode: int, duration: float) -> Dict:
        """è§£æpytestè¾“å‡º"""
        result = {
            'status': 'unknown',
            'duration': duration,
            'tests_run': 0,
            'failures': 0,
            'errors': 0,
            'skipped': 0,
            'stdout': stdout,
            'stderr': stderr,
            'returncode': returncode
        }
        
        if returncode == 0:
            result['status'] = 'passed'
        elif returncode == 1:
            result['status'] = 'failed'
        elif returncode == 2:
            result['status'] = 'error'
        else:
            result['status'] = 'timeout' if 'timeout' in stderr.lower() else 'unknown'
        
        # æ›´å¥½çš„è¾“å‡ºè§£æ - å¯»æ‰¾æœ€åçš„ç»Ÿè®¡è¡Œ
        lines = stdout.split('\n')
        for line in reversed(lines):
            line = line.strip()
            if not line:
                continue
                
            # å¯»æ‰¾ç»Ÿè®¡è¡Œï¼Œå¦‚ "12 passed, 2 warnings in 108.82s"
            if ('passed' in line or 'failed' in line or 'error' in line) and ('in' in line and 's' in line):
                import re
                # æå–æ•°å­—å’ŒçŠ¶æ€
                patterns = [
                    (r'(\d+)\s+passed', 'passed'),
                    (r'(\d+)\s+failed', 'failed'), 
                    (r'(\d+)\s+error', 'errors'),
                    (r'(\d+)\s+skipped', 'skipped')
                ]
                
                for pattern, status_type in patterns:
                    matches = re.findall(pattern, line)
                    if matches:
                        count = int(matches[0])
                        if status_type == 'passed':
                            result['tests_run'] += count
                        elif status_type == 'failed':
                            result['failures'] = count
                            result['tests_run'] += count
                        elif status_type == 'errors':
                            result['errors'] = count
                            result['tests_run'] += count
                        elif status_type == 'skipped':
                            result['skipped'] = count
                            result['tests_run'] += count
                break
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç»Ÿè®¡ä¿¡æ¯ï¼Œå°è¯•ä»è¾“å‡ºä¸­è®¡ç®—
        if result['tests_run'] == 0:
            # è®¡ç®—PASSEDå’ŒFAILEDæ ‡è®°çš„æ•°é‡
            passed_count = stdout.count('PASSED')
            failed_count = stdout.count('FAILED')
            error_count = stdout.count('ERROR')
            skipped_count = stdout.count('SKIPPED')
            
            result['tests_run'] = passed_count + failed_count + error_count + skipped_count
            result['failures'] = failed_count
            result['errors'] = error_count
            result['skipped'] = skipped_count
        
        return result
    
    def run_all_tests(self, categories: Optional[List[str]] = None) -> Dict:
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        print("ğŸ§ª å¼€å§‹å…¨é‡æµ‹è¯•è¿è¡Œ")
        print(f"é¡¹ç›®æ ¹ç›®å½•: {project_root}")
        print(f"æµ‹è¯•ç›®å½•: {self.tests_dir}")
        
        # å‘ç°æµ‹è¯•æ¨¡å—
        test_modules = self.discover_test_modules()
        
        if categories:
            # åªè¿è¡ŒæŒ‡å®šç±»åˆ«
            test_modules = {k: v for k, v in test_modules.items() if k in categories}
        
        print(f"\nå‘ç°çš„æµ‹è¯•ç±»åˆ«: {list(test_modules.keys())}")
        
        # è¿è¡Œæµ‹è¯•
        all_results = {}
        total_start_time = time.time()
        
        for category, test_files in test_modules.items():
            result = self.run_test_category(category, test_files)
            all_results[category] = result
            
            # å¦‚æœå¯ç”¨å¿«é€Ÿå¤±è´¥ä¸”æœ‰å¤±è´¥
            if self.fast_fail and result['status'] == 'failed':
                print(f"\nâš ï¸ å¿«é€Ÿå¤±è´¥æ¨¡å¼: åœ¨ {category} ä¸­æ£€æµ‹åˆ°å¤±è´¥ï¼Œåœæ­¢åç»­æµ‹è¯•")
                break
        
        total_duration = time.time() - total_start_time
        
        # ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
        summary = self.generate_summary_report(all_results, total_duration)
        
        return {
            'summary': summary,
            'results': all_results,
            'total_duration': total_duration
        }
    
    def generate_summary_report(self, results: Dict, total_duration: float) -> Dict:
        """ç”Ÿæˆæ€»ç»“æŠ¥å‘Š"""
        summary = {
            'total_categories': len(results),
            'passed_categories': 0,
            'failed_categories': 0,
            'total_tests': 0,
            'total_failures': 0,
            'total_errors': 0,
            'total_skipped': 0,
            'overall_status': 'passed',
            'total_duration': total_duration
        }
        
        for category, result in results.items():
            if result['status'] == 'passed':
                summary['passed_categories'] += 1
            elif result['status'] in ['failed', 'error']:
                summary['failed_categories'] += 1
                summary['overall_status'] = 'failed'
            
            summary['total_tests'] += result['tests_run']
            summary['total_failures'] += result['failures']
            summary['total_errors'] += result['errors']
            summary['total_skipped'] += result['skipped']
        
        return summary
    
    def print_final_report(self, test_results: Dict):
        """æ‰“å°æœ€ç»ˆæŠ¥å‘Š"""
        summary = test_results['summary']
        
        print(f"\n{'='*80}")
        print("ğŸ“Š æµ‹è¯•æ‰§è¡Œæ€»ç»“æŠ¥å‘Š")
        print(f"{'='*80}")
        
        # æ€»ä½“çŠ¶æ€
        status_symbol = "âœ…" if summary['overall_status'] == 'passed' else "âŒ"
        print(f"{status_symbol} æ€»ä½“çŠ¶æ€: {summary['overall_status'].upper()}")
        print(f"â±ï¸  æ€»è€—æ—¶: {summary['total_duration']:.2f}ç§’")
        print()
        
        # åˆ†ç±»ç»Ÿè®¡
        print("ğŸ“‹ åˆ†ç±»ç»Ÿè®¡:")
        print(f"   æµ‹è¯•ç±»åˆ«: {summary['total_categories']} ä¸ª")
        print(f"   é€šè¿‡ç±»åˆ«: {summary['passed_categories']} ä¸ª")
        print(f"   å¤±è´¥ç±»åˆ«: {summary['failed_categories']} ä¸ª")
        print()
        
        # æµ‹è¯•ç»Ÿè®¡
        print("ğŸ§® æµ‹è¯•ç»Ÿè®¡:")
        print(f"   æ€»æµ‹è¯•æ•°: {summary['total_tests']} ä¸ª")
        print(f"   å¤±è´¥æ•°: {summary['total_failures']} ä¸ª")
        print(f"   é”™è¯¯æ•°: {summary['total_errors']} ä¸ª")
        print(f"   è·³è¿‡æ•°: {summary['total_skipped']} ä¸ª")
        print()
        
        # è¯¦ç»†ç»“æœ
        print("ğŸ“ è¯¦ç»†ç»“æœ:")
        for category, result in test_results['results'].items():
            status_symbol = "âœ…" if result['status'] == 'passed' else "âŒ" if result['status'] == 'failed' else "âš ï¸"
            print(f"   {status_symbol} {category:<20} | {result['tests_run']:>3} æµ‹è¯• | {result['failures']:>2} å¤±è´¥ | {result['duration']:>6.2f}s")
        
        # å¤±è´¥è¯¦æƒ…
        failed_categories = [cat for cat, result in test_results['results'].items() if result['status'] in ['failed', 'error']]
        if failed_categories:
            print(f"\nâŒ å¤±è´¥çš„æµ‹è¯•ç±»åˆ«:")
            for category in failed_categories:
                result = test_results['results'][category]
                print(f"   â€¢ {category}: {result['failures']} ä¸ªå¤±è´¥, {result['errors']} ä¸ªé”™è¯¯")
                if result['stderr']:
                    print(f"     é”™è¯¯ä¿¡æ¯: {result['stderr'][:150]}...")
        
        print(f"\n{'='*80}")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="è¿è¡Œå…¨é‡æµ‹è¯•")
    parser.add_argument('--categories', nargs='+', 
                       choices=['core_functionality', 'unit_tests', 'integration_tests', 'performance_tests'],
                       help='æŒ‡å®šè¦è¿è¡Œçš„æµ‹è¯•ç±»åˆ«')
    parser.add_argument('--fast-fail', action='store_true', help='åœ¨ç¬¬ä¸€ä¸ªå¤±è´¥æ—¶åœæ­¢')
    parser.add_argument('--quiet', action='store_true', help='ç®€æ´è¾“å‡º')
    parser.add_argument('--timeout', type=int, default=600, help='æµ‹è¯•è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰')
    
    args = parser.parse_args()
    
    # åˆ›å»ºæµ‹è¯•è¿è¡Œå™¨
    runner = TestRunner(
        verbose=not args.quiet,
        fast_fail=args.fast_fail,
        timeout=args.timeout
    )
    
    # è¿è¡Œæµ‹è¯•
    results = runner.run_all_tests(categories=args.categories)
    
    # æ‰“å°æŠ¥å‘Š
    runner.print_final_report(results)
    
    # è¿”å›é€‚å½“çš„é€€å‡ºç 
    exit_code = 0 if results['summary']['overall_status'] == 'passed' else 1
    sys.exit(exit_code)


if __name__ == '__main__':
    main()