#!/usr/bin/env python3
"""
è®­ç»ƒè„šæœ¬

ç”¨äºè®­ç»ƒå¼ºåŒ–å­¦ä¹ äº¤æ˜“æ™ºèƒ½ä½“
"""

import argparse
import logging
import os
import sys
from pathlib import Path
from datetime import datetime
import torch
import numpy as np

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root / "src"))

from rl_trading_system.config import ConfigManager
from rl_trading_system.training import RLTrainer, TrainingConfig, create_split_strategy, SplitConfig
from rl_trading_system.data import QlibDataInterface, FeatureEngineer, DataProcessor
from rl_trading_system.models import TimeSeriesTransformer, SACAgent, TransformerConfig, SACConfig
from rl_trading_system.trading import PortfolioEnvironment, PortfolioConfig
from rl_trading_system.backtest.drawdown_control_config import DrawdownControlConfig
from rl_trading_system.utils.terminal_colors import (
    ColorFormatter, print_banner, print_section, print_model_recommendation,
    print_training_stats, print_evaluation_results
)


def setup_logging(output_dir: str, log_level: str = "INFO"):
    """è®¾ç½®æ—¥å¿—ç³»ç»Ÿ"""
    log_dir = Path(output_dir) / "logs"
    log_dir.mkdir(parents=True, exist_ok=True)

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    log_file = log_dir / f"training_{timestamp}.log"

    logging.basicConfig(
        level=getattr(logging, log_level.upper()),
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_file),
            logging.StreamHandler(sys.stdout)
        ]
    )

    return logging.getLogger(__name__)


def create_training_components(model_config: dict, trading_config: dict, output_dir: str):
    """åˆ›å»ºè®­ç»ƒæ‰€éœ€çš„ç»„ä»¶"""
    logger = logging.getLogger(__name__)
    logger.info("åˆå§‹åŒ–è®­ç»ƒç»„ä»¶...")

    # åˆ›å»ºæ•°æ®ç»„ä»¶
    data_interface = QlibDataInterface()
    feature_engineer = FeatureEngineer()
    data_processor = DataProcessor()

    # åŠ è½½å’Œå¤„ç†æ•°æ®
    logger.info("åŠ è½½è‚¡ç¥¨æ•°æ®...")
    # ä»nestedé…ç½®ä¸­æå–å‚æ•°
    trading_env = trading_config.get("trading", {}).get("environment", {})
    backtest_config = trading_config.get("backtest", {})
    
    stock_pool = trading_env.get("stock_pool")
    if not stock_pool:  # å¦‚æœstock_poolä¸ºç©ºåˆ—è¡¨ï¼Œä½¿ç”¨é»˜è®¤å€¼
        raise RuntimeError(f"empty tock_pool: {stock_pool}")
    
    start_date = backtest_config.get("start_date", "2020-01-01")
    end_date = backtest_config.get("end_date", "2023-12-31")

    # å°è¯•è·å–æ•°æ®ï¼Œå¦‚æœå¤±è´¥åˆ™ä½¿ç”¨å¯ç”¨æ•°æ®èŒƒå›´
    try:
        market_data = data_interface.get_price_data(
            symbols=stock_pool,
            start_date=start_date,
            end_date=end_date
        )
    except RuntimeError as e:
        logger.warning(f"æ— æ³•è·å–æŒ‡å®šæ—¶é—´èŒƒå›´çš„æ•°æ®: {e}")
        logger.info("å°è¯•è·å–å¯ç”¨çš„æ•°æ®èŒƒå›´...")
        
        try:
            available_start, available_end = data_interface.get_available_date_range(stock_pool)
            logger.info(f"æ‰¾åˆ°å¯ç”¨æ•°æ®èŒƒå›´: {available_start} åˆ° {available_end}")
            
            # ä½¿ç”¨å¯ç”¨çš„æ•°æ®èŒƒå›´é‡æ–°åŠ è½½æ•°æ®
            market_data = data_interface.get_price_data(
                symbols=stock_pool,
                start_date=available_start,
                end_date=available_end
            )
            
            # æ›´æ–°æ—¥æœŸèŒƒå›´
            start_date = available_start
            end_date = available_end
            logger.info(f"å·²è°ƒæ•´ä¸ºå¯ç”¨æ•°æ®èŒƒå›´: {start_date} åˆ° {end_date}")
            
        except Exception as fallback_error:
            raise RuntimeError(f"æ— æ³•è·å–ä»»ä½•å¯ç”¨çš„è‚¡ç¥¨æ•°æ®: åŸå§‹é”™è¯¯={e}, fallbacké”™è¯¯={fallback_error}") from e

    # ç‰¹å¾å·¥ç¨‹
    logger.info("æ‰§è¡Œç‰¹å¾å·¥ç¨‹...")
    if market_data.empty:
        raise ValueError(f"æ— æ³•è·å–è‚¡ç¥¨æ•°æ®: symbols={stock_pool}, "
                        f"start_date={start_date}, end_date={end_date}")
        
    # è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
    technical_features = feature_engineer.calculate_technical_indicators(market_data)
    
    # è®¡ç®—å…¶ä»–ç‰¹å¾
    microstructure_features = feature_engineer.calculate_microstructure_features(market_data)
    volatility_features = feature_engineer.calculate_volatility_features(market_data)
    momentum_features = feature_engineer.calculate_momentum_features(market_data)
    
    # åˆå¹¶æ‰€æœ‰ç‰¹å¾
    processed_data = feature_engineer.combine_features([
        market_data,
        technical_features,
        microstructure_features,
        volatility_features,
        momentum_features
    ])
    
    # æ ‡å‡†åŒ–ç‰¹å¾
    normalized_data = feature_engineer.normalize_features(processed_data)

    # æ•°æ®åˆ†å‰²
    logger.debug("åˆ†å‰²è®­ç»ƒ/éªŒè¯æ•°æ®...")
    split_config = SplitConfig(
        train_ratio=0.7,
        validation_ratio=0.2,
        test_ratio=0.1
    )
    split_strategy = create_split_strategy("time_series", split_config)
    data_split = split_strategy.split(normalized_data)

    # åˆ›å»ºTransformeré…ç½®
    transformer_config = TransformerConfig(
        d_model=model_config["model"]["transformer"]["d_model"],
        n_heads=model_config["model"]["transformer"]["n_heads"],
        n_layers=model_config["model"]["transformer"]["n_layers"],
        d_ff=model_config["model"]["transformer"]["d_ff"],
        dropout=model_config["model"]["transformer"]["dropout"],
        max_seq_len=model_config["model"]["transformer"]["max_seq_len"],
        n_features=model_config["model"]["transformer"]["n_features"]
    )

    # åˆ›å»ºSACé…ç½®ï¼Œé›†æˆTransformer
    sac_config = SACConfig(
        learning_rate=model_config["model"]["sac"]["lr_actor"],  # ä½¿ç”¨ actor å­¦ä¹ ç‡ä½œä¸ºé€šç”¨å­¦ä¹ ç‡
        gamma=model_config["model"]["sac"]["gamma"],
        tau=model_config["model"]["sac"]["tau"],
        ent_coef='auto',  # è‡ªåŠ¨è°ƒæ•´ç†µç³»æ•°
        target_entropy='auto',  # è‡ªåŠ¨è®¾ç½®ç›®æ ‡ç†µ
        batch_size=model_config["model"]["sac"]["batch_size"],
        buffer_size=model_config["model"]["sac"]["buffer_size"],
        learning_starts=100,  # å¼€å§‹å­¦ä¹ çš„æœ€å°æ­¥æ•°ï¼ˆé™ä½ä»¥ä¾¿æ›´å¿«å¼€å§‹å­¦ä¹ ï¼‰
        net_arch=[model_config["model"]["sac"]["hidden_dim"]] * 2,  # ä½¿ç”¨ä¸¤å±‚éšè—å±‚
        use_transformer=True,  # å¯ç”¨Transformeré›†æˆ
        transformer_config=transformer_config,  # ä¼ å…¥Transformeré…ç½®
        total_timesteps=model_config["training"]["n_episodes"] * 252,  # ä¼°ç®—æ€»æ—¶é—´æ­¥æ•°ï¼ˆn_episodes * å¹³å‡äº¤æ˜“æ—¥ï¼‰
        device='cuda' if torch.cuda.is_available() else 'cpu'
    )

    # å…ˆåˆ›å»ºäº¤æ˜“ç¯å¢ƒ
    logger.debug("åˆ›å»ºäº¤æ˜“ç¯å¢ƒ...")
    
    # æ£€æŸ¥æ˜¯å¦å¯ç”¨å›æ’¤æ§åˆ¶
    enable_drawdown_control = trading_config.get("drawdown_control", {}).get("enable", False)
    drawdown_control_config = None
    
    if enable_drawdown_control:
        logger.info("å¯ç”¨å›æ’¤æ§åˆ¶åŠŸèƒ½")
        # ä»é…ç½®ä¸­åˆ›å»ºå›æ’¤æ§åˆ¶é…ç½®
        drawdown_config_dict = trading_config.get("drawdown_control", {})
        drawdown_control_config = DrawdownControlConfig(
            max_drawdown_threshold=drawdown_config_dict.get("max_drawdown_threshold", 0.15),
            drawdown_warning_threshold=drawdown_config_dict.get("drawdown_warning_threshold", 0.08),
            enable_market_regime_detection=drawdown_config_dict.get("enable_market_regime_detection", True),
            drawdown_penalty_factor=drawdown_config_dict.get("drawdown_penalty_factor", 2.0),
            risk_aversion_coefficient=drawdown_config_dict.get("risk_aversion_coefficient", 0.5)
        )
    
    portfolio_config = PortfolioConfig(
        stock_pool=stock_pool,
        initial_cash=trading_env.get("initial_cash", 1000000.0),
        commission_rate=trading_env.get("commission_rate", 0.001),
        stamp_tax_rate=trading_env.get("stamp_tax_rate", 0.001),
        max_position_size=trading_env.get("max_position_size", 0.1),
        enable_drawdown_control=enable_drawdown_control,
        drawdown_control_config=drawdown_control_config
    )

    # Extract training data using indices
    train_data = normalized_data.iloc[data_split.train_indices]
    
    portfolio_env = PortfolioEnvironment(
        config=portfolio_config,
        data_interface=data_interface,
        feature_engineer=feature_engineer,
        start_date=start_date,
        end_date=end_date
    )

    # åˆ›å»ºSACæ™ºèƒ½ä½“ï¼ˆç°åœ¨ç¯å¢ƒå·²ç»åˆ›å»ºäº†ï¼‰
    logger.debug("åˆå§‹åŒ–SACæ™ºèƒ½ä½“ï¼ˆé›†æˆTransformerï¼‰...")
    sac_agent = SACAgent(sac_config, env=portfolio_env)
    sac_agent.set_env(portfolio_env)

    # åˆ›å»ºè®­ç»ƒé…ç½®
    training_config = TrainingConfig(
        n_episodes=model_config["training"]["n_episodes"],
        save_frequency=model_config["training"].get("eval_freq", 100),
        validation_frequency=model_config["training"].get("eval_freq", 100),
        early_stopping_patience=model_config["training"].get("patience", 50),
        early_stopping_min_delta=model_config["training"].get("min_delta", 0.001),
        save_dir=output_dir,
        
        # å¢å¼ºæŒ‡æ ‡é…ç½®
        enable_portfolio_metrics=trading_config.get("enhanced_metrics", {}).get("enable_portfolio_metrics", True),
        enable_agent_behavior_metrics=trading_config.get("enhanced_metrics", {}).get("enable_agent_behavior_metrics", True),
        enable_risk_control_metrics=trading_config.get("enhanced_metrics", {}).get("enable_risk_control_metrics", True),
        metrics_calculation_frequency=trading_config.get("enhanced_metrics", {}).get("metrics_calculation_frequency", 20),
        detailed_metrics_logging=trading_config.get("enhanced_metrics", {}).get("detailed_metrics_logging", True),
        risk_free_rate=trading_config.get("enhanced_metrics", {}).get("risk_free_rate", 0.03),
        
        # å›æ’¤æ§åˆ¶è®­ç»ƒå‚æ•°
        enable_drawdown_monitoring=enable_drawdown_control,
        drawdown_early_stopping=enable_drawdown_control,
        max_training_drawdown=trading_config.get("drawdown_control", {}).get("max_training_drawdown", 0.3),
        enable_adaptive_learning=trading_config.get("drawdown_control", {}).get("enable_adaptive_learning", False),
        
        # è‡ªé€‚åº”å­¦ä¹ ç‡å‚æ•°
        lr_adaptation_factor=trading_config.get("drawdown_control", {}).get("lr_adaptation_factor", 0.9),
        min_lr_factor=trading_config.get("drawdown_control", {}).get("min_lr_factor", 0.01),
        max_lr_factor=trading_config.get("drawdown_control", {}).get("max_lr_factor", 1.0),
        lr_recovery_factor=trading_config.get("drawdown_control", {}).get("lr_recovery_factor", 1.25),
        performance_threshold_down=trading_config.get("drawdown_control", {}).get("performance_threshold_down", 0.85),
        performance_threshold_up=trading_config.get("drawdown_control", {}).get("performance_threshold_up", 1.15),
        
        # å¤šæ ¸ä¼˜åŒ–å‚æ•°
        enable_multiprocessing=trading_config.get("model", {}).get("training", {}).get("enable_multiprocessing", True),
        num_workers=trading_config.get("model", {}).get("training", {}).get("num_workers", 4),
        parallel_environments=trading_config.get("model", {}).get("training", {}).get("parallel_environments", 2),
        data_loader_workers=trading_config.get("model", {}).get("training", {}).get("data_loader_workers", 2),
        pin_memory=trading_config.get("model", {}).get("training", {}).get("pin_memory", True),
        persistent_workers=trading_config.get("model", {}).get("training", {}).get("persistent_workers", True),
        prefetch_factor=trading_config.get("model", {}).get("training", {}).get("prefetch_factor", 2),
        
        # GPUä¼˜åŒ–å‚æ•°
        enable_mixed_precision=trading_config.get("model", {}).get("training", {}).get("enable_mixed_precision", True),
        enable_cudnn_benchmark=trading_config.get("model", {}).get("training", {}).get("enable_cudnn_benchmark", True),
        non_blocking_transfer=trading_config.get("model", {}).get("training", {}).get("non_blocking_transfer", True)
    )

    return portfolio_env, sac_agent, data_split, training_config


def main():
    parser = argparse.ArgumentParser(description="è®­ç»ƒå¼ºåŒ–å­¦ä¹ äº¤æ˜“æ™ºèƒ½ä½“")
    parser.add_argument("--config", type=str, default="config/model_config.yaml",
                       help="é…ç½®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--data-config", type=str, default="config/trading_config.yaml",
                       help="äº¤æ˜“é…ç½®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--episodes", type=int, default=None,
                       help="è®­ç»ƒè½®æ•°")
    parser.add_argument("--output-dir", type=str, default="./outputs",
                       help="è¾“å‡ºç›®å½•")
    parser.add_argument("--resume", type=str, default=None,
                       help="ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ")
    parser.add_argument("--log-level", type=str, default="INFO",
                       choices=["DEBUG", "INFO", "WARNING", "ERROR"],
                       help="æ—¥å¿—çº§åˆ«")
    parser.add_argument("--device", type=str, default="auto",
                       choices=["auto", "cpu", "cuda"],
                       help="è®­ç»ƒè®¾å¤‡")
    parser.add_argument("--no-color", action="store_true",
                       help="ç¦ç”¨å½©è‰²è¾“å‡º")

    args = parser.parse_args()
    
    # åˆå§‹åŒ–å½©è‰²æ ¼å¼åŒ–å™¨
    formatter = ColorFormatter(enable_color=not args.no_color)

    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path(args.output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    # è®¾ç½®æ—¥å¿—
    logger_instance = setup_logging(str(output_dir), args.log_level)

    # è®¾ç½®è®¾å¤‡
    if args.device == "auto":
        device = "cuda" if torch.cuda.is_available() else "cpu"
    else:
        device = args.device

    # æ‰“å°æ ‡é¢˜æ¨ªå¹…
    print_banner(
        "ğŸš€ å¼ºåŒ–å­¦ä¹ äº¤æ˜“æ™ºèƒ½ä½“è®­ç»ƒ",
        f"SAC + Transformer | è®¾å¤‡: {device}",
        formatter
    )

    try:
        # åŠ è½½é…ç½®
        print_section("ğŸ“ åŠ è½½é…ç½®æ–‡ä»¶", formatter)
        config_manager = ConfigManager()

        # æ£€æŸ¥é…ç½®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        model_config_path = Path(args.config)
        if not model_config_path.exists():
            print(formatter.error(f"âŒ æ¨¡å‹é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {args.config}"))
            raise FileNotFoundError(f"æ¨¡å‹é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {args.config}")

        data_config_path = Path(args.data_config)
        if not data_config_path.exists():
            print(formatter.error(f"âŒ æ•°æ®é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {args.data_config}"))
            raise FileNotFoundError(f"æ•°æ®é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {args.data_config}")

        model_config = config_manager.load_config(str(model_config_path))
        trading_config = config_manager.load_config(str(data_config_path))

        # è°ƒè¯•ï¼šæ‰“å°é…ç½®å†…å®¹
        logger_instance.debug(f"æ¨¡å‹é…ç½®å†…å®¹: {model_config}")
        logger_instance.debug(f"äº¤æ˜“é…ç½®å†…å®¹: {trading_config}")

        # è¦†ç›–é…ç½®å‚æ•°
        if args.episodes:
            if "training" not in model_config:
                model_config["training"] = {}
            model_config["training"]["n_episodes"] = args.episodes

        print(f"  {formatter.success('âœ… æ¨¡å‹é…ç½®æ–‡ä»¶')}: {formatter.path(args.config)}")
        print(f"  {formatter.success('âœ… äº¤æ˜“é…ç½®æ–‡ä»¶')}: {formatter.path(args.data_config)}")
        
        # å®‰å…¨åœ°è·å–è®­ç»ƒè½®æ•°
        n_episodes = model_config.get("model", {}).get("training", {}).get("n_episodes", 100)
        print(f"  {formatter.info('è®­ç»ƒè½®æ•°')}: {formatter.number(str(n_episodes))}")
        print(f"  {formatter.info('è¾“å‡ºç›®å½•')}: {formatter.path(args.output_dir)}")
        print(f"  {formatter.info('è®­ç»ƒè®¾å¤‡')}: {formatter.highlight(device)}")
        print()

        # åˆ›å»ºè®­ç»ƒç»„ä»¶
        environment, agent, data_split, training_config = create_training_components(
            model_config, trading_config, str(output_dir)
        )

        # è®¾ç½®è®¾å¤‡
        training_config.device = device

        # åˆ›å»ºè®­ç»ƒå™¨
        logger_instance.info("åˆå§‹åŒ–è®­ç»ƒå™¨...")
        trainer = RLTrainer(training_config, environment, agent, data_split)

        # ä»æ£€æŸ¥ç‚¹æ¢å¤ï¼ˆå¦‚æœæŒ‡å®šï¼‰
        start_episode = 0
        if args.resume:
            if Path(args.resume).exists():
                logger_instance.info(f"ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ: {args.resume}")
                start_episode = trainer.load_checkpoint(args.resume)
            else:
                logger_instance.warning(f"æ£€æŸ¥ç‚¹æ–‡ä»¶ä¸å­˜åœ¨: {args.resume}")

        # å¼€å§‹è®­ç»ƒ
        print_section("ğŸ¯ å¼€å§‹è®­ç»ƒ", formatter)
        print(f"  {formatter.info('æ­£åœ¨è®­ç»ƒå¼ºåŒ–å­¦ä¹ äº¤æ˜“æ™ºèƒ½ä½“...')}")
        print()
        
        training_stats = trainer.train()

        # è¾“å‡ºè®­ç»ƒç»Ÿè®¡
        print_training_stats(training_stats, formatter)

        # è¿è¡Œæœ€ç»ˆè¯„ä¼°
        print_section("ğŸ“Š æœ€ç»ˆè¯„ä¼°", formatter)
        print(f"  {formatter.info('æ­£åœ¨è¿è¡Œæ¨¡å‹è¯„ä¼°...')}")
        evaluation_stats = trainer.evaluate(n_episodes=20)

        # è¾“å‡ºè¯„ä¼°ç»“æœ
        print_evaluation_results(evaluation_stats, formatter)

        # æ˜¾ç¤ºæ¨¡å‹ä¿å­˜ä¿¡æ¯å’Œä½¿ç”¨å»ºè®®
        model_paths = {
            'final_model': str(output_dir / "final_model_agent.pth"),
        }
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æœ€ä½³æ¨¡å‹
        best_model_path = output_dir / "best_model_agent.pth"
        if best_model_path.exists():
            model_paths['best_model'] = str(best_model_path)
        
        print_model_recommendation(model_paths, formatter)
        
        print(formatter.success(f"ğŸ‰ è®­ç»ƒå®Œæˆï¼æ‰€æœ‰ç»“æœå·²ä¿å­˜åˆ°: {formatter.path(str(output_dir))}"))

    except Exception as e:
        logger_instance.error(f"è®­ç»ƒè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        logger_instance.exception("è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
        sys.exit(1)


if __name__ == "__main__":
    main()