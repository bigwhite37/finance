#!/usr/bin/env python3
"""
Transformeré…ç½®ç”Ÿæˆå™¨

æ ¹æ®ä¸åŒåœºæ™¯ç”Ÿæˆæ¨èçš„Transformeré…ç½®
"""

import argparse
import sys
import json
import yaml
from pathlib import Path
from typing import Dict, Any

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root / "src"))

from rl_trading_system.models.transformer import TransformerConfig
from rl_trading_system.models.sac_agent import SACConfig


def get_preset_configs() -> Dict[str, Dict[str, Any]]:
    """è·å–é¢„è®¾é…ç½®"""
    return {
        "lightweight": {
            "name": "è½»é‡é…ç½®",
            "description": "é€‚ç”¨äºèµ„æºå—é™ç¯å¢ƒï¼Œå¿«é€Ÿè®­ç»ƒå’Œæ¨ç†",
            "transformer": {
                "d_model": 128,
                "n_heads": 4,
                "n_layers": 3,
                "d_ff": 512,
                "dropout": 0.1,
                "max_seq_len": 252,
                "n_features": 37,
                "activation": "gelu"
            },
            "sac": {
                "state_dim": 128,
                "action_dim": 3,
                "hidden_dim": 256,
                "use_transformer": True
            }
        },
        "standard": {
            "name": "æ ‡å‡†é…ç½®",
            "description": "å¹³è¡¡æ€§èƒ½ä¸èµ„æºæ¶ˆè€—ï¼Œæ¨èç”¨äºå¤§éƒ¨åˆ†åœºæ™¯",
            "transformer": {
                "d_model": 256,
                "n_heads": 8,
                "n_layers": 6,
                "d_ff": 1024,
                "dropout": 0.1,
                "max_seq_len": 252,
                "n_features": 37,
                "activation": "gelu"
            },
            "sac": {
                "state_dim": 256,
                "action_dim": 3,
                "hidden_dim": 512,
                "use_transformer": True
            }
        },
        "high_performance": {
            "name": "é«˜æ€§èƒ½é…ç½®",
            "description": "é€‚ç”¨äºGPUå……è¶³ç¯å¢ƒï¼Œè¿½æ±‚æœ€ä½³æ€§èƒ½",
            "transformer": {
                "d_model": 512,
                "n_heads": 16,
                "n_layers": 8,
                "d_ff": 2048,
                "dropout": 0.1,
                "max_seq_len": 252,
                "n_features": 37,
                "activation": "gelu"
            },
            "sac": {
                "state_dim": 512,
                "action_dim": 3,
                "hidden_dim": 1024,
                "use_transformer": True
            }
        },
        "debug": {
            "name": "è°ƒè¯•é…ç½®",
            "description": "æå°é…ç½®ï¼Œç”¨äºå¿«é€Ÿè°ƒè¯•å’Œæµ‹è¯•",
            "transformer": {
                "d_model": 64,
                "n_heads": 2,
                "n_layers": 2,
                "d_ff": 256,
                "dropout": 0.1,
                "max_seq_len": 60,
                "n_features": 37,
                "activation": "gelu"
            },
            "sac": {
                "state_dim": 64,
                "action_dim": 3,
                "hidden_dim": 128,
                "use_transformer": True
            }
        }
    }


def validate_config(transformer_config: Dict, sac_config: Dict) -> bool:
    """éªŒè¯é…ç½®çš„åˆç†æ€§"""
    try:
        # åŸºæœ¬éªŒè¯
        d_model = transformer_config["d_model"]
        n_heads = transformer_config["n_heads"]
        
        assert d_model > 0, "d_modelå¿…é¡»å¤§äº0"
        assert n_heads > 0, "n_headså¿…é¡»å¤§äº0"
        assert d_model % n_heads == 0, f"d_model ({d_model}) å¿…é¡»èƒ½è¢«n_heads ({n_heads}) æ•´é™¤"
        
        # ä¸SACé…ç½®çš„ä¸€è‡´æ€§
        assert sac_config["state_dim"] == d_model, f"SAC state_dim ({sac_config['state_dim']}) å¿…é¡»ä¸Transformer d_model ({d_model}) ä¸€è‡´"
        
        # ç‰¹å¾ç»´åº¦æ£€æŸ¥
        assert transformer_config["n_features"] == 37, "å½“å‰ç³»ç»Ÿè¦æ±‚n_features=37"
        
        # åˆç†æ€§æ£€æŸ¥
        assert transformer_config["dropout"] <= 0.5, "dropoutä¸åº”è¶…è¿‡0.5"
        assert transformer_config["d_ff"] >= d_model, "d_ffåº”è¯¥è‡³å°‘ç­‰äºd_model"
        
        return True
    except AssertionError as e:
        print(f"âŒ é…ç½®éªŒè¯å¤±è´¥: {e}")
        return False


def estimate_model_complexity(config: Dict[str, Any]) -> Dict[str, Any]:
    """ä¼°ç®—æ¨¡å‹å¤æ‚åº¦"""
    transformer = config["transformer"]
    
    d_model = transformer["d_model"]
    n_layers = transformer["n_layers"]
    n_heads = transformer["n_heads"]
    d_ff = transformer["d_ff"]
    n_features = transformer["n_features"]
    max_seq_len = transformer["max_seq_len"]
    
    # ä¼°ç®—å‚æ•°é‡
    # è¾“å…¥æŠ•å½±å±‚
    input_proj_params = n_features * d_model
    
    # Transformerå±‚å‚æ•°
    # æ¯å±‚åŒ…å«ï¼šå¤šå¤´æ³¨æ„åŠ› + å‰é¦ˆç½‘ç»œ + å±‚å½’ä¸€åŒ–
    per_layer_params = (
        4 * d_model * d_model +  # Q, K, V, O æŠ•å½±
        2 * d_model * d_ff +     # å‰é¦ˆç½‘ç»œ
        4 * d_model              # å±‚å½’ä¸€åŒ–å‚æ•°
    )
    transformer_params = n_layers * per_layer_params
    
    # è¾“å‡ºæŠ•å½±å±‚
    output_proj_params = d_model * d_model
    
    total_params = input_proj_params + transformer_params + output_proj_params
    
    # ä¼°ç®—å†…å­˜ä½¿ç”¨ (å‡è®¾float32)
    memory_mb = total_params * 4 / (1024 * 1024)
    
    # ä¼°ç®—è®­ç»ƒæ—¶å†…å­˜ (åŒ…å«æ¢¯åº¦å’Œä¼˜åŒ–å™¨çŠ¶æ€)
    training_memory_mb = memory_mb * 4
    
    # å¤æ‚åº¦ç­‰çº§
    if total_params < 1e6:
        complexity = "ä½"
    elif total_params < 5e6:
        complexity = "ä¸­"
    else:
        complexity = "é«˜"
    
    return {
        "total_parameters": total_params,
        "model_size_mb": memory_mb,
        "training_memory_mb": training_memory_mb,
        "complexity": complexity,
        "estimated_training_time": f"{'å¿«' if total_params < 1e6 else 'ä¸­' if total_params < 5e6 else 'æ…¢'}",
        "inference_speed": f"{'å¾ˆå¿«' if total_params < 1e6 else 'å¿«' if total_params < 5e6 else 'ä¸­ç­‰'}"
    }


def generate_python_code(config: Dict[str, Any]) -> str:
    """ç”ŸæˆPythonä»£ç """
    transformer = config["transformer"]
    sac = config["sac"]
    
    code = f'''import torch
from rl_trading_system.models.transformer import TransformerConfig
from rl_trading_system.models.sac_agent import SACConfig, SACAgent

# Transformeré…ç½®
transformer_config = TransformerConfig(
    d_model={transformer["d_model"]},
    n_heads={transformer["n_heads"]},
    n_layers={transformer["n_layers"]},
    d_ff={transformer["d_ff"]},
    dropout={transformer["dropout"]},
    max_seq_len={transformer["max_seq_len"]},
    n_features={transformer["n_features"]},
    activation="{transformer["activation"]}"
)

# SACé…ç½®
sac_config = SACConfig(
    state_dim={sac["state_dim"]},
    action_dim={sac["action_dim"]},
    hidden_dim={sac["hidden_dim"]},
    use_transformer={str(sac["use_transformer"]).title()},
    transformer_config=transformer_config,
    device="cuda" if torch.cuda.is_available() else "cpu"
)

# åˆ›å»ºæ™ºèƒ½ä½“
agent = SACAgent(sac_config)

print(f"âœ… åˆ›å»ºäº†{{config['name']}}æ™ºèƒ½ä½“")
print(f"   Transformerå‚æ•°: {{transformer_config.d_model}}ç»´åº¦, {{transformer_config.n_heads}}å¤´, {{transformer_config.n_layers}}å±‚")
print(f"   è®¾å¤‡: {{sac_config.device}}")
'''
    return code


def save_config(config: Dict[str, Any], output_path: Path, format: str):
    """ä¿å­˜é…ç½®æ–‡ä»¶"""
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    if format == "json":
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
    elif format == "yaml":
        with open(output_path, 'w', encoding='utf-8') as f:
            yaml.dump(config, f, default_flow_style=False, allow_unicode=True)
    elif format == "python":
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(generate_python_code(config))


def main():
    parser = argparse.ArgumentParser(description="Transformeré…ç½®ç”Ÿæˆå™¨")
    parser.add_argument("--preset", type=str, 
                       choices=["lightweight", "standard", "high_performance", "debug"],
                       default="standard",
                       help="é¢„è®¾é…ç½®ç±»å‹")
    parser.add_argument("--output", type=str, default="config/generated_transformer_config",
                       help="è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆä¸å«æ‰©å±•åï¼‰")
    parser.add_argument("--format", type=str, choices=["json", "yaml", "python"], 
                       default="yaml", help="è¾“å‡ºæ ¼å¼")
    parser.add_argument("--list-presets", action="store_true",
                       help="åˆ—å‡ºæ‰€æœ‰é¢„è®¾é…ç½®")
    parser.add_argument("--validate", action="store_true",
                       help="éªŒè¯é…ç½®åˆç†æ€§")
    parser.add_argument("--analyze", action="store_true",
                       help="åˆ†ææ¨¡å‹å¤æ‚åº¦")
    
    # è‡ªå®šä¹‰å‚æ•°
    parser.add_argument("--d-model", type=int, help="è‡ªå®šä¹‰æ¨¡å‹ç»´åº¦")
    parser.add_argument("--n-heads", type=int, help="è‡ªå®šä¹‰æ³¨æ„åŠ›å¤´æ•°")
    parser.add_argument("--n-layers", type=int, help="è‡ªå®šä¹‰å±‚æ•°")
    parser.add_argument("--d-ff", type=int, help="è‡ªå®šä¹‰å‰é¦ˆç½‘ç»œç»´åº¦")
    
    args = parser.parse_args()
    
    presets = get_preset_configs()
    
    if args.list_presets:
        print("ğŸ“‹ å¯ç”¨çš„é¢„è®¾é…ç½®ï¼š\n")
        for key, preset in presets.items():
            print(f"ğŸ”¹ {key}: {preset['name']}")
            print(f"   æè¿°: {preset['description']}")
            transformer = preset["transformer"]
            print(f"   å‚æ•°: d_model={transformer['d_model']}, n_heads={transformer['n_heads']}, n_layers={transformer['n_layers']}")
            print()
        return
    
    # è·å–åŸºç¡€é…ç½®
    if args.preset in presets:
        config = presets[args.preset].copy()
    else:
        print(f"âŒ æœªçŸ¥çš„é¢„è®¾é…ç½®: {args.preset}")
        print("å¯ç”¨é…ç½®:", list(presets.keys()))
        return
    
    # åº”ç”¨è‡ªå®šä¹‰å‚æ•°
    if args.d_model:
        config["transformer"]["d_model"] = args.d_model
        config["sac"]["state_dim"] = args.d_model  # ä¿æŒä¸€è‡´
    if args.n_heads:
        config["transformer"]["n_heads"] = args.n_heads
    if args.n_layers:
        config["transformer"]["n_layers"] = args.n_layers
    if args.d_ff:
        config["transformer"]["d_ff"] = args.d_ff
    
    print(f"ğŸ”§ ç”Ÿæˆé…ç½®: {config['name']}")
    print(f"ğŸ“ æè¿°: {config['description']}")
    print()
    
    # éªŒè¯é…ç½®
    if args.validate or args.analyze:
        is_valid = validate_config(config["transformer"], config["sac"])
        if not is_valid:
            return
        print("âœ… é…ç½®éªŒè¯é€šè¿‡")
        print()
    
    # åˆ†æå¤æ‚åº¦
    if args.analyze:
        complexity = estimate_model_complexity(config)
        print("ğŸ“Š æ¨¡å‹å¤æ‚åº¦åˆ†æ:")
        print(f"   å‚æ•°é‡: {complexity['total_parameters']:,}")
        print(f"   æ¨¡å‹å¤§å°: {complexity['model_size_mb']:.1f} MB")
        print(f"   è®­ç»ƒå†…å­˜: {complexity['training_memory_mb']:.1f} MB")
        print(f"   å¤æ‚åº¦: {complexity['complexity']}")
        print(f"   è®­ç»ƒé€Ÿåº¦: {complexity['estimated_training_time']}")
        print(f"   æ¨ç†é€Ÿåº¦: {complexity['inference_speed']}")
        print()
    
    # ä¿å­˜é…ç½®
    output_path = Path(args.output).with_suffix(f".{args.format}")
    save_config(config, output_path, args.format)
    
    print(f"ğŸ’¾ é…ç½®å·²ä¿å­˜åˆ°: {output_path}")
    
    # æ˜¾ç¤ºä½¿ç”¨æ–¹æ³•
    if args.format == "python":
        print("\nğŸ“– ä½¿ç”¨æ–¹æ³•:")
        print(f"   python -c \"exec(open('{output_path}').read())\"")
    elif args.format == "yaml":
        print("\nğŸ“– ä½¿ç”¨æ–¹æ³•:")
        print(f"   åœ¨ä»£ç ä¸­: config = yaml.load(open('{output_path}'))")
    elif args.format == "json":
        print("\nğŸ“– ä½¿ç”¨æ–¹æ³•:")
        print(f"   åœ¨ä»£ç ä¸­: config = json.load(open('{output_path}'))")


if __name__ == "__main__":
    main()