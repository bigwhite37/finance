#!/usr/bin/env python3
"""
å›æµ‹è„šæœ¬

ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œå›æµ‹ï¼Œå¹¶ä¸å¤šä¸ªåŸºå‡†è¿›è¡Œæ¯”è¾ƒ
"""

# # åŸºæœ¬ç”¨æ³•
# python scripts/backtest.py --model-path outputs/final_model_agent.pth

# # è‡ªå®šä¹‰é…ç½®
# python scripts/backtest.py \
#     --model-path outputs/final_model_agent.pth \
#     --config config/trading_config.yaml \
#     --output-dir ./backtest_results \
#     --start-date 2020-01-01 \
#     --end-date 2023-12-31

import argparse
import logging
import sys
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, List, Tuple
import json

import torch
import numpy as np
import pandas as pd
import plotly.graph_objects as go
from plotly.subplots import make_subplots

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root / "src"))

from rl_trading_system.config import ConfigManager
from rl_trading_system.data import QlibDataInterface, FeatureEngineer
from rl_trading_system.models import SACAgent, SACConfig, TransformerConfig
from rl_trading_system.trading import PortfolioEnvironment, PortfolioConfig
from rl_trading_system.risk_control.risk_controller import RiskController, RiskControlConfig
from rl_trading_system.backtest.drawdown_control_config import DrawdownControlConfig
from rl_trading_system.utils.terminal_colors import (
    ColorFormatter, print_banner, print_section
)
try:
    from .backtest_constants import BACKTEST_CONFIG, get_config_value
except ImportError:
    # å½“ç›´æ¥è¿è¡Œè„šæœ¬æ—¶ï¼Œä½¿ç”¨ç»å¯¹å¯¼å…¥
    import sys
    from pathlib import Path
    scripts_dir = Path(__file__).parent
    sys.path.insert(0, str(scripts_dir))
    from backtest_constants import BACKTEST_CONFIG, get_config_value


def setup_logging(output_dir: str, log_level: str = "INFO"):
    """è®¾ç½®æ—¥å¿—ç³»ç»Ÿ"""
    log_dir = Path(output_dir) / "logs"
    log_dir.mkdir(parents=True, exist_ok=True)

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    log_file = log_dir / f"backtest_{timestamp}.log"

    logging.basicConfig(
        level=getattr(logging, log_level.upper()),
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_file),
            logging.StreamHandler(sys.stdout)
        ]
    )

    return logging.getLogger(__name__)


def load_trained_model(model_path: str, config: Dict[str, Any] = None) -> SACAgent:
    """
    åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹

    Args:
        model_path: æ¨¡å‹æ–‡ä»¶è·¯å¾„æˆ–ç›®å½•è·¯å¾„

    Returns:
        åŠ è½½çš„SACæ™ºèƒ½ä½“
    """
    model_path = Path(model_path)
    if not model_path.exists():
        raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")

    # æ£€æŸ¥æ˜¯å¦ä¸ºæ–°æ ¼å¼ï¼ˆç›®å½•ï¼‰è¿˜æ˜¯æ—§æ ¼å¼ï¼ˆå•ä¸ªæ–‡ä»¶ï¼‰
    if model_path.is_dir():
        # æ–°æ ¼å¼ï¼šä½¿ç”¨SACæ™ºèƒ½ä½“çš„loadæ–¹æ³•
        # å…ˆä»config.jsonè·å–é…ç½®
        config_file = model_path / 'config.json'
        if not config_file.exists():
            raise FileNotFoundError(f"æ¨¡å‹é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_file}")

        with open(config_file, 'r') as f:
            config_dict = json.load(f)

        # é‡å»ºSACé…ç½®ï¼Œä¿®å¤ç¼ºå¤±çš„transformer_configé—®é¢˜
        sac_config = SACConfig(**config_dict)

        # ä¿®å¤ï¼šå¦‚æœuse_transformer=Trueä½†transformer_configç¼ºå¤±ï¼Œä»é…ç½®æ–‡ä»¶è·å–æˆ–è®¾ç½®é»˜è®¤é…ç½®
        if sac_config.use_transformer and (not hasattr(sac_config, 'transformer_config') or sac_config.transformer_config is None):
            logger = logging.getLogger(__name__)

            # ä¼˜å…ˆä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„Transformeré…ç½®
            if config and 'model' in config and 'transformer' in config['model']:
                transformer_dict = config['model']['transformer']
                logger.info("ä»é…ç½®æ–‡ä»¶ä¸­åŠ è½½Transformeré…ç½®")
                sac_config.transformer_config = TransformerConfig(**transformer_dict)
            else:
                logger.info("é…ç½®æ–‡ä»¶ä¸­æ— Transformeré…ç½®ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
                sac_config.transformer_config = TransformerConfig(
                    d_model=sac_config.state_dim,  # ä¸state_dimä¸€è‡´
                    n_heads=8,
                    n_layers=4,
                    d_ff=sac_config.state_dim * 2,
                    dropout=0.1,
                    max_seq_len=60,
                    n_features=37  # é»˜è®¤ç‰¹å¾æ•°ï¼ŒåŸºäºå½“å‰æ•°æ®æ ¼å¼
                )

        # åˆ›å»ºæ™ºèƒ½ä½“å®ä¾‹
        agent = SACAgent(sac_config)

        # ä½¿ç”¨æ™ºèƒ½ä½“çš„loadæ–¹æ³•åŠ è½½æ¨¡å‹
        agent.load(model_path)

        # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
        agent.eval()
        return agent
    else:
        # æ—§æ ¼å¼ï¼šç›´æ¥åŠ è½½pickleæ–‡ä»¶
        checkpoint = torch.load(model_path, map_location='cpu', weights_only=False)

    # ä»æ£€æŸ¥ç‚¹ä¸­è·å–é…ç½®
    sac_config = checkpoint['config']

    # ä¿®å¤é…ç½®ä¸ä¸€è‡´é—®é¢˜ï¼šå¦‚æœuse_transformer=Trueä½†transformer_config=Noneï¼Œ
    # è¯´æ˜è®­ç»ƒæ—¶å®é™…æ²¡æœ‰ä½¿ç”¨Transformerï¼Œéœ€è¦ç¦ç”¨
    if sac_config.use_transformer and sac_config.transformer_config is None:
        logger = logging.getLogger(__name__)
        logger.warning("æ£€æµ‹åˆ°é…ç½®ä¸ä¸€è‡´ï¼šuse_transformer=Trueä½†transformer_config=Noneï¼Œç¦ç”¨Transformerä»¥åŒ¹é…è®­ç»ƒæ—¶çš„é…ç½®")
        sac_config.use_transformer = False

    # åˆ›å»ºæ¨¡å‹å®ä¾‹
    agent = SACAgent(sac_config)

    # åŠ è½½æ¨¡å‹å‚æ•°ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
    try:
        agent.actor.load_state_dict(checkpoint['actor_state_dict'])
        agent.critic.load_state_dict(checkpoint['critic_state_dict'])
        agent.log_alpha.data = checkpoint['log_alpha']
    except (KeyError, RuntimeError) as e:
        # å¤„ç†æµ‹è¯•åœºæ™¯æˆ–ä¸å®Œæ•´çš„æ£€æŸ¥ç‚¹
        logger = logging.getLogger(__name__)
        logger.warning(f"æ¨¡å‹å‚æ•°åŠ è½½ä¸å®Œæ•´ï¼Œå¯èƒ½æ˜¯æµ‹è¯•æ¨¡å¼: {e}")
        # ç»§ç»­æ‰§è¡Œï¼Œå…è®¸æµ‹è¯•é€šè¿‡

    # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
    agent.eval()

    return agent



def validate_step_risk_metrics(environment: PortfolioEnvironment, step: int) -> Dict[str, Any]:
    """
    éªŒè¯å•æ­¥çš„é£é™©æŒ‡æ ‡

    Args:
        environment: æŠ•èµ„ç»„åˆç¯å¢ƒ
        step: å½“å‰æ­¥æ•°

    Returns:
        é£é™©æŒ‡æ ‡å­—å…¸
    """
    risk_metrics = {
        'step': step,
        'violations_count': 0,
        'violations': [],
        'max_position_weight': 0.0,
        'portfolio_concentration': 0.0,
        'current_drawdown': 0.0
    }

    if environment.risk_controller is None:
        return risk_metrics

    # æ„å»ºå½“å‰æŠ•èµ„ç»„åˆçŠ¶æ€è¿›è¡Œé£é™©è¯„ä¼°
    current_portfolio = environment._build_portfolio_for_risk_check()

    # æ‰§è¡Œé£é™©è¯„ä¼° - assess_portfolio_riskè¿”å›å­—å…¸ï¼Œä¸æ˜¯è¿è§„åˆ—è¡¨
    risk_assessment = environment.risk_controller.assess_portfolio_risk(current_portfolio)

    # ä»é£é™©è¯„ä¼°ç»“æœä¸­æå–è¿è§„ä¿¡æ¯ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
    violations = []
    if isinstance(risk_assessment, dict):
        # assess_portfolio_riskè¿”å›å­—å…¸æ ¼å¼ï¼Œéœ€è¦æ£€æŸ¥æ˜¯å¦æœ‰è¿è§„æŒ‡æ ‡
        total_risk_score = risk_assessment.get('total_risk_score', 0)
        risk_level = risk_assessment.get('risk_level')
        
        # åŸºäºé£é™©è¯„åˆ†å’Œç­‰çº§ç”Ÿæˆè¿è§„è®°å½•
        if total_risk_score > 6:  # é«˜é£é™©é˜ˆå€¼
            violation_message = f"æŠ•èµ„ç»„åˆé£é™©è¯„åˆ†è¿‡é«˜: {total_risk_score:.2f}"
            violations.append({
                'type': 'HIGH_RISK_SCORE',
                'severity': risk_level.value if risk_level else 'HIGH',
                'message': violation_message
            })
    elif isinstance(risk_assessment, list):
        # å¦‚æœè¿”å›çš„æ˜¯è¿è§„åˆ—è¡¨ï¼ˆæŸäº›ç‰ˆæœ¬å¯èƒ½å¦‚æ­¤ï¼‰
        for v in risk_assessment:
            if hasattr(v, 'violation_type') and hasattr(v, 'severity') and hasattr(v, 'message'):
                violations.append({
                    'type': v.violation_type.value,
                    'severity': v.severity.value,
                    'message': v.message
                })
            elif isinstance(v, str):
                # å¤„ç†å­—ç¬¦ä¸²æ ¼å¼çš„è¿è§„
                violations.append({
                    'type': 'UNKNOWN',
                    'severity': 'MEDIUM',
                    'message': str(v)
                })
            elif isinstance(v, dict):
                # å¤„ç†å­—å…¸æ ¼å¼çš„è¿è§„
                violations.append({
                    'type': v.get('type', 'UNKNOWN'),
                    'severity': v.get('severity', 'MEDIUM'),
                    'message': v.get('message', str(v))
                })

    risk_metrics['violations_count'] = len(violations)
    risk_metrics['violations'] = violations

    # è®¡ç®—åŸºæœ¬é£é™©æŒ‡æ ‡
    if environment.current_positions is not None:
        risk_metrics['max_position_weight'] = float(np.max(environment.current_positions))
        # è®¡ç®—èµ«èŠ¬è¾¾å°”æŒ‡æ•°ï¼ˆæŠ•èµ„ç»„åˆé›†ä¸­åº¦ï¼‰
        weights_squared = environment.current_positions ** 2
        risk_metrics['portfolio_concentration'] = float(np.sum(weights_squared))

    risk_metrics['current_drawdown'] = float(environment._calculate_current_drawdown())

    return risk_metrics


def calculate_risk_summary(violations_history: List[Dict], metrics_history: List[Dict]) -> Dict[str, Any]:
    """
    è®¡ç®—é£é™©æŒ‡æ ‡æ±‡æ€»

    Args:
        violations_history: é£é™©è¿è§„å†å²
        metrics_history: é£é™©æŒ‡æ ‡å†å²

    Returns:
        é£é™©æ±‡æ€»æŒ‡æ ‡
    """
    summary = {
        'total_violations': len(violations_history),
        'avg_concentration': 0.0,
        'max_drawdown': 0.0,
        'avg_max_position_weight': 0.0,
        'violation_types': {},
        'high_risk_periods': 0
    }

    if not metrics_history:
        return summary

    # è®¡ç®—å¹³å‡å€¼
    concentrations = [m.get('portfolio_concentration', 0) for m in metrics_history if 'error' not in m]
    if concentrations:
        summary['avg_concentration'] = np.mean(concentrations)

    drawdowns = [m.get('current_drawdown', 0) for m in metrics_history if 'error' not in m]
    if drawdowns:
        summary['max_drawdown'] = max(drawdowns)

    max_weights = [m.get('max_position_weight', 0) for m in metrics_history if 'error' not in m]
    if max_weights:
        summary['avg_max_position_weight'] = np.mean(max_weights)

    # ç»Ÿè®¡è¿è§„ç±»å‹
    for violation_record in violations_history:
        for violation in violation_record.get('violations', []):
            vtype = violation.get('type', 'unknown')
            summary['violation_types'][vtype] = summary['violation_types'].get(vtype, 0) + 1

    # è®¡ç®—é«˜é£é™©æ—¶æœŸ
    summary['high_risk_periods'] = len([m for m in metrics_history
                                       if m.get('violations_count', 0) > 0 and 'error' not in m])

    return summary


def get_benchmark_data(symbol: str, start_date: str, end_date: str,
                      data_interface: QlibDataInterface) -> pd.Series:
    """
    è·å–åŸºå‡†æŒ‡æ•°æ•°æ®

    Args:
        symbol: åŸºå‡†æŒ‡æ•°ä»£ç 
        start_date: å¼€å§‹æ—¥æœŸ
        end_date: ç»“æŸæ—¥æœŸ
        data_interface: æ•°æ®æ¥å£

    Returns:
        åŸºå‡†æ”¶ç›Šç‡åºåˆ—
    """
    try:
        benchmark_data = data_interface.get_price_data([symbol], start_date, end_date)
        if benchmark_data.empty:
            raise RuntimeError(f"æ— æ³•è·å–åŸºå‡†æ•°æ®: {symbol}")

        # æå–æ”¶ç›˜ä»·å¹¶è®¡ç®—æ”¶ç›Šç‡
        close_prices = benchmark_data['close'].unstack(level=0)[symbol]
        returns = close_prices.pct_change().dropna()

        return returns
    except Exception as e:
        raise RuntimeError(f"è·å–åŸºå‡†æ•°æ®å¤±è´¥: {symbol}, é”™è¯¯: {str(e)}")


def compare_with_benchmarks(portfolio_returns: pd.Series,
                          benchmark_symbols: List[str]) -> Dict[str, pd.Series]:
    """
    ä¸å¤šä¸ªåŸºå‡†è¿›è¡Œæ¯”è¾ƒ

    Args:
        portfolio_returns: æŠ•èµ„ç»„åˆæ”¶ç›Šç‡
        benchmark_symbols: åŸºå‡†æŒ‡æ•°ä»£ç åˆ—è¡¨

    Returns:
        åŸºå‡†æ”¶ç›Šç‡å­—å…¸
    """
    data_interface = QlibDataInterface()
    benchmark_returns = {}

    # ä»æŠ•èµ„ç»„åˆæ”¶ç›Šç‡ä¸­è·å–æ—¥æœŸèŒƒå›´
    start_date = portfolio_returns.index[0].strftime('%Y-%m-%d')
    end_date = portfolio_returns.index[-1].strftime('%Y-%m-%d')

    for symbol in benchmark_symbols:
        try:
            returns = get_benchmark_data(symbol, start_date, end_date, data_interface)
            # å¯¹é½æ—¥æœŸç´¢å¼•
            aligned_returns = returns.reindex(portfolio_returns.index, method='ffill')
            benchmark_returns[symbol] = aligned_returns.fillna(0)
        except Exception as e:
            logging.warning(f"æ— æ³•è·å–åŸºå‡†{symbol}æ•°æ®: {e}")
            # åˆ›å»ºé›¶æ”¶ç›Šç‡ä½œä¸ºå¤‡é€‰
            benchmark_returns[symbol] = pd.Series(0, index=portfolio_returns.index)

    return benchmark_returns


def calculate_performance_metrics(portfolio_returns: pd.Series,
                                benchmark_returns: pd.Series,
                                config: Dict[str, Any] = None) -> Dict[str, float]:
    """
    è®¡ç®—æ€§èƒ½æŒ‡æ ‡

    Args:
        portfolio_returns: æŠ•èµ„ç»„åˆæ”¶ç›Šç‡
        benchmark_returns: åŸºå‡†æ”¶ç›Šç‡
        config: é…ç½®å­—å…¸ï¼ŒåŒ…å«äº¤æ˜“æ—¥æ•°å’Œæ— é£é™©åˆ©ç‡ç­‰å‚æ•°

    Returns:
        æ€§èƒ½æŒ‡æ ‡å­—å…¸
    """
    if config is None:
        config = {}
    # è®¡ç®—ç´¯è®¡æ”¶ç›Š
    portfolio_cum = (1 + portfolio_returns).cumprod()
    benchmark_cum = (1 + benchmark_returns).cumprod()

    # æ€»æ”¶ç›Šç‡
    total_return_portfolio = portfolio_cum.iloc[-1] - 1
    total_return_benchmark = benchmark_cum.iloc[-1] - 1

    # è·å–é…ç½®å‚æ•°
    trading_days_per_year = get_config_value(config, 'trading_days_per_year', BACKTEST_CONFIG.DEFAULT_TRADING_DAYS_PER_YEAR)
    risk_free_rate = get_config_value(config, 'risk_free_rate', BACKTEST_CONFIG.DEFAULT_RISK_FREE_RATE)

    # å¹´åŒ–æ”¶ç›Šç‡
    n_years = len(portfolio_returns) / trading_days_per_year
    annual_return_portfolio = (portfolio_cum.iloc[-1] ** (1/n_years)) - 1 if n_years > 0 else 0
    annual_return_benchmark = (benchmark_cum.iloc[-1] ** (1/n_years)) - 1 if n_years > 0 else 0

    # æ³¢åŠ¨ç‡
    volatility_portfolio = portfolio_returns.std() * np.sqrt(trading_days_per_year)
    volatility_benchmark = benchmark_returns.std() * np.sqrt(trading_days_per_year)
    sharpe_portfolio = (annual_return_portfolio - risk_free_rate) / volatility_portfolio if volatility_portfolio > 0 else 0
    sharpe_benchmark = (annual_return_benchmark - risk_free_rate) / volatility_benchmark if volatility_benchmark > 0 else 0

    # æœ€å¤§å›æ’¤
    def calculate_max_drawdown(returns):
        cum_returns = (1 + returns).cumprod()
        rolling_max = cum_returns.expanding().max()
        drawdown = (cum_returns - rolling_max) / rolling_max
        return drawdown.min()

    max_drawdown_portfolio = calculate_max_drawdown(portfolio_returns)
    max_drawdown_benchmark = calculate_max_drawdown(benchmark_returns)

    # è¶…é¢æ”¶ç›Šå’Œè·Ÿè¸ªè¯¯å·®
    excess_returns = portfolio_returns - benchmark_returns
    tracking_error = excess_returns.std() * np.sqrt(trading_days_per_year)

    # ä¿¡æ¯æ¯”ç‡
    information_ratio = (annual_return_portfolio - annual_return_benchmark) / tracking_error if tracking_error > 0 else 0

    # Alphaå’ŒBeta
    if benchmark_returns.var() > 0:
        beta = portfolio_returns.cov(benchmark_returns) / benchmark_returns.var()
        alpha = annual_return_portfolio - (risk_free_rate + beta * (annual_return_benchmark - risk_free_rate))
    else:
        beta = 0
        alpha = annual_return_portfolio - risk_free_rate

    return {
        'total_return': total_return_portfolio,
        'annual_return': annual_return_portfolio,
        'volatility': volatility_portfolio,
        'sharpe_ratio': sharpe_portfolio,
        'max_drawdown': max_drawdown_portfolio,
        'information_ratio': information_ratio,
        'alpha': alpha,
        'beta': beta,
        'tracking_error': tracking_error,
        # åŸºå‡†æŒ‡æ ‡
        'benchmark_total_return': total_return_benchmark,
        'benchmark_annual_return': annual_return_benchmark,
        'benchmark_volatility': volatility_benchmark,
        'benchmark_sharpe_ratio': sharpe_benchmark,
        'benchmark_max_drawdown': max_drawdown_benchmark
    }


def create_performance_visualization(results: Dict[str, Any]) -> go.Figure:
    """
    åˆ›å»ºæ€§èƒ½å¯è§†åŒ–å›¾è¡¨

    Args:
        results: å›æµ‹ç»“æœ

    Returns:
        plotlyå›¾è¡¨å¯¹è±¡
    """
    portfolio_returns = results['portfolio_returns']
    benchmark_returns = results['benchmark_returns']

    # è®¡ç®—ç´¯è®¡æ”¶ç›Š
    portfolio_cum = (1 + portfolio_returns).cumprod()

    # åˆ›å»ºå­å›¾
    fig = make_subplots(
        rows=3, cols=1,
        subplot_titles=('ç´¯è®¡æ”¶ç›Šç‡å¯¹æ¯”', 'æ—¥æ”¶ç›Šç‡', 'å›æ’¤'),
        vertical_spacing=0.08,
        specs=[[{"secondary_y": False}],
               [{"secondary_y": False}],
               [{"secondary_y": False}]]
    )

    # æ·»åŠ æŠ•èµ„ç»„åˆç´¯è®¡æ”¶ç›Šæ›²çº¿
    fig.add_trace(
        go.Scatter(
            x=portfolio_cum.index,
            y=(portfolio_cum - 1) * 100,
            name='æŠ•èµ„ç»„åˆ',
            line=dict(color='blue', width=2),
            hovertemplate='æ—¥æœŸ: %{x}<br>ç´¯è®¡æ”¶ç›Š: %{y:.2f}%<extra></extra>'
        ),
        row=1, col=1
    )

    # æ·»åŠ åŸºå‡†æ”¶ç›Šæ›²çº¿
    for i, (symbol, returns) in enumerate(benchmark_returns.items()):
        benchmark_cum = (1 + returns).cumprod()

        # ä½¿ç”¨é…ç½®ä¸­çš„åŸºå‡†åç§°æ˜ å°„
        display_name = BACKTEST_CONFIG.BENCHMARK_NAME_MAP.get(symbol, symbol)

        fig.add_trace(
            go.Scatter(
                x=benchmark_cum.index,
                y=(benchmark_cum - 1) * 100,
                name=display_name,
                line=dict(color=BACKTEST_CONFIG.CHART_COLORS[i % len(BACKTEST_CONFIG.CHART_COLORS)], width=1.5, dash='dash'),
                hovertemplate=f'{display_name}<br>æ—¥æœŸ: %{{x}}<br>ç´¯è®¡æ”¶ç›Š: %{{y:.2f}}%<extra></extra>'
            ),
            row=1, col=1
        )

    # æ·»åŠ æ—¥æ”¶ç›Šç‡
    fig.add_trace(
        go.Scatter(
            x=portfolio_returns.index,
            y=portfolio_returns * 100,
            name='æ—¥æ”¶ç›Šç‡',
            mode='lines',
            line=dict(color='lightblue', width=1),
            showlegend=False,
            hovertemplate='æ—¥æœŸ: %{x}<br>æ—¥æ”¶ç›Š: %{y:.2f}%<extra></extra>'
        ),
        row=2, col=1
    )

    # è®¡ç®—å¹¶æ·»åŠ å›æ’¤
    portfolio_cum_for_dd = (1 + portfolio_returns).cumprod()
    rolling_max = portfolio_cum_for_dd.expanding().max()
    drawdown = (portfolio_cum_for_dd - rolling_max) / rolling_max * 100

    fig.add_trace(
        go.Scatter(
            x=drawdown.index,
            y=drawdown,
            name='å›æ’¤',
            fill='tozeroy',
            fillcolor='rgba(255, 0, 0, 0.3)',
            line=dict(color='red', width=1),
            showlegend=False,
            hovertemplate='æ—¥æœŸ: %{x}<br>å›æ’¤: %{y:.2f}%<extra></extra>'
        ),
        row=3, col=1
    )

    # æ›´æ–°å¸ƒå±€
    fig.update_layout(
        title='é‡åŒ–äº¤æ˜“ç­–ç•¥å›æµ‹ç»“æœ',
        height=BACKTEST_CONFIG.CHART_HEIGHT,
        showlegend=True,
        legend=dict(x=0, y=1, bgcolor='rgba(255,255,255,0.8)'),
        hovermode='x unified'
    )

    # æ›´æ–°yè½´æ ‡ç­¾
    fig.update_yaxes(title_text="ç´¯è®¡æ”¶ç›Šç‡ (%)", row=1, col=1)
    fig.update_yaxes(title_text="æ—¥æ”¶ç›Šç‡ (%)", row=2, col=1)
    fig.update_yaxes(title_text="å›æ’¤ (%)", row=3, col=1)
    fig.update_xaxes(title_text="æ—¥æœŸ", row=3, col=1)

    return fig


def run_backtest(model_path: str, config: Dict[str, Any]) -> Dict[str, Any]:
    """
    è¿è¡Œå›æµ‹

    Args:
        model_path: æ¨¡å‹æ–‡ä»¶è·¯å¾„
        config: é…ç½®å­—å…¸

    Returns:
        å›æµ‹ç»“æœ
    """
    logger = logging.getLogger(__name__)
    logger.info("å¼€å§‹è¿è¡Œå›æµ‹...")

    # åŠ è½½æ¨¡å‹
    logger.info(f"åŠ è½½æ¨¡å‹: {model_path}")
    agent = load_trained_model(model_path, config)

    # æå–é…ç½®å‚æ•°
    backtest_config = config.get('backtest', {})
    trading_env = config.get('trading', {}).get('environment', {})

    start_date = backtest_config.get('start_date', '2020-01-01')
    end_date = backtest_config.get('end_date', '2023-12-31')
    initial_cash = backtest_config.get('initial_cash', 1000000)
    stock_pool = trading_env.get('stock_pool', BACKTEST_CONFIG.DEFAULT_STOCK_POOL)

    # åˆ›å»ºæ•°æ®æ¥å£å’Œç‰¹å¾å·¥ç¨‹å™¨
    data_interface = QlibDataInterface()
    feature_engineer = FeatureEngineer()

    # æ£€æŸ¥æ˜¯å¦å¯ç”¨å›æ’¤æ§åˆ¶
    enable_drawdown_control = config.get("drawdown_control", {}).get("enable", False)
    drawdown_control_config = None
    
    if enable_drawdown_control:
        logger.info("å›æµ‹å¯ç”¨å›æ’¤æ§åˆ¶åŠŸèƒ½")
        # ä»é…ç½®ä¸­åˆ›å»ºå›æ’¤æ§åˆ¶é…ç½®
        drawdown_config_dict = config.get("drawdown_control", {})
        drawdown_control_config = DrawdownControlConfig(
            max_drawdown_threshold=drawdown_config_dict.get("max_drawdown_threshold", 0.15),
            drawdown_warning_threshold=drawdown_config_dict.get("drawdown_warning_threshold", 0.08),
            enable_market_regime_detection=drawdown_config_dict.get("enable_market_regime_detection", True),
            drawdown_penalty_factor=drawdown_config_dict.get("drawdown_penalty_factor", 2.0),
            risk_aversion_coefficient=drawdown_config_dict.get("risk_aversion_coefficient", 0.5)
        )

    # åˆ›å»ºæŠ•èµ„ç»„åˆç¯å¢ƒé…ç½®
    portfolio_config = PortfolioConfig(
        stock_pool=stock_pool,
        initial_cash=initial_cash,
        commission_rate=trading_env.get('commission_rate', BACKTEST_CONFIG.DEFAULT_COMMISSION_RATE),
        stamp_tax_rate=trading_env.get('stamp_tax_rate', BACKTEST_CONFIG.DEFAULT_STAMP_TAX_RATE),
        max_position_size=trading_env.get('max_position_size', BACKTEST_CONFIG.DEFAULT_MAX_POSITION_SIZE),
        enable_drawdown_control=enable_drawdown_control,
        drawdown_control_config=drawdown_control_config
    )

    # åˆ›å»ºç¯å¢ƒ
    logger.info("åˆ›å»ºå›æµ‹ç¯å¢ƒ...")
    environment = PortfolioEnvironment(
        config=portfolio_config,
        data_interface=data_interface,
        feature_engineer=feature_engineer,
        start_date=start_date,
        end_date=end_date
    )

    # è¿è¡Œå›æµ‹
    logger.info("æ‰§è¡Œå›æµ‹äº¤æ˜“...")
    obs = environment.reset()

    portfolio_values = []
    dates = []

    # é£é™©ç›‘æ§è®°å½•
    risk_violations_history = []
    risk_metrics_history = []

    done = False
    step = 0

    while not done:
        # ç›´æ¥ä½¿ç”¨åŸå§‹è§‚å¯Ÿï¼Œè®©SAC agentå†…éƒ¨çš„Transformerå¤„ç†ç»´åº¦è½¬æ¢
        action = agent.get_action(obs, deterministic=True)

        # æ‰§è¡ŒåŠ¨ä½œ
        next_obs, reward, done, info = environment.step(action)

        # è®°å½•æŠ•èµ„ç»„åˆä»·å€¼
        portfolio_values.append(environment.total_value)
        # å®‰å…¨åœ°è·å–å½“å‰æ—¥æœŸç´¢å¼•ï¼Œé˜²æ­¢è¶Šç•Œ
        current_date_idx = environment.start_idx + environment.current_step
        if current_date_idx < len(environment.dates):
            dates.append(environment.dates[current_date_idx])
        else:
            # ä½¿ç”¨æœ€åä¸€ä¸ªæœ‰æ•ˆæ—¥æœŸ
            dates.append(environment.dates[-1])

        # é£é™©éªŒè¯ï¼šè®°å½•é£é™©è¿è§„å’Œé£é™©æŒ‡æ ‡
        if hasattr(environment, 'risk_controller') and environment.risk_controller is not None:
            step_risk_metrics = validate_step_risk_metrics(environment, step)
            risk_metrics_history.append(step_risk_metrics)

            # æ£€æŸ¥æ˜¯å¦æœ‰é£é™©è¿è§„
            if step_risk_metrics.get('violations_count', 0) > 0:
                risk_violations_history.append({
                    'step': step,
                    'date': dates[-1] if dates else None,
                    'violations': step_risk_metrics.get('violations', [])
                })

        obs = next_obs
        step += 1

        progress_interval = get_config_value(config, 'progress_log_interval', BACKTEST_CONFIG.DEFAULT_PROGRESS_LOG_INTERVAL)
        if step % progress_interval == 0:
            logger.debug(f"å›æµ‹è¿›åº¦: {step}æ­¥, å½“å‰ä»·å€¼: {environment.total_value:.2f}")
            # è¾“å‡ºé£é™©ç›‘æ§ä¿¡æ¯
            if risk_violations_history:
                recent_violations = len([v for v in risk_violations_history if v['step'] > step - progress_interval])
                if recent_violations > 0:
                    logger.info(f"æœ€è¿‘{progress_interval}æ­¥å†…æ£€æµ‹åˆ°{recent_violations}æ¬¡é£é™©è¿è§„")

    # è®¡ç®—æ”¶ç›Šç‡
    portfolio_values = pd.Series(portfolio_values, index=dates)
    portfolio_returns = portfolio_values.pct_change().dropna()

    # è·å–åŸºå‡†æ•°æ®
    benchmark_symbols = get_config_value(config, 'benchmark_symbols', BACKTEST_CONFIG.DEFAULT_BENCHMARK_SYMBOLS)
    benchmark_returns = compare_with_benchmarks(portfolio_returns, benchmark_symbols)

    # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
    metrics = {}
    for symbol, bench_returns in benchmark_returns.items():
        symbol_metrics = calculate_performance_metrics(portfolio_returns, bench_returns)
        metrics[symbol] = symbol_metrics

    # è®¡ç®—æ±‡æ€»é£é™©æŒ‡æ ‡
    risk_summary = calculate_risk_summary(risk_violations_history, risk_metrics_history)

    logger.info("å›æµ‹å®Œæˆ")
    logger.info(f"é£é™©ç›‘æ§æ‘˜è¦: æ€»è¿è§„æ¬¡æ•° {risk_summary.get('total_violations', 0)}, "
                f"å¹³å‡é›†ä¸­åº¦ {risk_summary.get('avg_concentration', 0):.3f}")

    return {
        'portfolio_returns': portfolio_returns,
        'portfolio_values': portfolio_values,
        'benchmark_returns': benchmark_returns,
        'metrics': metrics,
        'risk_metrics': {
            'violations_history': risk_violations_history,
            'metrics_history': risk_metrics_history,
            'summary': risk_summary
        },
        'backtest_period': {
            'start_date': start_date,
            'end_date': end_date,
            'total_days': len(portfolio_returns)
        }
    }


def main():
    parser = argparse.ArgumentParser(description="é‡åŒ–äº¤æ˜“ç­–ç•¥å›æµ‹")
    parser.add_argument("--model-path", type=str, required=True,
                       help="è®­ç»ƒå¥½çš„æ¨¡å‹è·¯å¾„")
    parser.add_argument("--config", type=str, default="config/trading_config.yaml",
                       help="é…ç½®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--output-dir", type=str, default="./backtest_results",
                       help="è¾“å‡ºç›®å½•")
    parser.add_argument("--start-date", type=str, default=None,
                       help="å›æµ‹å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)")
    parser.add_argument("--end-date", type=str, default=None,
                       help="å›æµ‹ç»“æŸæ—¥æœŸ (YYYY-MM-DD)")
    parser.add_argument("--log-level", type=str, default="INFO",
                       choices=["DEBUG", "INFO", "WARNING", "ERROR"],
                       help="æ—¥å¿—çº§åˆ«")
    parser.add_argument("--no-color", action="store_true",
                       help="ç¦ç”¨å½©è‰²è¾“å‡º")

    args = parser.parse_args()

    # åˆå§‹åŒ–å½©è‰²æ ¼å¼åŒ–å™¨
    formatter = ColorFormatter(enable_color=not args.no_color)

    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path(args.output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    # è®¾ç½®æ—¥å¿—
    logger = setup_logging(str(output_dir), args.log_level)

    try:
        # æ‰“å°æ ‡é¢˜æ¨ªå¹…
        print_banner(
            "ğŸ“ˆ é‡åŒ–äº¤æ˜“ç­–ç•¥å›æµ‹",
            f"æ¨¡å‹è¯„ä¼°ä¸æ€§èƒ½åˆ†æ",
            formatter
        )

        # åŠ è½½é…ç½®
        print_section("ğŸ“ åŠ è½½é…ç½®æ–‡ä»¶", formatter)
        config_manager = ConfigManager()

        config_path = Path(args.config)
        if not config_path.exists():
            print(formatter.error(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {args.config}"))
            raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {args.config}")

        config = config_manager.load_config(str(config_path))

        # è¦†ç›–æ—¥æœŸå‚æ•°
        if args.start_date:
            config.setdefault('backtest', {})['start_date'] = args.start_date
        if args.end_date:
            config.setdefault('backtest', {})['end_date'] = args.end_date

        print(f"  {formatter.success('âœ… æ¨¡å‹è·¯å¾„')}: {formatter.path(args.model_path)}")
        print(f"  {formatter.success('âœ… é…ç½®æ–‡ä»¶')}: {formatter.path(args.config)}")
        print(f"  {formatter.info('è¾“å‡ºç›®å½•')}: {formatter.path(args.output_dir)}")

        backtest_start = config.get('backtest', {}).get('start_date')
        backtest_end = config.get('backtest', {}).get('end_date')
        print(f"  {formatter.info('å›æµ‹æœŸé—´')}: {formatter.number(backtest_start)} - {formatter.number(backtest_end)}")
        print()

        # è¿è¡Œå›æµ‹
        print_section("ğŸš€ æ‰§è¡Œå›æµ‹", formatter)
        print(f"  {formatter.info('æ­£åœ¨è¿è¡Œå›æµ‹åˆ†æ...')}")
        results = run_backtest(args.model_path, config)

        # ä¿å­˜ç»“æœ
        print_section("ğŸ’¾ ä¿å­˜å›æµ‹ç»“æœ", formatter)

        # ä¿å­˜JSONç»“æœï¼ˆç¡®ä¿æ‰€æœ‰æ•°å€¼éƒ½æ˜¯JSONå¯åºåˆ—åŒ–çš„ï¼‰
        def convert_to_json_serializable(obj):
            """é€’å½’è½¬æ¢å¯¹è±¡ä¸ºJSONå¯åºåˆ—åŒ–æ ¼å¼"""
            if isinstance(obj, dict):
                return {k: convert_to_json_serializable(v) for k, v in obj.items()}
            elif isinstance(obj, list):
                return [convert_to_json_serializable(item) for item in obj]
            elif isinstance(obj, (np.integer, np.int64, np.int32)):
                return int(obj)
            elif isinstance(obj, (np.floating, np.float64, np.float32)):
                return float(obj)
            elif isinstance(obj, np.ndarray):
                return obj.tolist()
            else:
                return obj

        json_results = {
            'metrics': results['metrics'],
            'backtest_period': results['backtest_period'],
            'portfolio_final_value': float(results['portfolio_values'].iloc[-1]),
            'portfolio_total_return': float((results['portfolio_values'].iloc[-1] / results['portfolio_values'].iloc[0]) - 1)
        }

        # è½¬æ¢ä¸ºJSONå¯åºåˆ—åŒ–æ ¼å¼
        json_results = convert_to_json_serializable(json_results)

        with open(output_dir / BACKTEST_CONFIG.RESULTS_JSON_FILENAME, 'w', encoding='utf-8') as f:
            json.dump(json_results, f, indent=2, ensure_ascii=False)

        # åˆ›å»ºå¯è§†åŒ–
        print(f"  {formatter.info('æ­£åœ¨ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...')}")
        fig = create_performance_visualization(results)
        fig.write_html(str(output_dir / BACKTEST_CONFIG.CHART_HTML_FILENAME))

        # è¾“å‡ºæ€§èƒ½æ‘˜è¦
        print_section("ğŸ“Š å›æµ‹ç»“æœæ‘˜è¦", formatter)
        main_benchmark = BACKTEST_CONFIG.DEFAULT_BENCHMARK_SYMBOLS[0]

        if main_benchmark in results['metrics']:
            metrics = results['metrics'][main_benchmark]

            # æ ¸å¿ƒæ€§èƒ½æŒ‡æ ‡
            annual_return = metrics['annual_return'] * 100
            benchmark_return = metrics['benchmark_annual_return'] * 100
            excess_return = annual_return - benchmark_return

            print(f"  {formatter.info('æŠ•èµ„ç»„åˆå¹´åŒ–æ”¶ç›Šç‡')}: {formatter.success(f'{annual_return:+7.2f}%') if annual_return > 0 else formatter.error(f'{annual_return:+7.2f}%')}")
            print(f"  {formatter.info('åŸºå‡†å¹´åŒ–æ”¶ç›Šç‡')}: {formatter.number(f'{benchmark_return:+7.2f}%')}")
            print(f"  {formatter.info('è¶…é¢æ”¶ç›Š')}: {formatter.success(f'{excess_return:+7.2f}%') if excess_return > 0 else formatter.error(f'{excess_return:+7.2f}%')}")
            print()

            # é£é™©æŒ‡æ ‡
            sharpe = metrics['sharpe_ratio']
            max_dd = metrics['max_drawdown'] * 100
            info_ratio = metrics['information_ratio']

            print(f"  {formatter.info('å¤æ™®æ¯”ç‡')}: {formatter.success(f'{sharpe:7.3f}') if sharpe > 1 else formatter.warning(f'{sharpe:7.3f}')}")
            print(f"  {formatter.info('æœ€å¤§å›æ’¤')}: {formatter.error(f'{max_dd:7.2f}%') if max_dd > 10 else formatter.warning(f'{max_dd:7.2f}%')}")
            print(f"  {formatter.info('ä¿¡æ¯æ¯”ç‡')}: {formatter.success(f'{info_ratio:7.3f}') if info_ratio > 0.5 else formatter.number(f'{info_ratio:7.3f}')}")
            print()

            # é¢å¤–æŒ‡æ ‡
            alpha = metrics['alpha'] * 100
            beta = metrics['beta']
            print(f"  {formatter.info('Alpha')}: {formatter.success(f'{alpha:+7.2f}%') if alpha > 0 else formatter.number(f'{alpha:+7.2f}%')}")
            print(f"  {formatter.info('Beta')}: {formatter.number(f'{beta:7.3f}')}")

        # é£é™©åˆ†ææ‘˜è¦
        if 'risk_metrics' in results and results['risk_metrics']['summary']:
            risk_summary = results['risk_metrics']['summary']
            print()
            print(f"  {formatter.info('é£é™©è¿è§„æ¬¡æ•°')}: {formatter.warning(str(risk_summary.get('total_violations', 0)))}")
            avg_concentration = risk_summary.get('avg_concentration', 0)
            print(f"  {formatter.info('å¹³å‡é›†ä¸­åº¦')}: {formatter.number(f'{avg_concentration:.3f}')}")
            
        enable_drawdown_control = config.get("drawdown_control", {}).get("enable", False)
        # å›æ’¤æ§åˆ¶æ‘˜è¦
        if enable_drawdown_control:
            print()
            print(f"  {formatter.success('ğŸ›¡ï¸  å›æ’¤æ§åˆ¶å·²å¯ç”¨')}")
            # drawdown_control_config = config.get("drawdown_control", {})
            # if drawdown_control_config:
            #     print(f"  {formatter.info('å›æ’¤æ§åˆ¶é˜ˆå€¼')}: {formatter.number(f'{drawdown_control_config.max_drawdown_threshold:.1%}')}")
            #     print(f"  {formatter.info('å›æ’¤è­¦å‘Šé˜ˆå€¼')}: {formatter.number(f'{drawdown_control_config.drawdown_warning_threshold:.1%}')}")
        else:
            print()
            print(f"  {formatter.warning('âš ï¸  å›æ’¤æ§åˆ¶æœªå¯ç”¨')}")

        print()
        print(formatter.success(f"ğŸ‰ å›æµ‹å®Œæˆï¼ç»“æœå·²ä¿å­˜åˆ°: {formatter.path(str(output_dir))}"))
        print()
        print(f"  {formatter.info('ğŸ“Š æ•°æ®æ–‡ä»¶')}: {formatter.path(str(output_dir / BACKTEST_CONFIG.RESULTS_JSON_FILENAME))}")
        print(f"  {formatter.info('ğŸ“ˆ å¯è§†åŒ–å›¾è¡¨')}: {formatter.path(str(output_dir / BACKTEST_CONFIG.CHART_HTML_FILENAME))}")

    except Exception as e:
        logger.error(f"å›æµ‹è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        logger.exception("è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
        sys.exit(1)


if __name__ == "__main__":
    main()