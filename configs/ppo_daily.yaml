# PPO算法日线数据配置文件
# 适用于中长期投资策略，使用日线数据进行训练
# 基于fix.md分析报告的优化改进

# 数据配置
data:
  data_root: "/Users/shuzhenyi/.qlib/qlib_data"
  provider_uri:
    1min: "/Users/shuzhenyi/.qlib/qlib_data/cn_data_1min"
    day: "/Users/shuzhenyi/.qlib/qlib_data/cn_data"
  market: "csi300"
  stock_limit: 50
  # 可选：自定义股票池（如果指定则优先使用，否则使用market参数）
  custom_stocks: ["sh600919", "sh601288", "sh600036"]
  start_time: "2020-01-01"
  end_time: "2023-12-31"
  train_start: "2020-01-01"
  train_end: "2022-12-31"
  valid_start: "2023-01-01"
  valid_end: "2023-06-30"
  test_start: "2023-07-01"
  test_end: "2023-12-31"
  freq: "day"
  fields:
    - "$close"
    - "$open"
    - "$high"
    - "$low"
    - "$volume"
    - "$change"
    - "$factor"

# 环境配置
environment:
  initial_cash: 1000000
  lookback_window: 30  # 30天历史窗口
  transaction_cost: 0.001           # 降低交易成本到0.1%，避免过度惩罚
  max_drawdown_threshold: 0.20    # 环境内回撤阈值，允许更大的探索空间
  reward_penalty: 6.0              # 增强回撤惩罚力度
  features:
    - "$close"
    - "$open"
    - "$high"
    - "$low"
    - "$volume"
    - "$change"
    - "$factor"
  rebalance_freq: "daily"
  max_steps: 240                   # 确保episode足够长（约1年日频数据）

# 模型配置
model:
  algorithm: "PPO"
  learning_rate: 0.0003           # 恢复合理的学习率（不再人为放大）
  batch_size: 256
  gamma: 0.99
  n_steps: 2048  # PPO特有参数
  n_epochs: 10
  clip_range: 0.2
  ent_coef: 0.01  # 熵系数，鼓励探索，抑制过度确定性
  vf_coef: 0.5    # 价值函数损失系数
  max_grad_norm: 0.5  # 梯度裁剪
  use_custom_policy: false
  net_arch: [256, 256]             # 增加网络复杂度

# 训练配置
training:
  total_timesteps: 500000       # 增加到50万步，确保充分训练
  n_envs: 4
  seed: 42
  log_interval: 10

# 回调配置
callbacks:
  enable_eval: true
  eval_freq: 10000
  n_eval_episodes: 3               # 减少评估episode数以提高效率
  enable_checkpoint: true
  save_freq: 50000
  enable_drawdown_stopping: true
  max_training_drawdown: 0.20      # 重新设计后的回撤阈值
  drawdown_base_patience: 100      # 基础耐心值，支持动态调整
  drawdown_warmup_steps: 50000     # 预热期缩短到5万步
  enable_tensorboard: true
  enable_training_metrics: true
  metrics_log_interval: 1000       # 每1000步输出基础指标
  metrics_eval_interval: 5000      # 更频繁的详细评估

# 评估配置
evaluation:
  n_episodes: 5

# 日志配置
log_level: "INFO"

# 风险控制
risk_control:
  max_position_ratio: 0.15
  stop_loss_ratio: 0.08
  take_profit_ratio: 0.15
  volatility_limit: 0.03

# 特征工程配置
feature_engineering:
  enable_technical_indicators: true
  indicators:
    - "MA_5"    # 5日移动平均
    - "MA_10"   # 10日移动平均
    - "MA_20"   # 20日移动平均
    - "RSI_14"  # 14日RSI
    - "MACD"    # MACD指标
    - "BOLL"    # 布林带
  enable_factor_processing: true
  normalization: "zscore"  # 标准化方法
  handle_missing: "ffill"  # 缺失值处理

# 分层RL配置
experts:
  n_experts: 4              # 专家数量
  skill_dim: 10             # 技能向量维度
  buffer_size: 1000000      # 每个专家的经验池大小
  learning_rate: 0.0003     # 专家学习率
  mi_reward_weight: 0.5     # DIAYN互信息奖励权重

meta_router:
  kl_lambda: 0.1           # KL散度多样性奖励权重
  n_steps: 1024            # PPO步数
  batch_size: 64           # 批大小
  gamma: 0.99              # 折扣因子
  gae_lambda: 0.95         # GAE lambda
  ent_coef: 0.01           # 熵系数
  learning_rate: 0.0003    # 元路由器学习率

shared_buffer:
  capacity: 2000000        # 共享经验池容量
  sequence_length: 32      # 序列长度
  compress_data: true      # 数据压缩

trainer:
  diversity_threshold: 0.25  # 多样性阈值
  training_schedule:
    expert_steps: 1000     # 专家训练步数
    router_steps: 500      # 路由器训练步数
    buffer_update_freq: 100 # 经验池更新频率