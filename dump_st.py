#!/usr/bin/env python3
"""
Aè‚¡è‚¡ç¥¨ä¿¡æ¯è·å–å·¥å…· - å¤šæ ¸ä¼˜åŒ–ç‰ˆ
=====================================

åŠŸèƒ½æ¦‚è¿°ï¼š
---------
ä»AKShareæ•°æ®æºè·å–Aè‚¡å¸‚åœºæ‰€æœ‰è‚¡ç¥¨çš„åŸºæœ¬ä¿¡æ¯ã€è¡Œä¸šåˆ†ç±»å’Œè´¢åŠ¡æ•°æ®ï¼Œ
æ”¯æŒå¤šçº¿ç¨‹å¹¶è¡Œå¤„ç†ä»¥æå‡å¤§è§„æ¨¡æ•°æ®è·å–æ•ˆç‡ï¼Œå¹¶å°†ç»“æœä¿å­˜ä¸ºJSONæ ¼å¼ã€‚

ä¸»è¦ç‰¹æ€§ï¼š
---------
1. å…¨é¢æ•°æ®è¦†ç›–ï¼šåŸºæœ¬ä¿¡æ¯ + è¡Œä¸šåˆ†ç±» + å¸‚å€¼è´¢åŠ¡æ•°æ®
2. æ™ºèƒ½å¤šçº¿ç¨‹å¹¶è¡Œå¤„ç†ï¼šæ ¹æ®è‚¡ç¥¨æ•°é‡è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜å¤„ç†æ¨¡å¼
3. ç¨³å¥çš„é”™è¯¯å¤„ç†ï¼šå•è‚¡ç¥¨å¤±è´¥ä¸å½±å“æ•´ä½“ï¼Œæ”¯æŒè‡ªåŠ¨å›é€€
4. APIé™åˆ¶ä¿æŠ¤ï¼šå†…ç½®é¢‘ç‡æ§åˆ¶å’Œå¹¶å‘é™åˆ¶
5. é…ç½®åŒ–è®¾è®¡ï¼šæ”¯æŒçµæ´»çš„å‚æ•°è°ƒæ•´
6. è¯¦ç»†ç»Ÿè®¡æŠ¥å‘Šï¼šåŒ…å«å¸‚å€¼åˆ†å±‚ã€è¡Œä¸šåˆ†å¸ƒç­‰åˆ†æ

è¾“å‡ºJSONå­—æ®µè¯´æ˜ï¼š
=================

åŸºæœ¬ä¿¡æ¯å­—æ®µï¼š
-------------
- code (str): è‚¡ç¥¨ä»£ç ï¼Œ6ä½æ•°å­—æ ¼å¼ (å¦‚: "000001")
- name (str): è‚¡ç¥¨ç®€ç§° (å¦‚: "å¹³å®‰é“¶è¡Œ")
- exchange (str): äº¤æ˜“æ‰€ä»£ç 
  * "sh": ä¸Šæµ·è¯åˆ¸äº¤æ˜“æ‰€ (6å¼€å¤´)
  * "sz": æ·±åœ³è¯åˆ¸äº¤æ˜“æ‰€ (0,3å¼€å¤´)
  * "bj": åŒ—äº¬è¯åˆ¸äº¤æ˜“æ‰€ (8,4å¼€å¤´)

çŠ¶æ€æ ‡è¯†å­—æ®µï¼š
-------------
- is_st (bool): æ˜¯å¦ä¸ºSTè‚¡ç¥¨ (Special Treatment)
- is_star_st (bool): æ˜¯å¦ä¸º*STè‚¡ç¥¨ (é€€å¸‚é£é™©è­¦ç¤º)
- is_xd (bool): æ˜¯å¦ä¸ºXDè‚¡ç¥¨ (é™¤æ¯æ—¥)
- is_xr (bool): æ˜¯å¦ä¸ºXRè‚¡ç¥¨ (é™¤æƒæ—¥)
- is_dr (bool): æ˜¯å¦ä¸ºDRè‚¡ç¥¨ (é™¤æƒé™¤æ¯æ—¥)
- is_suspended (bool): æ˜¯å¦åœç‰Œ
- is_new (bool): æ˜¯å¦ä¸ºæ–°è‚¡

è¡Œä¸šåˆ†ç±»å­—æ®µï¼š
-------------
- industry (str): è¡Œä¸šåç§° (å¦‚: "é“¶è¡Œ", "è®¡ç®—æœºè®¾å¤‡")
- industry_code (str): è¡Œä¸šä»£ç  (å¦‚: "BK0475")
- industry_type (str): è¡Œä¸šåˆ†ç±»ç±»å‹
  * "sw": ç”³ä¸‡è¡Œä¸šåˆ†ç±» (æ¨è)
  * "concept": æ¦‚å¿µæ¿å—åˆ†ç±»
  * "unknown": æœªåˆ†ç±»

äº¤æ˜“æ•°æ®å­—æ®µï¼š
-------------
- close_price (float): æ”¶ç›˜ä»· (å…ƒ)
- volume (float): æˆäº¤é‡ (è‚¡)
- turnover (float): æˆäº¤é¢ (å…ƒ)

å¸‚å€¼è´¢åŠ¡å­—æ®µï¼š
-------------
- total_market_cap (float): æ€»å¸‚å€¼ (ä¸‡å…ƒ)
- float_market_cap (float): æµé€šå¸‚å€¼ (ä¸‡å…ƒ)
- pe_ratio (float): å¸‚ç›ˆç‡ (å€)
- pb_ratio (float): å¸‚å‡€ç‡ (å€)
- total_shares (float): æ€»è‚¡æœ¬ (è‚¡)
- float_shares (float): æµé€šè‚¡æœ¬ (è‚¡)
- ln_market_cap (float): å¯¹æ•°å¸‚å€¼ (ç”¨äºå› å­ä¸­æ€§åŒ–)
- listing_date (str): ä¸Šå¸‚æ—¥æœŸ (YYYY-MM-DDæ ¼å¼ï¼Œä¼˜å…ˆä»qlibæœ¬åœ°æ•°æ®è·å–æœ€æ—©å¯ç”¨æ—¥æœŸ)

è¾…åŠ©å­—æ®µï¼š
---------
- estimated_market_cap (float): ä¼°ç®—å¸‚å€¼ (ä¸‡å…ƒï¼Œå½“æ— æ³•è·å–å‡†ç¡®å¸‚å€¼æ—¶ä½¿ç”¨)
- data_date (str): æ•°æ®æ—¥æœŸ (YYYY-MM-DDæ ¼å¼)
- data_quality (str): æ•°æ®è·å–è´¨é‡æ ‡è¯†
  * "success": æ•°æ®è·å–æˆåŠŸï¼Œæ‰€æœ‰å­—æ®µå®Œæ•´
  * "partial": æ•°æ®éƒ¨åˆ†è·å–æˆåŠŸï¼Œå­˜åœ¨ç©ºå­—æ®µ
  * "retry_success": ç»è¿‡é‡è¯•åè·å–æˆåŠŸ
  * "failed": æ•°æ®è·å–å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼

ä½¿ç”¨ç¤ºä¾‹ï¼š
=========
```python
# ç›´æ¥è¿è¡Œè„šæœ¬
python dump_st.py

# æˆ–åœ¨ä»£ç ä¸­è°ƒç”¨
from dump_st import get_all_stocks_with_akshare_and_save
get_all_stocks_with_akshare_and_save()
```

æ€§èƒ½ç‰¹æ€§ï¼š
=========
- å¤šçº¿ç¨‹å¹¶è¡Œå¤„ç†ï¼šç›¸æ¯”å•çº¿ç¨‹æå‡çº¦4å€æ€§èƒ½
- æ™ºèƒ½é˜ˆå€¼æ§åˆ¶ï¼šè¶…è¿‡10åªè‚¡ç¥¨è‡ªåŠ¨å¯ç”¨å¹¶è¡Œæ¨¡å¼
- APIä¿æŠ¤æœºåˆ¶ï¼šé™åˆ¶å¹¶å‘æ•°é¿å…è¢«é™åˆ¶è®¿é—®
- å†…å­˜ä¼˜åŒ–ï¼šåˆ†æ‰¹å¤„ç†é¿å…å†…å­˜å ç”¨è¿‡å¤§

é…ç½®å‚æ•°ï¼š
=========
é€šè¿‡ä¿®æ”¹ PARALLEL_PROCESSING_CONFIG è°ƒæ•´å¤„ç†è¡Œä¸ºï¼š
- enable_parallel: æ˜¯å¦å¯ç”¨å¹¶è¡Œå¤„ç†
- parallel_threshold: å¹¶è¡Œå¤„ç†çš„è‚¡ç¥¨æ•°é‡é˜ˆå€¼
- max_workers: æœ€å¤§å·¥ä½œçº¿ç¨‹æ•°
- max_stocks_limit: æœ€å¤§å¤„ç†è‚¡ç¥¨æ•°é‡é™åˆ¶
- single_thread_batch_size: å•çº¿ç¨‹æ‰¹å¤„ç†å¤§å°

JSONæ•°æ®ç»“æ„ç¤ºä¾‹ï¼š
================
```json
[
  {
    "code": "000001",
    "name": "å¹³å®‰é“¶è¡Œ",
    "exchange": "sz",
    "is_st": false,
    "is_star_st": false,
    "is_xd": false,
    "is_xr": false,
    "is_dr": false,
    "is_suspended": false,
    "is_new": false,
    "industry": "é“¶è¡Œ",
    "industry_code": "BK0475",
    "industry_type": "sw",
    "close_price": 12.08,
    "volume": 0,
    "turnover": 0,
    "total_market_cap": 23442349.2,
    "float_market_cap": 23441930.8,
    "pe_ratio": 0.0,
    "pb_ratio": 0.0,
    "total_shares": 19405918198.0,
    "float_shares": 19405571850.0,
    "estimated_market_cap": 0,
    "ln_market_cap": 16.97,
    "listing_date": "2000-04-27",
    "data_date": "2024-08-15",
    "data_quality": "success"
  }
]
```

æ•°æ®è´¨é‡è¯´æ˜ï¼š
=============
- åŸºæœ¬ä¿¡æ¯å®Œæ•´ç‡ï¼šæ¥è¿‘100% (æ¥æºç¨³å®š)
- è¡Œä¸šåˆ†ç±»å®Œæ•´ç‡ï¼š80-90% (ä¼˜å…ˆç”³ä¸‡åˆ†ç±»)
- å¸‚å€¼æ•°æ®å®Œæ•´ç‡ï¼š60-80% (ä¾èµ–APIå¯ç”¨æ€§)
- çŠ¶æ€æ ‡è¯†å‡†ç¡®ç‡ï¼š95%+ (åŸºäºè‚¡ç¥¨åç§°åˆ†æ)

æ€§èƒ½æŒ‡æ ‡ï¼š
=========
- å¤„ç†é€Ÿåº¦ï¼šå•çº¿ç¨‹ ~1åª/ç§’ï¼Œå¤šçº¿ç¨‹ ~4åª/ç§’
- å†…å­˜å ç”¨ï¼šçº¦100MB (5000åªè‚¡ç¥¨)
- APIè°ƒç”¨ï¼šæ¯åªè‚¡ç¥¨2-3æ¬¡è¯·æ±‚
- å»ºè®®æ‰¹æ¬¡ï¼š200åªè‚¡ç¥¨/æ‰¹æ¬¡ (é¿å…APIé™åˆ¶)

è¾“å‡ºæ–‡ä»¶ï¼š
=========
stocks_akshare.json - åŒ…å«æ‰€æœ‰è‚¡ç¥¨ä¿¡æ¯çš„JSONæ–‡ä»¶
æ ¼å¼ï¼šUTF-8ç¼–ç ï¼Œå¯ç›´æ¥è¢«pandasã€Excelç­‰å·¥å…·è¯»å–

ä½œè€…ï¼šClaude
ç‰ˆæœ¬ï¼šv2.0 å¤šæ ¸ä¼˜åŒ–ç‰ˆ
æ›´æ–°æ—¥æœŸï¼š2024-08-18
"""

import akshare as ak
import json
import re
import pandas as pd
import time
import numpy as np
import random
from datetime import datetime, timedelta
from multiprocessing import Pool, cpu_count
from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor, as_completed
import logging
import os
try:
    import qlib
    from qlib.data import D
    QLIB_AVAILABLE = True
except ImportError:
    QLIB_AVAILABLE = False

# ============ ä¸Šå¸‚æ—¥æœŸæ˜ å°„ä¸è§„èŒƒåŒ–å·¥å…· ============
LISTING_DATE_MAP = {}

# ============ Qlibç›¸å…³å·¥å…·å‡½æ•° ============
_QLIB_INITIALIZED = False

def _normalize_instrument_for_qlib(code: str) -> str:
    """è§„èŒƒè‚¡ç¥¨ä»£ç ä¸º Qlib æ ‡å‡†æ ¼å¼ï¼Œå¦‚ 600000->SH600000, 000001->SZ000001"""
    c = str(code).strip().zfill(6)
    if len(c) == 6 and c.isdigit():
        if c[0] == '6':
            return 'SH' + c
        elif c[0] in ('0', '3'):
            return 'SZ' + c
        elif c[0] in ('8', '4'):
            return 'BJ' + c
    return c

def _init_qlib_once(qlib_dir: str = "~/.qlib/qlib_data/cn_data"):
    """ä»…åˆå§‹åŒ–ä¸€æ¬¡ Qlib"""
    global _QLIB_INITIALIZED
    if _QLIB_INITIALIZED:
        return True

    qlib_dir_expanded = os.path.expanduser(qlib_dir)
    if not os.path.exists(qlib_dir_expanded):
        print(f"  âš ï¸ Qlibæ•°æ®ç›®å½•ä¸å­˜åœ¨äº '{qlib_dir_expanded}'ï¼Œè·³è¿‡qlibä¸Šå¸‚æ—¥æœŸè·å–")
        return False

    qlib.init(provider_uri=qlib_dir_expanded, region="cn")
    _QLIB_INITIALIZED = True
    print(f"  âœ… Qlib åˆå§‹åŒ–æˆåŠŸï¼Œæ•°æ®è·¯å¾„: {qlib_dir_expanded}")
    return True

def get_earliest_available_date_from_qlib(stock_code: str, qlib_dir: str = "~/.qlib/qlib_data/cn_data") -> str:
    """
    ä»æœ¬åœ° qlib æ•°æ®è·å–è‚¡ç¥¨æœ€æ—©å¯ç”¨çš„äº¤æ˜“æ—¥æœŸä½œä¸ºä¸Šå¸‚æ—¥æœŸ

    Parameters:
    -----------
    stock_code : str
        è‚¡ç¥¨ä»£ç ï¼Œå¦‚ '600000' æˆ– '000001'
    qlib_dir : str
        qlib æ•°æ®ç›®å½•è·¯å¾„

    Returns:
    --------
    str : æœ€æ—©å¯ç”¨æ—¥æœŸçš„å­—ç¬¦ä¸²æ ¼å¼ 'YYYY-MM-DD'ï¼Œå¤±è´¥æ—¶è¿”å›ç©ºå­—ç¬¦ä¸²
    """
    if not QLIB_AVAILABLE:
        return ''

    if not _init_qlib_once(qlib_dir):
        return ''

    inst = _normalize_instrument_for_qlib(stock_code)

    # è·å–è‚¡ç¥¨çš„å†å²æ•°æ®ï¼Œåªå– $close å­—æ®µä»¥å‡å°‘ I/O
    df = D.features(
        instruments=[inst],
        fields=['$close'],
        start_time='1900-01-01',
        end_time=pd.Timestamp.today().strftime('%Y-%m-%d'),
        freq='day',
        disk_cache=0,
    )

    if df is None or df.empty:
        return ''

    # è·å–æœ€æ—©çš„å¯ç”¨æ—¥æœŸ
    # df æœ‰ MultiIndex: level 0 = instrument, level 1 = datetime
    earliest_ts = df.index.get_level_values('datetime').min()

    if pd.isna(earliest_ts):
        return ''

    earliest_date_str = pd.to_datetime(earliest_ts).strftime('%Y-%m-%d')
    return earliest_date_str

def build_qlib_listing_date_map(stock_codes: list, qlib_dir: str = "~/.qlib/qlib_data/cn_data"):
    """
    æ‰¹é‡ä» qlib æ•°æ®è·å–è‚¡ç¥¨ä¸Šå¸‚æ—¥æœŸæ˜ å°„

    Parameters:
    -----------
    stock_codes : list
        è‚¡ç¥¨ä»£ç åˆ—è¡¨
    qlib_dir : str
        qlib æ•°æ®ç›®å½•è·¯å¾„
    """
    global LISTING_DATE_MAP

    if not QLIB_AVAILABLE:
        print("  âš ï¸ qlib ä¸å¯ç”¨ï¼Œè·³è¿‡ä» qlib è·å–ä¸Šå¸‚æ—¥æœŸ")
        return

    if not _init_qlib_once(qlib_dir):
        return

    print(f"  ğŸ”„ æ­£åœ¨ä» qlib æ•°æ®è·å– {len(stock_codes)} åªè‚¡ç¥¨çš„ä¸Šå¸‚æ—¥æœŸ...")

    qlib_success_count = 0
    qlib_batch_size = 50  # åˆ†æ‰¹å¤„ç†é¿å…å†…å­˜é—®é¢˜

    # åˆ†æ‰¹å¤„ç†è‚¡ç¥¨ä»£ç 
    for i in range(0, len(stock_codes), qlib_batch_size):
        batch_codes = stock_codes[i:i + qlib_batch_size]

        for code in batch_codes:
            earliest_date = get_earliest_available_date_from_qlib(code, qlib_dir)
            if earliest_date:
                LISTING_DATE_MAP[code] = earliest_date
                qlib_success_count += 1

        # è¿›åº¦æç¤º
        processed = min(i + qlib_batch_size, len(stock_codes))
        if processed % 100 == 0 or processed == len(stock_codes):
            print(f"    å·²å¤„ç†: {processed}/{len(stock_codes)} ({processed/len(stock_codes)*100:.1f}%)")

    print(f"  âœ… ä» qlib æ•°æ®è·å–åˆ° {qlib_success_count} åªè‚¡ç¥¨çš„ä¸Šå¸‚æ—¥æœŸ")

def _normalize_to_yyyymmdd(date_str):
    """å°†å„ç§å¸¸è§æ—¥æœŸæ ¼å¼è§„èŒƒåŒ–ä¸º 'YYYY-MM-DD'ï¼›æ— æ³•è§£æè¿”å›ç©ºå­—ç¬¦ä¸²
    å…¼å®¹ï¼š
      - 'YYYY-MM-DD'ã€'YYYY/MM/DD'ã€'YYYYMMDD'
      - æ—¶é—´æˆ³ï¼ˆç§’çº§10ä½ / æ¯«ç§’çº§13ä½ï¼‰
      - æ··å…¥éæ•°å­—å­—ç¬¦ï¼Œè‡ªåŠ¨å‰”é™¤
    """
    s = str(date_str).strip()
    digits = "".join(ch for ch in s if ch.isdigit())
    if len(digits) == 13:  # æ¯«ç§’
        ts = int(digits) / 1000.0
        return datetime.utcfromtimestamp(ts).strftime("%Y-%m-%d")
    if len(digits) == 10:  # ç§’
        ts = int(digits)
        return datetime.utcfromtimestamp(ts).strftime("%Y-%m-%d")
    if len(digits) == 8:   # YYYYMMDD
        return datetime.strptime(digits, "%Y%m%d").strftime("%Y-%m-%d")

    dt = pd.to_datetime(s, errors="coerce")
    if pd.isna(dt):
        return ""
    return dt.strftime("%Y-%m-%d")

def build_listing_date_map():
    """
    æ„å»º Aè‚¡ code -> ä¸Šå¸‚æ—¥æœŸ çš„å…¨é‡æ˜ å°„ï¼š
      1) ä¼˜å…ˆä½¿ç”¨äº¤æ˜“æ‰€è‚¡ç¥¨åˆ—è¡¨æ¥å£ï¼ˆå«ä¸Šå¸‚æ—¥æœŸï¼‰
         - ak.stock_info_sh_name_code()  # ä¸Šæµ·äº¤æ˜“æ‰€
         - ak.stock_info_sz_name_code()  # æ·±åœ³äº¤æ˜“æ‰€
      2) å…œåº•ï¼šé€è‚¡ä¿¡æ¯æ—¶å†ä» stock_individual_info_em è§£æ
    """
    global LISTING_DATE_MAP
    LISTING_DATE_MAP = {}

    def _add_from_df(df):
        if df is None or df.empty:
            return 0
        code_candidates = [c for c in df.columns if ("ä»£ç " in str(c)) or (str(c).lower() in {"code", "sec_code"})]
        date_candidates = [c for c in df.columns if ("ä¸Šå¸‚" in str(c)) and (("æ—¥æœŸ" in str(c)) or ("æ—¶é—´" in str(c)))]
        if not code_candidates or not date_candidates:
            return 0
        code_col, date_col = code_candidates[0], date_candidates[0]
        added = 0
        for _, row in df[[code_col, date_col]].iterrows():
            raw_code = str(row.get(code_col, "")).strip()
            if not raw_code:
                continue
            code_digits = "".join(ch for ch in raw_code if ch.isdigit())
            if not code_digits:
                continue
            code = code_digits[-6:].zfill(6)
            ld = _normalize_to_yyyymmdd(row.get(date_col, ""))
            if ld:
                LISTING_DATE_MAP[code] = ld
                added += 1
        return added

    total_added = 0

    # ä¸Šæµ·äº¤æ˜“æ‰€è‚¡ç¥¨åˆ—è¡¨
    try:
        df = ak.stock_info_sh_name_code()
        added = _add_from_df(df)
        total_added += added
        print(f"    ä¸Šæµ·äº¤æ˜“æ‰€: æˆåŠŸè·å– {added} æ¡è®°å½•")
    except Exception as e:
        print(f"    ä¸Šæµ·äº¤æ˜“æ‰€å¤±è´¥: {e}")

    # æ·±åœ³äº¤æ˜“æ‰€è‚¡ç¥¨åˆ—è¡¨
    try:
        df = ak.stock_info_sz_name_code()
        added = _add_from_df(df)
        total_added += added
        print(f"    æ·±åœ³äº¤æ˜“æ‰€: æˆåŠŸè·å– {added} æ¡è®°å½•")
    except Exception as e:
        print(f"    æ·±åœ³äº¤æ˜“æ‰€å¤±è´¥: {e}")

    print(f"  âœ… å·²ä»äº¤æ˜“æ‰€è‚¡ç¥¨åˆ—è¡¨æ„å»ºä¸Šå¸‚æ—¥æœŸæ˜ å°„ï¼š{len(LISTING_DATE_MAP)} æ¡ï¼ˆæœ¬è½®æ–°å¢ {total_added} æ¡ï¼‰")

def _build_listing_date_map_from_spot_df(spot_df):
    """ä»å®æ—¶è¡Œæƒ…æ•°æ®ä¸­å°è¯•æå–ä¸Šå¸‚æ—¥æœŸä¿¡æ¯ï¼ˆå¦‚æœåŒ…å«è¯¥å­—æ®µï¼‰"""
    global LISTING_DATE_MAP

    # å¯»æ‰¾å¯èƒ½çš„ä¸Šå¸‚æ—¥æœŸå­—æ®µ
    date_candidates = [c for c in spot_df.columns if ('ä¸Šå¸‚' in str(c)) and (('æ—¥æœŸ' in str(c)) or ('æ—¶é—´' in str(c)))]
    code_candidates = [c for c in spot_df.columns if ('ä»£ç ' in str(c)) or (str(c).lower() in {'code', 'sec_code'})]

    if not date_candidates or not code_candidates:
        return 0  # æ²¡æœ‰æ‰¾åˆ°ç›¸å…³å­—æ®µ

    date_col = date_candidates[0]
    code_col = code_candidates[0]
    added = 0

    for _, row in spot_df[[code_col, date_col]].iterrows():
        raw_code = str(row.get(code_col, '')).strip()
        if not raw_code:
            continue

        # æ ‡å‡†åŒ–ä»£ç æ ¼å¼
        code_digits = ''.join(ch for ch in raw_code if ch.isdigit())
        if not code_digits:
            continue
        code = code_digits[-6:].zfill(6)

        # è§£ææ—¥æœŸ
        listing_date = _normalize_to_yyyymmdd(row.get(date_col, ''))
        if listing_date:
            LISTING_DATE_MAP[code] = listing_date
            added += 1

    return added

# ============ é…ç½®å‚æ•° ============
PARALLEL_PROCESSING_CONFIG = {
    'enable_parallel': True,        # æ˜¯å¦å¯ç”¨å¹¶è¡Œå¤„ç†
    'parallel_threshold': 10,       # è¶…è¿‡å¤šå°‘åªè‚¡ç¥¨æ‰å¯ç”¨å¹¶è¡Œå¤„ç†
    'max_workers': None,            # æœ€å¤§å·¥ä½œçº¿ç¨‹æ•°ï¼ŒNoneè¡¨ç¤ºè‡ªåŠ¨é€‰æ‹©
    'single_thread_batch_size': 20  # å•çº¿ç¨‹æ¨¡å¼çš„æ‰¹å¤„ç†å¤§å°
}

def analyze_stock_info(code, name):
    """
    åˆ†æè‚¡ç¥¨ä»£ç å’Œåç§°ï¼Œæå–äº¤æ˜“æ‰€å’ŒçŠ¶æ€ä¿¡æ¯
    """
    # ç¡®ä¿ä»£ç æ˜¯6ä½å­—ç¬¦ä¸²
    code = str(code).zfill(6)

    # åˆ¤æ–­äº¤æ˜“æ‰€
    if code.startswith('0') or code.startswith('3'):
        exchange = 'sz'  # æ·±äº¤æ‰€ (000xxx, 002xxx, 300xxx)
    elif code.startswith('6'):
        exchange = 'sh'  # ä¸Šäº¤æ‰€ (600xxx, 601xxx, 603xxx, 605xxx, 688xxx)
    elif code.startswith('8') or code.startswith('4'):
        exchange = 'bj'  # åŒ—äº¤æ‰€ (8xxxxx, 43xxxx, 83xxxx, 87xxxx)
    else:
        exchange = 'unknown'

    # åˆ†æè‚¡ç¥¨çŠ¶æ€æ ‡è¯†
    name_upper = name.upper()

    # STç›¸å…³
    is_st = bool(re.search(r'\*?ST', name_upper))
    is_star_st = bool(re.search(r'\*ST', name_upper))

    # XD, XR, DR (é™¤æƒé™¤æ¯ç›¸å…³)
    is_xd = 'XD' in name_upper  # é™¤æ¯
    is_xr = 'XR' in name_upper  # é™¤æƒ
    is_dr = 'DR' in name_upper  # é™¤æƒé™¤æ¯

    # å…¶ä»–æ ‡è¯†
    is_suspended = 'åœç‰Œ' in name or 'æš‚åœ' in name
    is_new = 'N' in name_upper and len([c for c in name if c.isalpha()]) <= 3  # æ–°è‚¡

    return {
        'exchange': exchange,
        'is_st': is_st,
        'is_star_st': is_star_st,
        'is_xd': is_xd,
        'is_xr': is_xr,
        'is_dr': is_dr,
        'is_suspended': is_suspended,
        'is_new': is_new
    }

def get_industry_info():
    """
    è·å–è‚¡ç¥¨è¡Œä¸šåˆ†ç±»ä¿¡æ¯

    æ•°æ®æ¥æºï¼š
    ---------
    1. ä¼˜å…ˆè·å–ç”³ä¸‡è¡Œä¸šåˆ†ç±» (industry_type='sw')
    2. å›é€€åˆ°æ¦‚å¿µæ¿å—åˆ†ç±» (industry_type='concept')

    è¿”å›å­—æ®µï¼š
    ---------
    - industry: è¡Œä¸šåç§°
    - industry_code: è¡Œä¸šä»£ç 
    - industry_type: åˆ†ç±»ç±»å‹ ('sw'/'concept'/'unknown')

    Returns:
    --------
    dict: è‚¡ç¥¨ä»£ç  -> è¡Œä¸šä¿¡æ¯çš„æ˜ å°„å­—å…¸
    """
    industry_mapping = {}

    try:
        print("  æ­£åœ¨è·å–è¡Œä¸šåˆ†ç±»ä¿¡æ¯...")

        # æ–¹æ³•1: è·å–ç”³ä¸‡è¡Œä¸šåˆ†ç±»ï¼ˆæœ€å¸¸ç”¨ï¼‰
        try:
            print("    å°è¯•è·å–ç”³ä¸‡è¡Œä¸šåˆ†ç±»...")
            sw_industry = ak.stock_board_industry_name_em()
            if sw_industry is not None and not sw_industry.empty:
                print(f"    è·å–åˆ° {len(sw_industry)} ä¸ªè¡Œä¸šæ¿å—")

                # è·å–æ¯ä¸ªè¡Œä¸šçš„æˆåˆ†è‚¡
                for _, row in sw_industry.iterrows():
                    industry_name = row.get('æ¿å—åç§°', '')
                    if industry_name:
                        try:
                            # è·å–è¯¥è¡Œä¸šçš„æˆåˆ†è‚¡
                            industry_stocks = ak.stock_board_industry_cons_em(symbol=industry_name)
                            if industry_stocks is not None and not industry_stocks.empty:
                                for _, stock_row in industry_stocks.iterrows():
                                    stock_code = str(stock_row.get('ä»£ç ', '')).strip()
                                    if len(stock_code) == 6 and stock_code.isdigit():
                                        industry_mapping[stock_code] = {
                                            'industry': industry_name,
                                            'industry_code': row.get('æ¿å—ä»£ç ', ''),
                                            'industry_type': 'sw'  # ç”³ä¸‡åˆ†ç±»
                                        }
                            time.sleep(0.1)  # é¿å…è¯·æ±‚è¿‡å¿«
                        except Exception as e:
                            print(f"    è·å–è¡Œä¸š {industry_name} æˆåˆ†è‚¡å¤±è´¥: {e}")
                            continue

        except Exception as e:
            print(f"    ç”³ä¸‡è¡Œä¸šåˆ†ç±»è·å–å¤±è´¥: {e}")

        # æ–¹æ³•2: å¦‚æœç”³ä¸‡å¤±è´¥ï¼Œå°è¯•æ¦‚å¿µæ¿å—åˆ†ç±»
        if not industry_mapping:
            try:
                print("    å°è¯•è·å–æ¦‚å¿µæ¿å—åˆ†ç±»...")
                concept_boards = ak.stock_board_concept_name_em()
                if concept_boards is not None and not concept_boards.empty:
                    print(f"    è·å–åˆ° {len(concept_boards)} ä¸ªæ¦‚å¿µæ¿å—")

                    # é€‰æ‹©éƒ¨åˆ†é‡è¦æ¦‚å¿µæ¿å—
                    for _, row in concept_boards.head(50).iterrows():  # é™åˆ¶æ•°é‡é¿å…è¿‡å¤šè¯·æ±‚
                        concept_name = row.get('æ¿å—åç§°', '')
                        if concept_name:
                            try:
                                concept_stocks = ak.stock_board_concept_cons_em(symbol=concept_name)
                                if concept_stocks is not None and not concept_stocks.empty:
                                    for _, stock_row in concept_stocks.iterrows():
                                        stock_code = str(stock_row.get('ä»£ç ', '')).strip()
                                        if len(stock_code) == 6 and stock_code.isdigit():
                                            # å¦‚æœè¿˜æ²¡æœ‰è¡Œä¸šåˆ†ç±»ï¼Œåˆ™ç”¨æ¦‚å¿µåˆ†ç±»
                                            if stock_code not in industry_mapping:
                                                industry_mapping[stock_code] = {
                                                    'industry': concept_name,
                                                    'industry_code': row.get('æ¿å—ä»£ç ', ''),
                                                    'industry_type': 'concept'  # æ¦‚å¿µåˆ†ç±»
                                                }
                                time.sleep(0.1)
                            except Exception as e:
                                print(f"    è·å–æ¦‚å¿µ {concept_name} æˆåˆ†è‚¡å¤±è´¥: {e}")
                                continue

            except Exception as e:
                print(f"    æ¦‚å¿µæ¿å—åˆ†ç±»è·å–å¤±è´¥: {e}")

        print(f"  âœ… è¡Œä¸šä¿¡æ¯è·å–å®Œæˆï¼Œè¦†ç›– {len(industry_mapping)} åªè‚¡ç¥¨")

    except Exception as e:
        print(f"  âŒ è¡Œä¸šä¿¡æ¯è·å–å¤±è´¥: {e}")

    return industry_mapping

def get_single_stock_market_cap(code):
    """
    è·å–å•åªè‚¡ç¥¨çš„å¸‚å€¼æ•°æ®ï¼ˆç”¨äºå¤šè¿›ç¨‹å¤„ç†ï¼‰

    Parameters:
    -----------
    code : str
        è‚¡ç¥¨ä»£ç 

    Returns:
    --------
    tuple : (code, market_data_dict) or (code, None)
    """
    # è·å–è‚¡ç¥¨è¯¦ç»†ä¿¡æ¯
    stock_info = ak.stock_individual_info_em(symbol=code)
    info_dict = dict(zip(stock_info['item'], stock_info['value']))

    # æå–å¸‚å€¼ç›¸å…³æ•°æ®
    total_market_cap_raw = info_dict.get('æ€»å¸‚å€¼', '0')
    float_market_cap_raw = info_dict.get('æµé€šå¸‚å€¼', '0')
    total_shares_raw = info_dict.get('æ€»è‚¡æœ¬', '0')
    float_shares_raw = info_dict.get('æµé€šè‚¡', '0')

    # æå–ä¸Šå¸‚æ—¥æœŸï¼Œå°è¯•å¤šç§å¯èƒ½çš„å­—æ®µå
    listing_date_raw = (
        info_dict.get('ä¸Šå¸‚æ—¶é—´', '') or
        info_dict.get('ä¸Šå¸‚æ—¥æœŸ', '') or
        info_dict.get('æŒ‚ç‰Œæ—¶é—´', '') or
        info_dict.get('æŒ‚ç‰Œæ—¥æœŸ', '')
    )

    # ä¼˜å…ˆä½¿ç”¨ qlib è·å–çš„ä¸Šå¸‚æ—¥æœŸï¼Œç„¶åä»ä¸ªè‚¡ä¿¡æ¯é‡Œè§£æï¼Œæœ€åå›é€€åˆ°å…¨å±€æ˜ å°„
    listing_date = ''
    # ç¬¬ä¸€ä¼˜å…ˆçº§ï¼šä» qlib è·å–çš„ä¸Šå¸‚æ—¥æœŸæ˜ å°„
    listing_date = LISTING_DATE_MAP.get(code, '')
    # ç¬¬äºŒä¼˜å…ˆçº§ï¼šä»ä¸ªè‚¡ä¿¡æ¯é‡Œè§£æä¸Šå¸‚æ—¥æœŸ
    if not listing_date:
        date_str = str(listing_date_raw).strip() if listing_date_raw is not None else ''
        listing_date = _normalize_to_yyyymmdd(date_str)

    # è§£ææ•°å€¼
    total_market_cap = _parse_market_value(str(total_market_cap_raw)) if total_market_cap_raw else 0
    float_market_cap = _parse_market_value(str(float_market_cap_raw)) if float_market_cap_raw else 0
    total_shares = _parse_numeric(str(total_shares_raw)) if total_shares_raw else 0
    float_shares = _parse_numeric(str(float_shares_raw)) if float_shares_raw else 0

    # å¦‚æœå¸‚å€¼æ•°æ®æ˜¯ç›´æ¥çš„æ•°å€¼ï¼ˆå…ƒä¸ºå•ä½ï¼‰ï¼Œè½¬æ¢ä¸ºä¸‡å…ƒ
    if total_market_cap == 0 and isinstance(total_market_cap_raw, (int, float)) and total_market_cap_raw > 0:
        total_market_cap = total_market_cap_raw / 10000
    if float_market_cap == 0 and isinstance(float_market_cap_raw, (int, float)) and float_market_cap_raw > 0:
        float_market_cap = float_market_cap_raw / 10000

    # è®¡ç®—æ”¶ç›˜ä»·ï¼ˆå¦‚æœæœ‰è‚¡æœ¬å’Œå¸‚å€¼æ•°æ®ï¼‰
    close_price = 0
    if total_market_cap > 0 and total_shares > 0:
        close_price = (total_market_cap * 10000) / total_shares  # ä¸‡å…ƒè½¬å…ƒå†é™¤ä»¥è‚¡æœ¬

    # åˆ¤æ–­æ•°æ®è´¨é‡
    data_quality = "success"
    if total_market_cap == 0 and float_market_cap == 0 and total_shares == 0:
        data_quality = "failed"
    elif not listing_date or total_market_cap == 0:
        data_quality = "partial"

    market_data = {
        'close_price': close_price,
        'volume': 0,  # å®æ—¶æ•°æ®æ¥å£æœ‰é—®é¢˜ï¼Œå…ˆè®¾ä¸º0
        'turnover': 0,  # å®æ—¶æ•°æ®æ¥å£æœ‰é—®é¢˜ï¼Œå…ˆè®¾ä¸º0
        'total_market_cap': total_market_cap,
        'float_market_cap': float_market_cap,
        'pe_ratio': 0,  # éœ€è¦å•ç‹¬æ¥å£è·å–
        'pb_ratio': 0,  # éœ€è¦å•ç‹¬æ¥å£è·å–
        'total_shares': total_shares,
        'float_shares': float_shares,
        'estimated_market_cap': 0,
        'ln_market_cap': np.log1p(total_market_cap) if total_market_cap > 0 else 0,
        'listing_date': listing_date,  # ä¸Šå¸‚æ—¥æœŸ
        'data_date': '2024-08-15',
        'data_quality': data_quality
    }

    return (code, market_data)

    # time.sleep(0.1)  # è½»å¾®å»¶è¿Ÿé¿å…è¯·æ±‚è¿‡å¿«

def get_market_cap_data_parallel(stock_codes, max_workers=None):
    """
    ä½¿ç”¨å¤šçº¿ç¨‹å¹¶è¡Œè·å–è‚¡ç¥¨å¸‚å€¼æ•°æ®ï¼ˆæ€§èƒ½ä¼˜åŒ–ç‰ˆï¼‰

    åŠŸèƒ½ç‰¹æ€§ï¼š
    ---------
    - å¹¶è¡Œå¤„ç†ï¼šä½¿ç”¨ThreadPoolExecutorå®ç°å¤šçº¿ç¨‹å¤„ç†
    - è¿›åº¦ç›‘æ§ï¼šæ¯10åªè‚¡ç¥¨æ˜¾ç¤ºä¸€æ¬¡è¿›åº¦
    - é”™è¯¯æ¢å¤ï¼šå•è‚¡ç¥¨å¤±è´¥ä¸å½±å“æ•´ä½“ï¼Œè‡ªåŠ¨å›é€€æœºåˆ¶
    - APIä¿æŠ¤ï¼šå†…ç½®é¢‘ç‡æ§åˆ¶ï¼Œé¿å…è§¦åŠAPIé™åˆ¶
    - é‡è¯•æœºåˆ¶ï¼šå¤±è´¥çš„è‚¡ç¥¨ä¼šè‡ªåŠ¨åŠ å…¥é‡è¯•é˜Ÿåˆ—è¿›è¡Œé‡è¯•

    æ€§èƒ½è¡¨ç°ï¼š
    ---------
    - ç›¸æ¯”å•çº¿ç¨‹æå‡çº¦4å€é€Ÿåº¦
    - é€‚åˆå¤„ç†10åªä»¥ä¸Šè‚¡ç¥¨çš„åœºæ™¯
    - å†…å­˜å ç”¨ä½ï¼Œæ”¯æŒå¤§æ‰¹é‡å¤„ç†

    Parameters:
    -----------
    stock_codes : list[str]
        è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼Œæ”¯æŒ6ä½æ•°å­—æ ¼å¼
    max_workers : int, optional
        æœ€å¤§å·¥ä½œçº¿ç¨‹æ•°ï¼ŒNoneæ—¶è‡ªåŠ¨é€‰æ‹©min(CPUæ ¸å¿ƒæ•°, 8)

    Returns:
    --------
    dict: è‚¡ç¥¨ä»£ç  -> å¸‚å€¼è´¢åŠ¡æ•°æ®çš„æ˜ å°„å­—å…¸
        åŒ…å«total_market_cap, float_market_cap, pe_ratioç­‰å­—æ®µ

    Raises:
    -------
    Exception: å¹¶è¡Œå¤„ç†å¤±è´¥æ—¶è‡ªåŠ¨å›é€€åˆ°å•çº¿ç¨‹æ¨¡å¼
    """
    if max_workers is None:
        max_workers = min(cpu_count(), 8)  # é™åˆ¶æœ€å¤§8ä¸ªè¿›ç¨‹é¿å…APIé™åˆ¶

    print(f"  æ­£åœ¨ä½¿ç”¨ {max_workers} ä¸ªå·¥ä½œçº¿ç¨‹å¹¶è¡Œè·å– {len(stock_codes)} åªè‚¡ç¥¨çš„å¸‚å€¼æ•°æ®...")

    market_cap_data = {}
    retry_queue = []  # é‡è¯•é˜Ÿåˆ—

    try:
        # ä½¿ç”¨ThreadPoolExecutorè€Œä¸æ˜¯ProcessPoolExecutorï¼Œå› ä¸ºakshareå¯èƒ½æœ‰ç½‘ç»œI/Oä¾èµ–
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_code = {executor.submit(get_single_stock_market_cap, code): code for code in stock_codes}

            # æ”¶é›†ç»“æœ
            completed_count = 0
            failed_count = 0

            for future in as_completed(future_to_code):
                code = future_to_code[future]
                try:
                    result_code, market_data = future.result()
                    if market_data and market_data.get('total_market_cap', 0) > 0:
                        market_cap_data[result_code] = market_data
                        completed_count += 1
                        if completed_count % 10 == 0:  # æ¯10åªè‚¡ç¥¨æ‰“å°ä¸€æ¬¡è¿›åº¦
                            print(f"    å·²å®Œæˆ: {completed_count}/{len(stock_codes)} ({completed_count/len(stock_codes)*100:.1f}%)")
                    else:
                        # å³ä½¿æ•°æ®ä¸ºç©ºä¹Ÿè¦ä¿å­˜ï¼Œé¿å…åç»­å¤„ç†å‡ºé”™
                        market_cap_data[result_code] = market_data if market_data else {}
                        failed_count += 1

                except Exception as e:
                    print(f"    å¤„ç† {code} æ—¶å‘ç”Ÿé”™è¯¯: {e}")
                    # å°†å¤±è´¥çš„è‚¡ç¥¨åŠ å…¥é‡è¯•é˜Ÿåˆ—
                    retry_queue.append(code)
                    failed_count += 1

        print(f"  âœ… å¹¶è¡Œå¤„ç†å®Œæˆ: æˆåŠŸ {completed_count} åª, å¤±è´¥ {failed_count} åª")

        # å¤„ç†é‡è¯•é˜Ÿåˆ—
        if retry_queue:
            print(f"  ğŸ”„ å¼€å§‹é‡è¯• {len(retry_queue)} åªå¤±è´¥çš„è‚¡ç¥¨...")
            retry_count = 0
            max_retry_rounds = 10  # æœ€å¤§é‡è¯•è½®æ•°

            while retry_queue and retry_count < max_retry_rounds:
                retry_count += 1
                print(f"    ç¬¬ {retry_count} è½®é‡è¯•ï¼Œå‰©ä½™ {len(retry_queue)} åªè‚¡ç¥¨...")

                current_retry_queue = retry_queue.copy()
                retry_queue.clear()  # æ¸…ç©ºé‡è¯•é˜Ÿåˆ—ï¼Œå¤±è´¥çš„ä¼šé‡æ–°åŠ å…¥

                for i, code in enumerate(current_retry_queue):
                    try:
                        # éšæœºå»¶è¿Ÿ 0.5-2.0 ç§’é¿å…APIé™åˆ¶
                        time.sleep(random.uniform(0.5, 2.0))

                        result_code, market_data = get_single_stock_market_cap(code)
                        if market_data and market_data.get('total_market_cap', 0) > 0:
                            # æ ‡è®°ä¸ºé‡è¯•æˆåŠŸ
                            market_data['data_quality'] = 'retry_success'
                            market_cap_data[result_code] = market_data
                            print(f"      âœ… é‡è¯•æˆåŠŸ: {code}")
                        else:
                            market_cap_data[result_code] = market_data if market_data else {}
                            # å¦‚æœæ•°æ®ä»ç„¶ä¸ºç©ºï¼Œä¸å†é‡è¯•ï¼Œä½¿ç”¨é»˜è®¤å€¼
                            print(f"      âš ï¸ é‡è¯•è·å¾—ç©ºæ•°æ®: {code}")

                    except Exception as e:
                        print(f"      âŒ é‡è¯•å¤±è´¥: {code} - {e}")
                        # é‡æ–°åŠ å…¥é‡è¯•é˜Ÿåˆ—
                        retry_queue.append(code)

                if retry_queue:
                    success_this_round = len(current_retry_queue) - len(retry_queue)
                    print(f"    ç¬¬ {retry_count} è½®é‡è¯•ç»“æœ: æˆåŠŸ {success_this_round} åª, ä»éœ€é‡è¯• {len(retry_queue)} åª")
                else:
                    print(f"    ğŸ‰ ç¬¬ {retry_count} è½®é‡è¯•åæ‰€æœ‰è‚¡ç¥¨éƒ½æˆåŠŸäº†!")
                    break

            # ä¸ºæœ€ç»ˆå¤±è´¥çš„è‚¡ç¥¨è®¾ç½®é»˜è®¤æ•°æ®
            for code in retry_queue:
                market_cap_data[code] = {
                    'close_price': 0,
                    'volume': 0,
                    'turnover': 0,
                    'total_market_cap': 0,
                    'float_market_cap': 0,
                    'pe_ratio': 0,
                    'pb_ratio': 0,
                    'total_shares': 0,
                    'float_shares': 0,
                    'estimated_market_cap': 0,
                    'ln_market_cap': 0,
                    'listing_date': '',  # é»˜è®¤ç©ºå­—ç¬¦ä¸²
                    'data_date': '2024-08-15',
                    'data_quality': 'failed'
                }

            if retry_queue:
                print(f"  âš ï¸ ç»è¿‡ {max_retry_rounds} è½®é‡è¯•åï¼Œä»æœ‰ {len(retry_queue)} åªè‚¡ç¥¨è·å–å¤±è´¥ï¼Œå·²è®¾ç½®ä¸ºé»˜è®¤æ•°æ®")

    except Exception as e:
        print(f"  âŒ å¹¶è¡Œå¤„ç†å¤±è´¥: {e}")
        # å›é€€åˆ°å•çº¿ç¨‹å¤„ç†
        print("  å›é€€åˆ°å•çº¿ç¨‹å¤„ç†...")
        return get_market_cap_data(stock_codes, max_batch_size=50)

    return market_cap_data

def get_market_cap_data(stock_codes, max_batch_size=50):
    """
    è·å–è‚¡ç¥¨å¸‚å€¼å’Œç›¸å…³è´¢åŠ¡æ•°æ®

    Parameters:
    -----------
    stock_codes : list
        è‚¡ç¥¨ä»£ç åˆ—è¡¨
    max_batch_size : int
        æ‰¹é‡å¤„ç†å¤§å°ï¼Œé¿å…è¯·æ±‚è¿‡äºé¢‘ç¹

    Returns:
    --------
    dict : è‚¡ç¥¨ä»£ç åˆ°è´¢åŠ¡æ•°æ®çš„æ˜ å°„
    """
    market_cap_data = {}

    try:
        print(f"  æ­£åœ¨è·å– {len(stock_codes)} åªè‚¡ç¥¨çš„å¸‚å€¼æ•°æ®...")

        # åˆ†æ‰¹å¤„ç†è‚¡ç¥¨ä»£ç 
        batches = [stock_codes[i:i + max_batch_size] for i in range(0, len(stock_codes), max_batch_size)]

        for batch_idx, batch_codes in enumerate(batches):
            print(f"    å¤„ç†æ‰¹æ¬¡ {batch_idx + 1}/{len(batches)} ({len(batch_codes)} åªè‚¡ç¥¨)")

            for code in batch_codes:
                try:
                    # ç›´æ¥è·å–è‚¡ç¥¨è¯¦ç»†ä¿¡æ¯ï¼ˆåŒ…å«å¸‚å€¼æ•°æ®ï¼‰
                    stock_info = ak.stock_individual_info_em(symbol=code)
                    if stock_info is not None and not stock_info.empty:
                        info_dict = dict(zip(stock_info['item'], stock_info['value']))

                        # æå–å¸‚å€¼ç›¸å…³æ•°æ®
                        total_market_cap_raw = info_dict.get('æ€»å¸‚å€¼', '0')
                        float_market_cap_raw = info_dict.get('æµé€šå¸‚å€¼', '0')
                        total_shares_raw = info_dict.get('æ€»è‚¡æœ¬', '0')
                        float_shares_raw = info_dict.get('æµé€šè‚¡', '0')

                        # æå–ä¸Šå¸‚æ—¥æœŸï¼Œå°è¯•å¤šç§å¯èƒ½çš„å­—æ®µå
                        listing_date_raw = (
                            info_dict.get('ä¸Šå¸‚æ—¶é—´', '') or
                            info_dict.get('ä¸Šå¸‚æ—¥æœŸ', '') or
                            info_dict.get('æŒ‚ç‰Œæ—¶é—´', '') or
                            info_dict.get('æŒ‚ç‰Œæ—¥æœŸ', '')
                        )

                        # ä¼˜å…ˆä½¿ç”¨ qlib è·å–çš„ä¸Šå¸‚æ—¥æœŸï¼Œç„¶åä»ä¸ªè‚¡ä¿¡æ¯é‡Œè§£æï¼Œæœ€åå›é€€åˆ°å…¨å±€æ˜ å°„
                        listing_date = ''
                        # ç¬¬ä¸€ä¼˜å…ˆçº§ï¼šä» qlib è·å–çš„ä¸Šå¸‚æ—¥æœŸæ˜ å°„
                        listing_date = LISTING_DATE_MAP.get(code, '')
                        # ç¬¬äºŒä¼˜å…ˆçº§ï¼šä»ä¸ªè‚¡ä¿¡æ¯é‡Œè§£æä¸Šå¸‚æ—¥æœŸ
                        if not listing_date and listing_date_raw:
                            listing_date = _normalize_to_yyyymmdd(listing_date_raw)

                        # è§£ææ•°å€¼
                        total_market_cap = _parse_market_value(str(total_market_cap_raw)) if total_market_cap_raw else 0
                        float_market_cap = _parse_market_value(str(float_market_cap_raw)) if float_market_cap_raw else 0
                        total_shares = _parse_numeric(str(total_shares_raw)) if total_shares_raw else 0
                        float_shares = _parse_numeric(str(float_shares_raw)) if float_shares_raw else 0

                        # å¦‚æœå¸‚å€¼æ•°æ®æ˜¯ç›´æ¥çš„æ•°å€¼ï¼ˆå…ƒä¸ºå•ä½ï¼‰ï¼Œè½¬æ¢ä¸ºä¸‡å…ƒ
                        if total_market_cap == 0 and isinstance(total_market_cap_raw, (int, float)) and total_market_cap_raw > 0:
                            total_market_cap = total_market_cap_raw / 10000
                        if float_market_cap == 0 and isinstance(float_market_cap_raw, (int, float)) and float_market_cap_raw > 0:
                            float_market_cap = float_market_cap_raw / 10000

                        # è®¡ç®—æ”¶ç›˜ä»·ï¼ˆå¦‚æœæœ‰è‚¡æœ¬å’Œå¸‚å€¼æ•°æ®ï¼‰
                        close_price = 0
                        if total_market_cap > 0 and total_shares > 0:
                            close_price = (total_market_cap * 10000) / total_shares  # ä¸‡å…ƒè½¬å…ƒå†é™¤ä»¥è‚¡æœ¬

                        # åˆ¤æ–­æ•°æ®è´¨é‡
                        data_quality = "success"
                        if total_market_cap == 0 and float_market_cap == 0 and total_shares == 0:
                            data_quality = "failed"
                        elif not listing_date or total_market_cap == 0:
                            data_quality = "partial"

                        market_cap_data[code] = {
                            'close_price': close_price,
                            'volume': 0,  # å®æ—¶æ•°æ®æ¥å£æœ‰é—®é¢˜ï¼Œå…ˆè®¾ä¸º0
                            'turnover': 0,  # å®æ—¶æ•°æ®æ¥å£æœ‰é—®é¢˜ï¼Œå…ˆè®¾ä¸º0
                            'total_market_cap': total_market_cap,
                            'float_market_cap': float_market_cap,
                            'pe_ratio': 0,  # éœ€è¦å•ç‹¬æ¥å£è·å–
                            'pb_ratio': 0,  # éœ€è¦å•ç‹¬æ¥å£è·å–
                            'total_shares': total_shares,
                            'float_shares': float_shares,
                            'estimated_market_cap': 0,
                            'ln_market_cap': np.log1p(total_market_cap) if total_market_cap > 0 else 0,
                            'listing_date': listing_date,  # ä¸Šå¸‚æ—¥æœŸ
                            'data_date': '2024-08-15',
                            'data_quality': data_quality
                        }

                        print(f"      âœ… {code}: å¸‚å€¼={total_market_cap:.1f}ä¸‡, è‚¡ä»·â‰ˆ{close_price:.2f}")

                    time.sleep(0.2)  # é¿å…è¯·æ±‚è¿‡å¿«

                except Exception as e:
                    print(f"      è·å– {code} å¸‚å€¼æ•°æ®å¤±è´¥: {e}")
                    # è®¾ç½®é»˜è®¤å€¼
                    market_cap_data[code] = {
                        'close_price': 0,
                        'volume': 0,
                        'turnover': 0,
                        'total_market_cap': 0,
                        'float_market_cap': 0,
                        'pe_ratio': 0,
                        'pb_ratio': 0,
                        'total_shares': 0,
                        'float_shares': 0,
                        'estimated_market_cap': 0,
                        'ln_market_cap': 0,
                        'listing_date': '',  # é»˜è®¤ç©ºå­—ç¬¦ä¸²
                        'data_date': '2024-08-15',
                        'data_quality': 'failed'
                    }
                    continue

            print(f"    æ‰¹æ¬¡ {batch_idx + 1} å®Œæˆ")
            time.sleep(1)  # æ‰¹æ¬¡é—´ç­‰å¾…

        print(f"  âœ… å¸‚å€¼æ•°æ®è·å–å®Œæˆï¼Œè¦†ç›– {len(market_cap_data)} åªè‚¡ç¥¨")

    except Exception as e:
        print(f"  âŒ å¸‚å€¼æ•°æ®è·å–å¤±è´¥: {e}")

    return market_cap_data

def _parse_market_value(value_str):
    """
    è§£æå¸‚å€¼å­—ç¬¦ä¸²ï¼Œè½¬æ¢ä¸ºæ•°å€¼ï¼ˆå•ä½ï¼šä¸‡å…ƒï¼‰
    ä¾‹å¦‚ï¼š'1234.56äº¿' -> 12345600
    """
    if not value_str or value_str == '-':
        return 0

    try:
        # ç§»é™¤å¯èƒ½çš„ç¬¦å·å’Œç©ºæ ¼
        clean_str = str(value_str).replace(',', '').replace(' ', '').strip()

        # æå–æ•°å€¼éƒ¨åˆ†
        import re
        number_match = re.search(r'[\d.]+', clean_str)
        if number_match:
            number = float(number_match.group())

            # å¤„ç†å•ä½
            if 'äº¿' in clean_str:
                return number * 10000  # äº¿ -> ä¸‡
            elif 'ä¸‡' in clean_str:
                return number
            else:
                return number / 10000  # å‡è®¾åŸå§‹å•ä½æ˜¯å…ƒï¼Œè½¬æ¢ä¸ºä¸‡å…ƒ
    except:
        pass

    return 0

def _parse_numeric(value_str):
    """
    è§£ææ•°å€¼å­—ç¬¦ä¸²
    """
    if not value_str or value_str == '-':
        return 0

    try:
        # ç§»é™¤å¯èƒ½çš„ç¬¦å·å’Œç©ºæ ¼
        clean_str = str(value_str).replace(',', '').replace(' ', '').strip()

        # æå–æ•°å€¼éƒ¨åˆ†
        import re
        number_match = re.search(r'[\d.]+', clean_str)
        if number_match:
            return float(number_match.group())
    except:
        pass

    return 0

def get_all_stocks_with_akshare_and_save():
    """
    ä½¿ç”¨AKShareè·å–Aè‚¡å¸‚åœºæ‰€æœ‰è‚¡ç¥¨ä¿¡æ¯å¹¶ä¿å­˜ä¸ºJSONæ–‡ä»¶ã€‚
    åŒ…å«è‚¡ç¥¨ä»£ç ã€åç§°ã€äº¤æ˜“æ‰€ã€å„ç§çŠ¶æ€æ ‡è¯†ã€è¡Œä¸šåˆ†ç±»ä¿¡æ¯ä»¥åŠå¸‚å€¼ç­‰è´¢åŠ¡å‚æ•°ã€‚

    æ–°å¢å¸‚å€¼ç›¸å…³å­—æ®µï¼š
    - close_price: æ”¶ç›˜ä»·
    - volume: æˆäº¤é‡
    - turnover: æˆäº¤é¢
    - total_market_cap: æ€»å¸‚å€¼(ä¸‡å…ƒ)
    - float_market_cap: æµé€šå¸‚å€¼(ä¸‡å…ƒ)
    - pe_ratio: å¸‚ç›ˆç‡
    - pb_ratio: å¸‚å‡€ç‡
    - total_shares: æ€»è‚¡æœ¬
    - float_shares: æµé€šè‚¡æœ¬
    - ln_market_cap: å¯¹æ•°å¸‚å€¼
    - listing_date: ä¸Šå¸‚æ—¥æœŸï¼ˆä¼˜å…ˆä»qlibæœ¬åœ°æ•°æ®è·å–ï¼‰
    - data_quality: æ•°æ®è·å–è´¨é‡æ ‡è¯†

    æ€§èƒ½ä¼˜åŒ–ç‰¹æ€§ï¼š
    - æ™ºèƒ½å¤šçº¿ç¨‹å¹¶è¡Œå¤„ç†ï¼šè¶…è¿‡é˜ˆå€¼çš„è‚¡ç¥¨æ•°é‡è‡ªåŠ¨å¯ç”¨å¤šçº¿ç¨‹å¤„ç†
    - è‡ªé€‚åº”æ‰¹å¤„ç†ï¼šæ ¹æ®è‚¡ç¥¨æ•°é‡é€‰æ‹©æœ€ä¼˜å¤„ç†æ–¹å¼
    - é…ç½®çµæ´»ï¼šé€šè¿‡PARALLEL_PROCESSING_CONFIGè°ƒæ•´å¹¶è¡Œå‚æ•°
    - é”™è¯¯æ¢å¤ï¼šå¹¶è¡Œå¤„ç†å¤±è´¥æ—¶è‡ªåŠ¨å›é€€åˆ°å•çº¿ç¨‹æ¨¡å¼
    - APIé™åˆ¶ä¿æŠ¤ï¼šé™åˆ¶åŒæ—¶å¤„ç†çš„è‚¡ç¥¨æ•°é‡é¿å…APIé™åˆ¶
    """
    try:
        all_stocks_list = []

        print("æ­£åœ¨è·å–Aè‚¡è‚¡ç¥¨ä¿¡æ¯...")

        # ç¬¬ä¸€æ­¥ï¼šè·å–è¡Œä¸šåˆ†ç±»ä¿¡æ¯
        industry_mapping = get_industry_info()

        # ç¬¬äºŒæ­¥ï¼šè·å–è‚¡ç¥¨åŸºæœ¬åˆ—è¡¨ç”¨äºåç»­å¸‚å€¼æ•°æ®è·å–
        stock_codes_for_market_cap = []

        # å°è¯•å¤šç§æ–¹å¼è·å–Aè‚¡è‚¡ç¥¨ä¿¡æ¯
        a_stocks_df = None

        # æ–¹æ³•1: å°è¯•è·å–æ²ªæ·±è‚¡ç¥¨ä¿¡æ¯
        try:
            print("  å°è¯•æ–¹æ³•1: è·å–æ²ªæ·±Aè‚¡...")
            a_stocks_df = ak.stock_zh_a_spot_em()
            if a_stocks_df is not None and not a_stocks_df.empty:
                print(f"  æˆåŠŸè·å– {len(a_stocks_df)} åªè‚¡ç¥¨")
        except Exception as e:
            print(f"  æ–¹æ³•1å¤±è´¥: {e}")

        # æ–¹æ³•2: å¦‚æœæ–¹æ³•1å¤±è´¥ï¼Œå°è¯•å…¶ä»–æ¥å£
        if a_stocks_df is None or a_stocks_df.empty:
            try:
                print("  å°è¯•æ–¹æ³•2: è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯...")
                a_stocks_df = ak.stock_info_a_code_name()
            except Exception as e:
                print(f"  æ–¹æ³•2å¤±è´¥: {e}")

        # æ–¹æ³•3: å¦‚æœå‰é¢éƒ½å¤±è´¥ï¼Œå°è¯•åˆå¹¶æ²ªæ·±æ•°æ®
        if a_stocks_df is None or a_stocks_df.empty:
            try:
                print("  å°è¯•æ–¹æ³•3: åˆ†åˆ«è·å–æ²ªæ·±æ•°æ®...")
                # è·å–æ²ªå¸‚æ•°æ®
                sh_stocks = ak.stock_zh_a_spot_em()
                if sh_stocks is not None and not sh_stocks.empty:
                    a_stocks_df = sh_stocks
                    print(f"  è·å–åˆ° {len(a_stocks_df)} åªè‚¡ç¥¨æ•°æ®")
            except Exception as e:
                print(f"  æ–¹æ³•3å¤±è´¥: {e}")
                return
        if a_stocks_df is not None and not a_stocks_df.empty:
            print(f"åŸå§‹æ•°æ®åˆ—å: {list(a_stocks_df.columns)}")
            try:
                _build_listing_date_map_from_spot_df(a_stocks_df)
                print(f"  âœ… å·²ä»å®æ—¶è¡Œæƒ…è¡¨æå–ä¸Šå¸‚æ—¥æœŸæ˜ å°„ï¼š{len(LISTING_DATE_MAP)} æ¡")
            except Exception as e:
                print(f"  âš ï¸ ä¸Šå¸‚æ—¥æœŸæ˜ å°„æ„å»ºå¤±è´¥: {e}")

            # å¤„ç†åˆ—åæ˜ å°„
            code_col = None
            name_col = None
            for col in a_stocks_df.columns:
                if 'ä»£ç ' in col or 'code' in col.lower():
                    code_col = col
                if 'ç®€ç§°' in col or 'åç§°' in col or 'name' in col.lower():
                    name_col = col

            if code_col and name_col:
                for _, row in a_stocks_df.iterrows():
                    code = str(row[code_col]).strip()
                    name = str(row[name_col]).strip()

                    # ç¡®ä¿æ˜¯6ä½æœ‰æ•ˆä»£ç 
                    if len(code) == 6 and code.isdigit():
                        # æ”¶é›†è‚¡ç¥¨ä»£ç ç”¨äºå¸‚å€¼æ•°æ®è·å–
                        stock_codes_for_market_cap.append(code)

                        # åˆ†æè‚¡ç¥¨ä¿¡æ¯
                        stock_info = analyze_stock_info(code, name)

                        # è·å–è¡Œä¸šä¿¡æ¯
                        industry_info = industry_mapping.get(code, {})

                        stock_data = {
                            'code': code,
                            'name': name,
                            'exchange': stock_info['exchange'],
                            'is_st': stock_info['is_st'],
                            'is_star_st': stock_info['is_star_st'],
                            'is_xd': stock_info['is_xd'],
                            'is_xr': stock_info['is_xr'],
                            'is_dr': stock_info['is_dr'],
                            'is_suspended': stock_info['is_suspended'],
                            'is_new': stock_info['is_new'],
                            # è¡Œä¸šä¿¡æ¯å­—æ®µ
                            'industry': industry_info.get('industry', 'æœªåˆ†ç±»'),
                            'industry_code': industry_info.get('industry_code', ''),
                            'industry_type': industry_info.get('industry_type', 'unknown')
                        }

                        all_stocks_list.append(stock_data)

                print(f"âœ… Aè‚¡: {len(all_stocks_list)} åªè‚¡ç¥¨")

                # ç¬¬ä¸‰æ­¥ï¼šæ„å»ºåŸºç¡€ä¸Šå¸‚æ—¥æœŸæ˜ å°„ï¼ˆä»äº¤æ˜“æ‰€è‚¡ç¥¨åˆ—è¡¨ï¼‰
                print("\nğŸ”„ æ„å»ºåŸºç¡€ä¸Šå¸‚æ—¥æœŸæ˜ å°„...")
                build_listing_date_map()

                # ç¬¬å››æ­¥ï¼šä½¿ç”¨ qlib æ•°æ®è¡¥å……è‚¡ç¥¨ä¸Šå¸‚æ—¥æœŸ
                print("\nğŸ”„ ä½¿ç”¨ qlib æ•°æ®è·å–è‚¡ç¥¨ä¸Šå¸‚æ—¥æœŸ...")
                build_qlib_listing_date_map(stock_codes_for_market_cap)

                # ç¬¬äº”æ­¥ï¼šè·å–å¸‚å€¼å’Œè´¢åŠ¡æ•°æ®ï¼ˆæ™ºèƒ½é€‰æ‹©å¤„ç†æ¨¡å¼ï¼‰
                print("\nå¼€å§‹è·å–å¸‚å€¼å’Œè´¢åŠ¡æ•°æ®...")

                # æ ¹æ®é…ç½®å’Œè‚¡ç¥¨æ•°é‡å†³å®šå¤„ç†æ–¹å¼
                config = PARALLEL_PROCESSING_CONFIG
                stock_count = len(stock_codes_for_market_cap)
                use_parallel = (
                    config['enable_parallel'] and
                    stock_count > config['parallel_threshold']
                )

                if use_parallel:
                    print(f"  æ£€æµ‹åˆ° {stock_count} åªè‚¡ç¥¨ï¼Œå¯ç”¨å¤šçº¿ç¨‹å¹¶è¡Œå¤„ç†åŠ é€Ÿ...")
                    market_cap_mapping = get_market_cap_data_parallel(
                        stock_codes_for_market_cap,
                        max_workers=config['max_workers']
                    )
                else:
                    print(f"  è‚¡ç¥¨æ•°é‡è¾ƒå°‘({stock_count}åª)æˆ–å¹¶è¡Œå¤„ç†å·²ç¦ç”¨ï¼Œä½¿ç”¨å•çº¿ç¨‹å¤„ç†...")
                    market_cap_mapping = get_market_cap_data(
                        stock_codes_for_market_cap,
                        max_batch_size=config['single_thread_batch_size']
                    )

                # ç¬¬äº”æ­¥ï¼šå°†å¸‚å€¼æ•°æ®æ•´åˆåˆ°è‚¡ç¥¨ä¿¡æ¯ä¸­
                for stock_data in all_stocks_list:
                    code = stock_data['code']
                    market_data = market_cap_mapping.get(code, {})

                    # æ·»åŠ å¸‚å€¼å’Œè´¢åŠ¡å­—æ®µ
                    stock_data.update({
                        'close_price': market_data.get('close_price', 0),
                        'volume': market_data.get('volume', 0),
                        'turnover': market_data.get('turnover', 0),
                        'total_market_cap': market_data.get('total_market_cap', 0),
                        'float_market_cap': market_data.get('float_market_cap', 0),
                        'pe_ratio': market_data.get('pe_ratio', 0),
                        'pb_ratio': market_data.get('pb_ratio', 0),
                        'total_shares': market_data.get('total_shares', 0),
                        'float_shares': market_data.get('float_shares', 0),
                        'estimated_market_cap': market_data.get('estimated_market_cap', 0),
                        'ln_market_cap': market_data.get('ln_market_cap', 0),
                        'listing_date': market_data.get('listing_date', ''),  # ä¸Šå¸‚æ—¥æœŸ
                        'data_date': market_data.get('data_date', '2024-08-15'),
                        'data_quality': market_data.get('data_quality', 'failed')  # æ•°æ®è´¨é‡çŠ¶æ€
                    })

                print(f"âœ… å¸‚å€¼æ•°æ®æ•´åˆå®Œæˆ")
            else:
                print(f"âŒ æ— æ³•è¯†åˆ«åˆ—å: {list(a_stocks_df.columns)}")
                return

        if all_stocks_list:
            # ç»Ÿè®¡ä¿¡æ¯
            print(f"\nğŸ“Š æ•°æ®æ±‡æ€»:")
            print(f"  æ€»è®¡: {len(all_stocks_list)} åªè‚¡ç¥¨")

            # æŒ‰äº¤æ˜“æ‰€ç»Ÿè®¡
            exchange_stats = {}
            for stock in all_stocks_list:
                exchange = stock['exchange']
                exchange_stats[exchange] = exchange_stats.get(exchange, 0) + 1

            print(f"  äº¤æ˜“æ‰€åˆ†å¸ƒ:")
            for exchange, count in exchange_stats.items():
                print(f"    {exchange.upper()}: {count} åª")

            # æŒ‰çŠ¶æ€ç»Ÿè®¡
            st_count = sum(1 for s in all_stocks_list if s['is_st'])
            star_st_count = sum(1 for s in all_stocks_list if s['is_star_st'])
            xd_count = sum(1 for s in all_stocks_list if s['is_xd'])
            xr_count = sum(1 for s in all_stocks_list if s['is_xr'])
            dr_count = sum(1 for s in all_stocks_list if s['is_dr'])

            print(f"  çŠ¶æ€ç»Ÿè®¡:")
            print(f"    STè‚¡ç¥¨: {st_count} åª")
            print(f"    *STè‚¡ç¥¨: {star_st_count} åª")
            print(f"    é™¤æ¯(XD): {xd_count} åª")
            print(f"    é™¤æƒ(XR): {xr_count} åª")
            print(f"    é™¤æƒé™¤æ¯(DR): {dr_count} åª")

            # æŒ‰è¡Œä¸šç»Ÿè®¡ï¼ˆTop 10ï¼‰
            industry_stats = {}
            industry_type_stats = {}
            for stock in all_stocks_list:
                industry = stock.get('industry', 'æœªåˆ†ç±»')
                industry_type = stock.get('industry_type', 'unknown')
                industry_stats[industry] = industry_stats.get(industry, 0) + 1
                industry_type_stats[industry_type] = industry_type_stats.get(industry_type, 0) + 1

            print(f"  è¡Œä¸šåˆ†ç±»ç»Ÿè®¡:")
            print(f"    ç”³ä¸‡åˆ†ç±»: {industry_type_stats.get('sw', 0)} åª")
            print(f"    æ¦‚å¿µåˆ†ç±»: {industry_type_stats.get('concept', 0)} åª")
            print(f"    æœªåˆ†ç±»: {industry_type_stats.get('unknown', 0)} åª")

            print(f"  ä¸»è¦è¡Œä¸šåˆ†å¸ƒï¼ˆTop 10ï¼‰:")
            sorted_industries = sorted(industry_stats.items(), key=lambda x: x[1], reverse=True)
            for industry, count in sorted_industries[:10]:
                print(f"    {industry}: {count} åª")

            # æ•°æ®è´¨é‡ç»Ÿè®¡
            quality_stats = {}
            for stock in all_stocks_list:
                quality = stock.get('data_quality', 'unknown')
                quality_stats[quality] = quality_stats.get(quality, 0) + 1

            print(f"  æ•°æ®è´¨é‡ç»Ÿè®¡:")
            print(f"    æ€»è‚¡ç¥¨æ•°: {len(all_stocks_list)} åª")
            print(f"    æˆåŠŸè·å–: {quality_stats.get('success', 0)} åª ({quality_stats.get('success', 0)/len(all_stocks_list)*100:.1f}%)")
            print(f"    éƒ¨åˆ†æ•°æ®: {quality_stats.get('partial', 0)} åª ({quality_stats.get('partial', 0)/len(all_stocks_list)*100:.1f}%)")
            print(f"    é‡è¯•æˆåŠŸ: {quality_stats.get('retry_success', 0)} åª ({quality_stats.get('retry_success', 0)/len(all_stocks_list)*100:.1f}%)")
            print(f"    è·å–å¤±è´¥: {quality_stats.get('failed', 0)} åª ({quality_stats.get('failed', 0)/len(all_stocks_list)*100:.1f}%)")
            
            # ä¸Šå¸‚æ—¥æœŸç»Ÿè®¡
            listing_date_stocks = [s for s in all_stocks_list if s.get('listing_date', '')]

            # å¸‚å€¼ç»Ÿè®¡
            market_cap_stocks = [s for s in all_stocks_list if s.get('total_market_cap', 0) > 0]
            total_stocks_with_market_data = len([s for s in all_stocks_list if 'total_market_cap' in s])

            print(f"\n  ä¸Šå¸‚æ—¥æœŸæ•°æ®ç»Ÿè®¡:")
            print(f"    æ€»è‚¡ç¥¨æ•°: {len(all_stocks_list)} åª")
            print(f"    æœ‰ä¸Šå¸‚æ—¥æœŸ: {len(listing_date_stocks)} åª")
            print(f"    ä¸Šå¸‚æ—¥æœŸå®Œæ•´ç‡: {len(listing_date_stocks)/len(all_stocks_list)*100:.1f}%")

            print(f"  å¸‚å€¼æ•°æ®ç»Ÿè®¡:")
            print(f"    æ€»è‚¡ç¥¨æ•°: {len(all_stocks_list)} åª")
            print(f"    åŒ…å«å¸‚å€¼å­—æ®µ: {total_stocks_with_market_data} åª")
            print(f"    æœ‰æ•ˆå¸‚å€¼æ•°æ®: {len(market_cap_stocks)} åª")
            print(f"    å¸‚å€¼æ•°æ®å®Œæ•´ç‡: {len(market_cap_stocks)/len(all_stocks_list)*100:.1f}%")

            if market_cap_stocks:
                market_caps = [s['total_market_cap'] for s in market_cap_stocks]
                print(f"  å¸‚å€¼åˆ†å¸ƒç»Ÿè®¡ (åŸºäº {len(market_cap_stocks)} åªæœ‰æ•ˆæ•°æ®):")
                print(f"    å¹³å‡å¸‚å€¼: {np.mean(market_caps):.1f} ä¸‡å…ƒ")
                print(f"    ä¸­ä½æ•°å¸‚å€¼: {np.median(market_caps):.1f} ä¸‡å…ƒ")
                print(f"    æœ€å¤§å¸‚å€¼: {np.max(market_caps):.1f} ä¸‡å…ƒ")
                print(f"    æœ€å°å¸‚å€¼: {np.min(market_caps):.1f} ä¸‡å…ƒ")

                # å¸‚å€¼åˆ†å±‚ç»Ÿè®¡
                large_cap = sum(1 for mc in market_caps if mc >= 1000000)  # 100äº¿ä»¥ä¸Š
                mid_cap = sum(1 for mc in market_caps if 200000 <= mc < 1000000)  # 20-100äº¿
                small_cap = sum(1 for mc in market_caps if mc < 200000)  # 20äº¿ä»¥ä¸‹

                print(f"  å¸‚å€¼åˆ†å±‚åˆ†å¸ƒ:")
                print(f"    å¤§ç›˜è‚¡(â‰¥100äº¿): {large_cap} åª ({large_cap/len(market_cap_stocks)*100:.1f}%)")
                print(f"    ä¸­ç›˜è‚¡(20-100äº¿): {mid_cap} åª ({mid_cap/len(market_cap_stocks)*100:.1f}%)")
                print(f"    å°ç›˜è‚¡(<20äº¿): {small_cap} åª ({small_cap/len(market_cap_stocks)*100:.1f}%)")

            print(f"\næ­£åœ¨ä¿å­˜åˆ° stocks_akshare.json...")

            # ä¿å­˜ä¸ºJSONæ–‡ä»¶
            with open('stocks_akshare.json', 'w', encoding='utf-8') as f:
                json.dump(all_stocks_list, f, ensure_ascii=False, indent=2)

            print("âœ… æ–‡ä»¶ stocks_akshare.json å·²æˆåŠŸä¿å­˜ã€‚")

            # æ˜¾ç¤ºéƒ¨åˆ†ç¤ºä¾‹æ•°æ®
            print(f"\nğŸ“‹ ç¤ºä¾‹æ•°æ®ï¼ˆå‰5åªï¼‰:")
            for i, stock in enumerate(all_stocks_list[:5]):
                status_flags = []
                if stock['is_st']: status_flags.append('ST')
                if stock['is_xd']: status_flags.append('XD')
                if stock['is_xr']: status_flags.append('XR')
                if stock['is_dr']: status_flags.append('DR')
                status_str = f"[{','.join(status_flags)}]" if status_flags else ""

                industry_info = f"({stock.get('industry', 'æœªåˆ†ç±»')})" if stock.get('industry') != 'æœªåˆ†ç±»' else ""

                # å¸‚å€¼ä¿¡æ¯
                market_cap = stock.get('total_market_cap', 0)
                market_cap_str = f" å¸‚å€¼:{market_cap:.1f}ä¸‡" if market_cap > 0 else ""

                # ä¸Šå¸‚æ—¥æœŸä¿¡æ¯
                listing_date = stock.get('listing_date', '')
                listing_str = f" ä¸Šå¸‚:{listing_date}" if listing_date else ""

                pe_ratio = stock.get('pe_ratio', 0)
                pe_str = f" PE:{pe_ratio:.2f}" if pe_ratio > 0 else ""

                # æ•°æ®è´¨é‡ä¿¡æ¯
                quality = stock.get('data_quality', 'unknown')
                quality_indicator = {
                    'success': 'âœ…',
                    'partial': 'âš ï¸',
                    'retry_success': 'â™¾ï¸',
                    'failed': 'âŒ',
                    'unknown': 'â“'
                }.get(quality, 'â“')

                print(f"  {i+1}. {stock['code']} - {stock['name']} ({stock['exchange'].upper()}) {industry_info}{market_cap_str}{listing_str}{pe_str} {status_str} {quality_indicator}")

        else:
            print("âŒ æœªè·å–åˆ°ä»»ä½•è‚¡ç¥¨æ•°æ®ã€‚")

    except Exception as e:
        print(f"âŒ è·å–æˆ–å¤„ç†æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

# ä¸»ç¨‹åºå…¥å£
if __name__ == "__main__":
    print("="*60)
    print("ğŸš€ è‚¡ç¥¨ä¿¡æ¯è·å–å·¥å…· (å¤šæ ¸ä¼˜åŒ–ç‰ˆ)")
    print("æ­£åœ¨ä»AKShareè·å–å…¨å¸‚åœºè‚¡ç¥¨ä¿¡æ¯...")
    print("åŒ…å«ï¼šåŸºæœ¬ä¿¡æ¯ + è¡Œä¸šåˆ†ç±» + å¸‚å€¼è´¢åŠ¡æ•°æ®")
    print("ç‰¹æ€§ï¼šæ™ºèƒ½å¤šçº¿ç¨‹å¹¶è¡Œå¤„ç†ï¼Œæ˜¾è‘—æå‡è·å–é€Ÿåº¦")
    print("="*60)
    get_all_stocks_with_akshare_and_save()