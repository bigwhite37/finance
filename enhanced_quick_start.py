#!/usr/bin/env python3
"""
å¢å¼ºç³»ç»Ÿå¿«é€Ÿå¼€å§‹
æŒ‰ç…§ quick_start.md æµç¨‹ï¼Œä½¿ç”¨å¢å¼ºç»„ä»¶è¿›è¡Œè®­ç»ƒå’Œå›æµ‹
"""

import os
import sys
import argparse
import numpy as np
import pandas as pd
import logging
import torch
import warnings
import yaml
from datetime import datetime
warnings.filterwarnings('ignore')

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# å¯¼å…¥å¢å¼ºç»„ä»¶
from rl_agent.stable_cvar_ppo_agent import StableCVaRPPOAgent
from rl_agent.enhanced_trading_environment import EnhancedTradingEnvironment
from rl_agent.adaptive_safety_shield import AdaptiveSafetyShield
from rl_agent.enhanced_reward_system import EnhancedRewardSystem
from factors.advanced_alpha_factors import AdvancedAlphaFactors

# å¯¼å…¥åŸºç¡€ç»„ä»¶
from data.data_manager import DataManager
from config.config_manager import ConfigManager
from backtest.backtest_engine import BacktestEngine
from utils.logger import setup_logger

logger = logging.getLogger(__name__)


def load_enhanced_config(config_file: str) -> dict:
    """åŠ è½½å¢å¼ºé…ç½®æ–‡ä»¶"""
    with open(config_file, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    return config


def create_enhanced_systems(config: dict):
    """åˆ›å»ºå¢å¼ºç³»ç»Ÿç»„ä»¶"""
    # åˆå§‹åŒ–æ•°æ®ç®¡ç†å™¨
    data_manager = DataManager(config.get('data', {}))
    
    # åˆ›å»ºå›æµ‹å¼•æ“
    backtest_engine = BacktestEngine(config.get('backtest', {}))
    
    return {
        'data_manager': data_manager,
        'backtest_engine': backtest_engine
    }


def prepare_enhanced_data(data_manager, config):
    """å‡†å¤‡å¢å¼ºæ•°æ®"""
    logger.info("æ­£åœ¨è·å–è‚¡ç¥¨æ•°æ®...")
    
    data_config = config.get('data', {})
    stock_data = data_manager.get_stock_data(
        start_time=data_config['start_date'],
        end_time=data_config['end_date'],
        include_fundamentals=True
    )
    
    if stock_data.empty:
        raise ValueError("æœªèƒ½è·å–åˆ°è‚¡ç¥¨æ•°æ®")
    
    # è·å–ä»·æ ¼å’Œæˆäº¤é‡æ•°æ®
    price_data = stock_data['$close'].unstack().T
    volume_data = stock_data['$volume'].unstack().T
    
    logger.info(f"ä»·æ ¼æ•°æ®å½¢çŠ¶: {price_data.shape}")
    
    # è‚¡ç¥¨æ± ç­›é€‰
    if 'selected_stocks.pkl' in os.listdir('./models') and os.path.exists('./models/selected_stocks.pkl'):
        import pickle
        with open('./models/selected_stocks.pkl', 'rb') as f:
            selected_stocks = pickle.load(f)
        logger.info(f"å·²åŠ è½½è®­ç»ƒæ—¶çš„è‚¡ç¥¨æ± ï¼ŒåŒ…å« {len(selected_stocks)} åªè‚¡ç¥¨")
        
        # æ£€æŸ¥è‚¡ç¥¨åœ¨å½“å‰æ•°æ®ä¸­çš„å¯ç”¨æ€§
        available_stocks = list(set(selected_stocks) & set(price_data.columns))
        logger.info(f"å½“å‰æœŸé—´å¯ç”¨è‚¡ç¥¨: {len(available_stocks)} åª")
        
        if len(available_stocks) < len(selected_stocks) * 0.8:
            logger.warning(f"å¯ç”¨è‚¡ç¥¨æ¯”ä¾‹è¾ƒä½: {len(available_stocks)}/{len(selected_stocks)}")
        
        price_data = price_data[available_stocks]
        volume_data = volume_data[available_stocks]
        
    else:
        # é¦–æ¬¡è®­ç»ƒï¼Œè¿›è¡Œè‚¡ç¥¨ç­›é€‰
        logger.info("æ­£åœ¨ç­›é€‰ä½æ³¢åŠ¨è‚¡ç¥¨æ± ...")
        
        # ç®€å•çš„è‚¡ç¥¨ç­›é€‰é€»è¾‘
        returns = price_data.pct_change().dropna()
        volatility = returns.std()
        
        # é€‰æ‹©æ³¢åŠ¨ç‡é€‚ä¸­çš„è‚¡ç¥¨
        vol_threshold = volatility.quantile(0.7)  # é€‰æ‹©æ³¢åŠ¨ç‡åœ¨70%åˆ†ä½ä»¥ä¸‹çš„è‚¡ç¥¨
        selected_stocks = volatility[volatility <= vol_threshold].index.tolist()
        
        # è¿›ä¸€æ­¥ç­›é€‰ï¼šç¡®ä¿æœ‰è¶³å¤Ÿçš„äº¤æ˜“æ•°æ®
        min_data_points = len(price_data) * 0.8
        valid_stocks = []
        for stock in selected_stocks:
            if price_data[stock].notna().sum() >= min_data_points:
                valid_stocks.append(stock)
        
        selected_stocks = valid_stocks[:800]  # é™åˆ¶æœ€å¤§è‚¡ç¥¨æ•°
        logger.info(f"ç­›é€‰å‡º {len(selected_stocks)} åªè‚¡ç¥¨")
        
        # ä¿å­˜è‚¡ç¥¨æ± 
        os.makedirs('./models', exist_ok=True)
        import pickle
        with open('./models/selected_stocks.pkl', 'wb') as f:
            pickle.dump(selected_stocks, f)
        
        price_data = price_data[selected_stocks]
        volume_data = volume_data[selected_stocks]
    
    # è®¡ç®—å¢å¼ºå› å­
    logger.info("æ­£åœ¨è®¡ç®—å¢å¼ºå› å­...")
    enhanced_factors = AdvancedAlphaFactors(config.get('factors', {}))
    
    # è®¡ç®—å¯ç”¨çš„å› å­å­é›†ï¼ˆé¿å…è®¡ç®—è¿‡äºå¤æ‚çš„å› å­ï¼‰
    available_factors = [
        'momentum_reversal_5d', 'momentum_reversal_20d', 'momentum_trend_strength',
        'price_acceleration', 'relative_strength_index', 'momentum_quality',
        'technical_alpha', 'volume_price_correlation'
    ]
    
    factor_data = enhanced_factors.calculate_all_factors(
        price_data, volume_data, factors=available_factors
    )
    
    logger.info(f"å› å­è®¡ç®—å®Œæˆ! å› å­æ•°æ®å½¢çŠ¶: {factor_data.shape}")
    
    return price_data, factor_data


def train_enhanced_system(config_file: str):
    """è®­ç»ƒå¢å¼ºç³»ç»Ÿ"""
    logger.info("ğŸš€ å¼€å§‹è®­ç»ƒå¢å¼ºç³»ç»Ÿ")
    
    # åŠ è½½é…ç½®
    config = load_enhanced_config(config_file)
    
    # åˆ›å»ºç³»ç»Ÿç»„ä»¶
    systems = create_enhanced_systems(config)
    
    # å‡†å¤‡æ•°æ®
    price_data, factor_data = prepare_enhanced_data(systems['data_manager'], config)
    
    # åˆ›å»ºå¢å¼ºäº¤æ˜“ç¯å¢ƒ
    logger.info("åˆ›å»ºå¢å¼ºäº¤æ˜“ç¯å¢ƒ...")
    enhanced_env = EnhancedTradingEnvironment(
        factor_data=factor_data,
        price_data=price_data,
        config=config,
        train_universe=list(price_data.columns)
    )
    
    # åˆ›å»ºç¨³å®šCVaR-PPOæ™ºèƒ½ä½“
    logger.info("åˆ›å»ºç¨³å®šCVaR-PPOæ™ºèƒ½ä½“...")
    agent_config = config.get('agent', {})
    enhanced_agent = StableCVaRPPOAgent(
        state_dim=enhanced_env.observation_space.shape[0],
        action_dim=enhanced_env.action_space.shape[0],
        config=agent_config
    )
    
    # å¼€å§‹è®­ç»ƒ
    training_config = config.get('training', {})
    total_episodes = training_config.get('total_episodes', 400)
    save_frequency = training_config.get('save_frequency', 50)
    
    logger.info(f"å¼€å§‹è®­ç»ƒ: æ€»å…± {total_episodes} ä¸ªepisode")
    
    best_performance = {
        'episode': 0,
        'annual_return': -np.inf,
        'sharpe_ratio': -np.inf,
        'model_path': None
    }
    
    for episode in range(total_episodes):
        # é‡ç½®ç¯å¢ƒ
        observation, info = enhanced_env.reset()
        episode_reward = 0.0
        episode_steps = 0
        
        while True:
            # è·å–åŠ¨ä½œ
            action, log_prob, value = enhanced_agent.get_action(observation)
            
            # æ‰§è¡ŒåŠ¨ä½œ
            next_observation, reward, terminated, truncated, info = enhanced_env.step(action)
            
            # å­˜å‚¨ç»éªŒ
            enhanced_agent.store_experience(
                observation, action, reward, log_prob, value, terminated
            )
            
            episode_reward += reward
            episode_steps += 1
            observation = next_observation
            
            if terminated or truncated:
                break
        
        # æ›´æ–°æ™ºèƒ½ä½“
        if len(enhanced_agent.memory['states']) >= enhanced_agent.batch_size:
            update_info = enhanced_agent.update()
        
        # å®šæœŸä¿å­˜å’Œè¯„ä¼°
        if (episode + 1) % save_frequency == 0:
            # è·å–å½“å‰æ€§èƒ½
            if 'performance_metrics' in info:
                annual_return = info['performance_metrics'].get('annualized_return', 0.0)
                sharpe_ratio = info['performance_metrics'].get('sharpe_ratio', 0.0)
                
                logger.info(
                    f"Episode {episode + 1}/{total_episodes}: "
                    f"å¥–åŠ±={episode_reward:.2f}, "
                    f"å¹´åŒ–æ”¶ç›Š={annual_return:.2%}, "
                    f"å¤æ™®æ¯”ç‡={sharpe_ratio:.2f}"
                )
                
                # æ›´æ–°æœ€ä½³æ¨¡å‹
                if annual_return > best_performance['annual_return']:
                    best_performance.update({
                        'episode': episode + 1,
                        'annual_return': annual_return,
                        'sharpe_ratio': sharpe_ratio
                    })
                    
                    # ä¿å­˜æœ€ä½³æ¨¡å‹
                    model_dir = config.get('model', {}).get('save_dir', './models/enhanced_csi300_2020_2022')
                    os.makedirs(model_dir, exist_ok=True)
                    model_path = f"{model_dir}/best_enhanced_agent_episode_{episode + 1}.pth"
                    enhanced_agent.save_model(model_path)
                    best_performance['model_path'] = model_path
                    
                    logger.info(f"ä¿å­˜æœ€ä½³æ¨¡å‹: {model_path}, å¹´åŒ–æ”¶ç›Š: {annual_return:.2%}")
    
    # è®­ç»ƒå®Œæˆ
    logger.info("âœ… è®­ç»ƒå®Œæˆ")
    logger.info(f"æœ€ä½³æ€§èƒ½: Episode {best_performance['episode']}, "
               f"å¹´åŒ–æ”¶ç›Š: {best_performance['annual_return']:.2%}, "
               f"å¤æ™®æ¯”ç‡: {best_performance['sharpe_ratio']:.2f}")
    
    return best_performance


def backtest_enhanced_system(config_file: str, model_path: str):
    """å›æµ‹å¢å¼ºç³»ç»Ÿ"""
    logger.info("ğŸ“Š å¼€å§‹å›æµ‹å¢å¼ºç³»ç»Ÿ")
    
    # åŠ è½½é…ç½®
    config = load_enhanced_config(config_file)
    
    # åˆ›å»ºç³»ç»Ÿç»„ä»¶
    systems = create_enhanced_systems(config)
    
    # å‡†å¤‡å›æµ‹æ•°æ®
    price_data, factor_data = prepare_enhanced_data(systems['data_manager'], config)
    
    # åˆ›å»ºå›æµ‹ç¯å¢ƒ
    logger.info("åˆ›å»ºå›æµ‹ç¯å¢ƒ...")
    backtest_env = EnhancedTradingEnvironment(
        factor_data=factor_data,
        price_data=price_data,
        config=config
    )
    
    # åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
    logger.info(f"åŠ è½½æ¨¡å‹: {model_path}")
    enhanced_agent = StableCVaRPPOAgent(
        state_dim=backtest_env.observation_space.shape[0],
        action_dim=backtest_env.action_space.shape[0],
        config=config.get('agent', {})
    )
    enhanced_agent.load_model(model_path)
    
    # è¿è¡Œå›æµ‹
    logger.info("å¼€å§‹è¿è¡Œå›æµ‹...")
    observation, info = backtest_env.reset()
    
    backtest_results = {
        'daily_returns': [],
        'portfolio_values': [],
        'actions': [],
        'rewards': []
    }
    
    step_count = 0
    while True:
        # è·å–åŠ¨ä½œï¼ˆç¡®å®šæ€§ï¼Œä¸æ¢ç´¢ï¼‰
        action, _, _ = enhanced_agent.get_action(observation, deterministic=True)
        
        # æ‰§è¡ŒåŠ¨ä½œ
        next_observation, reward, terminated, truncated, info = backtest_env.step(action)
        
        # è®°å½•ç»“æœ
        backtest_results['actions'].append(action.copy())
        backtest_results['rewards'].append(reward)
        
        if 'portfolio_value' in info:
            backtest_results['portfolio_values'].append(info['portfolio_value'])
        
        observation = next_observation
        step_count += 1
        
        # å®šæœŸè¾“å‡ºè¿›åº¦
        if step_count % 50 == 0:
            current_return = info.get('cumulative_return', 0.0)
            current_drawdown = info.get('current_drawdown', 0.0)
            logger.info(f"å›æµ‹è¿›åº¦: {step_count} æ­¥, ç´¯ç§¯æ”¶ç›Š: {current_return:.2%}, å›æ’¤: {current_drawdown:.2%}")
        
        if terminated or truncated:
            break
    
    # è·å–æœ€ç»ˆæŠ¥å‘Š
    final_report = backtest_env.get_final_report()
    final_performance = final_report['final_performance']
    
    # è¾“å‡ºå›æµ‹ç»“æœ
    logger.info("ğŸ“ˆ å›æµ‹å®Œæˆ")
    logger.info("=" * 60)
    logger.info("å¢å¼ºç³»ç»Ÿå›æµ‹æŠ¥å‘Š")
    logger.info("=" * 60)
    
    print(f"\nã€å›æµ‹æ¦‚è¦ã€‘")
    print(f"å›æµ‹æœŸé—´: {config['data']['start_date']} è‡³ {config['data']['end_date']}")
    print(f"å›æµ‹æ­¥æ•°: {step_count}")
    print(f"æœ€ç»ˆç»„åˆä»·å€¼: {backtest_results['portfolio_values'][-1]:,.0f}" if backtest_results['portfolio_values'] else "N/A")
    
    print(f"\nã€æ ¸å¿ƒæŒ‡æ ‡ã€‘")
    print(f"å¹´åŒ–æ”¶ç›Šç‡: {final_performance.get('annualized_return', 0.0):.2%}")
    print(f"å¤æ™®æ¯”ç‡: {final_performance.get('sharpe_ratio', 0.0):.2f}")
    print(f"æœ€å¤§å›æ’¤: {final_performance.get('max_drawdown', 0.0):.2%}")
    print(f"èƒœç‡: {final_performance.get('win_rate', 0.0):.1%}")
    print(f"å¡å°”ç›æ¯”ç‡: {final_performance.get('calmar_ratio', 0.0):.2f}")
    
    print(f"\nã€ç›®æ ‡è¾¾æˆè¯„ä¼°ã€‘")
    annual_return = final_performance.get('annualized_return', 0.0)
    target_return = 0.08
    target_achieved = annual_return >= target_return
    
    print(f"ç›®æ ‡å¹´åŒ–æ”¶ç›Š: {target_return:.1%}")
    print(f"å®é™…å¹´åŒ–æ”¶ç›Š: {annual_return:.2%}")
    print(f"ç›®æ ‡è¾¾æˆ: {'âœ… æ˜¯' if target_achieved else 'âŒ å¦'}")
    print(f"ç›®æ ‡å®Œæˆåº¦: {annual_return / target_return:.1%}")
    
    if target_achieved:
        print(f"ğŸ‰ æ­å–œï¼å¢å¼ºç³»ç»ŸæˆåŠŸè¾¾åˆ°8%å¹´åŒ–æ”¶ç›Šç›®æ ‡ï¼")
    else:
        gap = target_return - annual_return
        print(f"ğŸ“ˆ è·ç¦»ç›®æ ‡è¿˜éœ€æå‡: {gap:.2%}")
    
    return final_performance


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='å¢å¼ºç³»ç»Ÿå¿«é€Ÿå¼€å§‹')
    parser.add_argument('--mode', choices=['train', 'backtest', 'full'], 
                       default='full', help='è¿è¡Œæ¨¡å¼')
    parser.add_argument('--train_config', default='config_enhanced_train.yaml',
                       help='è®­ç»ƒé…ç½®æ–‡ä»¶')
    parser.add_argument('--backtest_config', default='config_enhanced_backtest.yaml',
                       help='å›æµ‹é…ç½®æ–‡ä»¶')
    parser.add_argument('--model', help='æ¨¡å‹è·¯å¾„ï¼ˆå›æµ‹æ¨¡å¼éœ€è¦ï¼‰')
    
    args = parser.parse_args()
    
    # è®¾ç½®æ—¥å¿—
    setup_logger()
    
    logger.info("ğŸš€ å¢å¼ºç³»ç»Ÿå¿«é€Ÿå¼€å§‹")
    
    best_model_path = None
    
    if args.mode in ['train', 'full']:
        logger.info("=" * 60)
        logger.info("ç¬¬ä¸€æ­¥ï¼šè®­ç»ƒå¢å¼ºç³»ç»Ÿ (2020-2022)")
        logger.info("=" * 60)
        
        best_performance = train_enhanced_system(args.train_config)
        best_model_path = best_performance['model_path']
        
        logger.info(f"è®­ç»ƒå®Œæˆï¼Œæœ€ä½³æ¨¡å‹: {best_model_path}")
    
    if args.mode in ['backtest', 'full']:
        logger.info("=" * 60)
        logger.info("ç¬¬äºŒæ­¥ï¼šå›æµ‹å¢å¼ºç³»ç»Ÿ (2023)")
        logger.info("=" * 60)
        
        # ç¡®å®šä½¿ç”¨çš„æ¨¡å‹è·¯å¾„
        if args.model:
            model_path = args.model
        elif best_model_path:
            model_path = best_model_path
        else:
            # æŸ¥æ‰¾æœ€æ–°çš„æ¨¡å‹
            model_dir = './models/enhanced_csi300_2020_2022'
            if os.path.exists(model_dir):
                model_files = [f for f in os.listdir(model_dir) if f.endswith('.pth')]
                if model_files:
                    model_path = os.path.join(model_dir, sorted(model_files)[-1])
                else:
                    raise ValueError("æœªæ‰¾åˆ°å¯ç”¨çš„æ¨¡å‹æ–‡ä»¶")
            else:
                raise ValueError("æœªæ‰¾åˆ°æ¨¡å‹ç›®å½•ï¼Œè¯·å…ˆè¿è¡Œè®­ç»ƒ")
        
        logger.info(f"ä½¿ç”¨æ¨¡å‹: {model_path}")
        
        # è¿è¡Œå›æµ‹
        backtest_results = backtest_enhanced_system(args.backtest_config, model_path)
        
        logger.info("å›æµ‹å®Œæˆ")
    
    logger.info("âœ… å¢å¼ºç³»ç»Ÿå¿«é€Ÿå¼€å§‹å®Œæˆ")


if __name__ == "__main__":
    main()