**æ¦‚è¦**
æ•´ä½“ä¸Šï¼Œä½ æŠŠ SAC æ™ºèƒ½ä½“è¿ç§»åˆ° Stable-Baselines3ï¼ˆSB3ï¼‰æ¡†æ¶çš„æ–¹å‘æ˜¯æ­£ç¡®çš„ï¼šä½¿ç”¨ policy_kwargs æŒ‚æ¥ Transformer-based ç‰¹å¾æå–å™¨ã€ç”¨ make_vec_env å°è£…å¹¶è¡Œç¯å¢ƒã€ä¾èµ– EvalCallback ä¿å­˜æœ€ä½³æ¨¡å‹ç­‰éƒ½ç¬¦åˆ SB3 å®˜æ–¹åšæ³•ã€‚
ä¸è¿‡ï¼Œä»£ç é‡Œä»æœ‰è‹¥å¹²æ½œåœ¨ bug ä¸è®¾è®¡éšæ‚£ï¼ˆå°¤å…¶æ˜¯ RLTrainer ä¸é©±åŠ¨è„šæœ¬çš„å¯¹æ¥ï¼‰ï¼Œä¸€æ—¦è¿›å…¥é•¿æ—¶é—´è®­ç»ƒå°±å¯èƒ½å¯¼è‡´å´©æºƒã€æ€§èƒ½ä¸‹é™æˆ–æ‰¾ä¸åˆ°æ¨¡å‹æ–‡ä»¶ã€‚ä¸‹é¢æŒ‰æ¨¡å—ç»™å‡ºè¯¦ç»† review ä¸æ”¹è¿›å»ºè®®ã€‚

â¸»

### 1  SACAgent å®ç°

### 1.1 å‚æ•°æ³¨å…¥ä¸ policy_kwargs
	* 	ä½ ç”¨ _inject_training_params æŠŠ TrainingConfig é‡Œçš„æ ¸å¿ƒè¶…å‚æ•°å†™è¿›å®ä¾‹å±æ€§ï¼Œä½†â€‹_create_model() é‡Œæ˜¯é  getattr(self,'learning_rate',3e-4) å†è¯»å›ã€‚
	* 	è‹¥åç»­åœ¨è„šæœ¬é‡Œç›´æ¥ä¿®æ”¹ training_config.learning_rate å¹¶ **æœªé‡æ–°è°ƒç”¨** set_env()ï¼Œæ¨¡å‹é‡Œçš„å­¦ä¹ ç‡ä¸ä¼šåŒæ­¥æ›´æ–°ã€‚å¯ä»¥åœ¨ _inject_training_params é‡Œç›´æ¥æ„é€  policy_kwargs æˆ–åœ¨ create_model å‰å¼ºåˆ¶åˆ·æ–°ã€‚
	* 	activation_fn å­—ç¬¦ä¸²è½¬ nn.Module æ²¡é—®é¢˜ï¼Œä½†æœ€å¥½ç›´æ¥æŠŠ **ç±»æœ¬èº«** ä¼ è¿›å»ï¼ˆnn.ReLU è€Œéå®ä¾‹ï¼‰ï¼ŒSB3 ä¼šè‡ªåŠ¨å®ä¾‹åŒ–ã€‚

### 1.2 è‡ªå®šä¹‰ Transformer ç‰¹å¾æå–å™¨
	* 	forward() ä¸­å¯¹å¼ é‡ç»´åº¦çš„æ’/åˆ ç»´æ¯”è¾ƒæ¿€è¿›ï¼Œå®¹æ˜“æŠŠ (batch, seq, feat) å¼„æˆ (1,1,seq,feat)ï¼›å»ºè®®åªåœ¨ obs.dim()==2 æ—¶åŠ  batch ç»´ï¼Œå…¶ä½™ç»´åº¦ä¿æŒä¸€è‡´ã€‚
	* 	å¦‚æœè¾“å…¥æ˜¯ DictObsï¼ŒMultiInputPolicy å·²ç»ä¿è¯æŠŠå­ç©ºé—´æ‰“åŒ…æˆå­—å…¸ï¼›æ­¤æ—¶ extractor åªéœ€å¤„ç† obs['features'] å³å¯ï¼Œæ— éœ€å¯¹æ™®é€šå¼ é‡åˆ†æ”¯å†åšç»´åº¦åˆ¤å®šã€‚

### 1.3 å‘é‡åŒ–ç¯å¢ƒåˆ›å»º
	* 	SB3 >= 2.2 çš„ make_vec_env å·²ç»åœ¨ vec_env_kwargs é‡Œæ”¯æŒ start_methodï¼›ä½†ä½ åœ¨è°ƒç”¨å‰ **æ‰‹åŠ¨å…ˆåˆ›å»ºä¸€æ¬¡** test_env = self.env_factory() æ¥æ¢æµ‹ç¯å¢ƒç±»å‹ï¼Œè¿™ä¸€æ­¥ä¼šæå‰å ç”¨ GPU / I/Oã€‚å¯ç›´æ¥ç”¨ make_vec_env çš„ env_id=None å’Œè‡ªå®šä¹‰å·¥å‚é¿å…å¤šä½™å®ä¾‹ã€‚
	* 	VecTransposeDict åªåœ¨ **Gym DictObs ä¸” image-likeå¼ é‡** æ—¶å¿…éœ€ã€‚è‹¥ä½ çš„è§‚æµ‹éƒ½æ˜¯ float ç‰¹å¾ï¼Œé¢å¤–è½¬ç½®ä¼šå¸¦æ¥å¤åˆ¶å¼€é”€ï¼Œå¯é€šè¿‡ is_image_space åˆ¤æ–­åå†åŒ…ä¸€å±‚ã€‚

### 1.4 ä¿å­˜ / åŠ è½½
	* 	save(path/'sac_model') ä¼šè½ç›˜ â€¦/sac_model.zipï¼Œè€Œ load() å»æ‰¾çš„æ˜¯ â€¦/sac_modelï¼ˆæ— åç¼€ï¼‰â€”â€”SB3 åœ¨è¯»æ—¶ä¼šè‡ªåŠ¨åŠ â€œ.zipâ€ï¼Œè¿™é‡Œ OKï¼Œä½†é©±åŠ¨è„šæœ¬é‡Œå¼•ç”¨æ–‡ä»¶åè¦ç»Ÿä¸€ã€‚

â¸»

### 2  Callback ä½“ç³»

### 2.1 TrainingProgressCallback
	* 	ä½ å·²æŒ‰ SB3 å»ºè®®æ”¹ç”¨ model.num_timesteps è€Œä¸æ˜¯ self.num_callsï¼Œé¿å…é‡ç½®è®¡æ•°é”™ä¹±ï¼ŒğŸ‘ã€‚
	* 	è‹¥ç”¨ SubprocVecEnvï¼Œnum_timesteps æ¯æ­¥å¢åŠ  n_envsï¼Œå›è°ƒé‡Œçš„ log_freq éœ€æŒ‰ n_envs ç¼©æ”¾ï¼Œå¦åˆ™æ—¥å¿—é¢‘ç‡ä¼šå˜å¿« n_envs å€ã€‚

### 2.2 EarlyStopping ä¸ DrawdownEarlyStopping
	* 	è¿™ä¸¤ä¸ªç±»ç›®å‰ **æ²¡æœ‰æŒ‚åˆ° SB3 callback é“¾**ï¼Œåªåœ¨ä½ è‡ªå·±çš„ä¼ ç»Ÿ trainer ä»£ç é‡Œç”¨åˆ°ï¼Œè€Œæ–°æµç¨‹å®Œå…¨ä¾èµ– .learn()ã€‚å»ºè®®æŠŠé€»è¾‘å°è£…æˆç»§æ‰¿ BaseCallback çš„ç‰ˆæœ¬å¹¶åŠ å…¥ _create_callbacks()ã€‚

â¸»

### 3  RLTrainer

### 3.1 evaluate() ç¼ºå¤±
	* 	é©±åŠ¨è„šæœ¬åœ¨è®­ç»ƒåè°ƒç”¨ trainer.evaluate()ï¼Œä½†ç±»é‡Œå¹¶æœªå®šä¹‰ï¼Œè¿è¡Œä¸€å®šæŠ¥ AttributeErrorã€‚å¯ä»¥ç›´æ¥ä½¿ç”¨ stable_baselines3.common.evaluation.evaluate_policy æˆ–è®© RLTrainer ç®€å•å°è£…è¯¥å‡½æ•°ã€‚

### 3.2 å¤šè¿›ç¨‹ / VecEnv
	* 	mp.set_start_method('spawn', force=True) åœ¨å­è¿›ç¨‹é‡Œå†æ¬¡è°ƒç”¨ä¼šæŠ¥é”™ï¼›ä½ å·²ç» try/except å¤„ç†ï¼Œä»å»ºè®®åªåœ¨ **ä¸»è¿›ç¨‹ç¬¬ä¸€æ¬¡** set-methodï¼ˆä¹Ÿå¯äº¤ç»™ SB3ï¼‰ã€‚
	* 	parallel_environments ä¸ n_envs å­˜åœ¨é‡å¤å®šä¹‰ï¼›TrainingConfig.__post_init__ åä½ æŠŠ n_envs åŒæ­¥ï¼Œä½†é©±åŠ¨è„šæœ¬åˆä» YAML é‡Œå„å–ä¸€æ¬¡ï¼Œå®¹æ˜“ä¸²ã€‚ä¿æŒå•ä¸€æ¥æºã€‚

### 3.3 æŒ‡æ ‡å†å²
	* 	portfolio_values_history ç­‰åˆ—è¡¨åœ¨é•¿è®­ç»ƒä¸­å¯èƒ½å­˜ 10â¶ æ¡æ•°æ®ï¼Œå†…å­˜å ç”¨å¯è¾¾ GBã€‚è€ƒè™‘æŒ‰çª—å£ç»Ÿè®¡æˆ–å®šæœŸè½ç›˜ã€‚

â¸»

### 4  é©±åŠ¨è„šæœ¬ (train.py)

| **é—®é¢˜** | **å½±å“** | **å»ºè®®** |
| --- | --- | --- |
| trainer.evaluate() è°ƒç”¨ä¸å­˜åœ¨ | è®­ç»ƒåç›´æ¥å´©æºƒ | æ”¹ä¸º from stable_baselines3.common.evaluation import evaluate_policyï¼Œæˆ–è¡¥å®ç° |
| model_config["training"] vs model_config["model"]["training"] æ··ç”¨ | YAML å­—æ®µå±‚çº§å˜åŠ¨æ—¶è¯»å–ç©ºå€¼ | ç»Ÿä¸€é‡‡ç”¨ä¸€å¤„ï¼Œç¼ºçœç”¨ dict.get(..., default) |
| ä¿å­˜æ¨¡å‹è·¯å¾„ | ä½ æŠŠ final_model å½“æ–‡ä»¶å¤¹ï¼Œè€Œ agent.save() å­˜ sac_model.zip | ç›´æ¥æŠŠ final_model.zip ä½œä¸ºæ–‡ä»¶åä¼ ç»™ agent.save() |
| é¢œè‰²è¾“å‡ºåŒ…è£… | ColorFormatter åœ¨å¤šè¿›ç¨‹æ—¶ä¸ä¿è¯çº¿ç¨‹å®‰å…¨ | è‹¥å¹¶å‘æ‰“å°ï¼Œé” stdout |

â¸»

### 5  å…¶ä»–æ”¹è¿›å»ºè®®
	1.	**å½’ä¸€åŒ–** â€”â€” å¯¹è¿ç»­ç‰¹å¾å¯ç›´æ¥åœ¨ç¯å¢ƒå¤–ç”¨ VecNormalize è‡ªåŠ¨ç»´æŠ¤å‡å€¼æ–¹å·®ï¼Œæ¯”æ‰‹åŠ¨æ ‡å‡†åŒ– + æ•°æ®æ¼‚ç§»æ›´ç¨³ã€‚
	2.	**Replay Buffer å¤§å°** â€”â€” SAC é»˜è®¤ 1 M æ­¥ï¼ŒA è‚¡æ—¥é¢‘æ•°æ®é›†å¯èƒ½è¿œå°äºæ­¤ï¼›å ç”¨å†…å­˜ä½†å­¦ä¸åˆ°æ–°æ ·æœ¬ã€‚æ ¹æ® total_timesteps è°ƒæ•´åˆ° 1-3 Ã— æ•°æ®é›†é•¿åº¦å³å¯ã€‚
	3.	**Transformer è¾“å…¥æ©ç ** â€”â€” è‹¥æ¯æ—¥è‚¡ç¥¨æ•°å˜åŒ–ï¼Œç»™ Transformer ä¼  padding maskï¼Œé¿å…å‡å€¼æ± åŒ–ç¨€é‡Šæœ‰æ•ˆ tokenã€‚
	4.	**æ€§èƒ½ç›‘æ§** â€”â€” å¯åœ¨ EnhancedMetricsCallback é‡Œç”¨ self.locals["losses"] ç›´æ¥æ‹‰ SB3 tensorboard scalarsï¼Œé¿å…è‡ªå·±è§£æ loggerã€‚
	5.	**Lightning / Pytorch-Prof** â€”â€” å¯¹é•¿åºåˆ— Transformerï¼Œå¯ç”¨ torch.compile æˆ– Flash-Attention æ›¿ä»£åŸç”Ÿ nn.MultiheadAttentionï¼Œé€Ÿåº¦ 2-3Ã—ã€‚

