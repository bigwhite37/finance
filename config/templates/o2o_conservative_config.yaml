# O2O保守策略配置模板
# 适用于风险厌恶的量化交易场景

data:
  start_date: '2020-01-01'
  end_date: '2023-12-31'
  universe: 'csi300'
  factors: ['technical', 'fundamental', 'macro']
  apply_cleaning: true
  outlier_threshold: 2.5  # 更严格的异常值处理

o2o:
  # 离线预训练参数 - 保守设置
  offline_epochs: 150  # 更多训练轮数确保充分学习
  behavior_cloning_weight: 0.7  # 更重视历史经验
  td_learning_weight: 0.3
  offline_batch_size: 128  # 较小批次提高稳定性
  offline_lr: 1e-4  # 较低学习率
  
  # 热身微调参数 - 保守设置
  warmup_days: 90  # 更长热身期
  warmup_epochs: 30
  critic_only_updates: true
  warmup_lr: 5e-5  # 更低学习率
  convergence_threshold: 0.005  # 更严格收敛标准
  
  # 在线学习参数 - 保守设置
  initial_rho: 0.1  # 较低初始在线比例
  rho_increment: 0.005  # 缓慢增长
  trust_region_beta: 2.0  # 更强信任域约束
  beta_decay: 0.95
  online_buffer_size: 15000
  priority_alpha: 0.4  # 较低优先级权重
  priority_beta: 0.6
  importance_weight_clip: 5.0  # 限制重要性权重
  
  # 漂移检测参数 - 敏感设置
  kl_threshold: 0.08  # 更敏感的KL散度阈值
  sharpe_drop_threshold: 0.15  # 更敏感的夏普率阈值
  cvar_breach_threshold: -0.015  # 更严格的CVaR阈值
  drift_window: 40  # 更长检测窗口
  noise_filter: true

agent:
  hidden_dims: [512, 256, 128]  # 更大网络容量
  activation: 'relu'
  cvar_alpha: 0.03  # 更保守的CVaR参数
  risk_lambda: 2.0  # 更高风险惩罚
  entropy_coef: 0.005  # 较低熵系数
  value_coef: 0.8  # 更重视价值学习
  max_grad_norm: 0.3  # 更严格梯度裁剪

environment:
  initial_capital: 1000000
  transaction_cost: 0.0015  # 考虑更高交易成本
  max_position: 0.05  # 更保守的最大仓位
  rebalance_freq: 'daily'
  risk_free_rate: 0.03

training:
  max_episodes: 2000
  eval_freq: 25  # 更频繁评估
  save_freq: 50
  early_stopping_patience: 300

logging:
  level: 'INFO'
  save_logs: true
  log_dir: 'logs/conservative'
  tensorboard: true
  detailed_metrics: true