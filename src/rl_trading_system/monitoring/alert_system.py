"""
å‘Šè­¦ç³»ç»Ÿæ¨¡å—
å®ç°DynamicThresholdManagerç±»å’Œé˜ˆå€¼è®¡ç®—ï¼Œå¤šçº§åˆ«å‘Šè­¦å’Œå‘Šè­¦è§„åˆ™é…ç½®ï¼Œå¤šæ¸ é“é€šçŸ¥å’Œå‘Šè­¦èšåˆã€é™é»˜å’Œæ—¥å¿—è®°å½•
ä¸¥æ ¼éµå¾ªTDDå¼€å‘ï¼Œä¸å…è®¸æ•è·å¼‚å¸¸ï¼Œè®©å¼‚å¸¸æš´éœ²ä»¥å°½æ—©å‘ç°é”™è¯¯
"""
import json
import smtplib
import requests
import time
import threading
from datetime import datetime, timedelta
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from typing import Dict, List, Optional, Any, Union
from enum import Enum
from collections import defaultdict, deque
from dataclasses import dataclass, asdict
import pandas as pd
import numpy as np
from scipy import stats


class AlertLevel(Enum):
    """å‘Šè­¦çº§åˆ«æšä¸¾"""
    INFO = "info"
    WARNING = "warning"
    ERROR = "error"
    CRITICAL = "critical"


class AlertChannel(Enum):
    """å‘Šè­¦æ¸ é“æšä¸¾"""
    EMAIL = "email"
    WEBHOOK = "webhook"
    SMS = "sms"


@dataclass
class AlertRule:
    """å‘Šè­¦è§„åˆ™ç±»"""
    rule_id: str
    metric_name: str
    threshold_value: float
    comparison_operator: str
    alert_level: AlertLevel
    description: str = ""
    is_active: bool = True
    
    def __post_init__(self):
        """åˆå§‹åŒ–åéªŒè¯"""
        if not self.rule_id:
            raise ValueError("è§„åˆ™IDä¸èƒ½ä¸ºç©º")
        
        valid_operators = [">", ">=", "<", "<=", "==", "!="]
        if self.comparison_operator not in valid_operators:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¯”è¾ƒæ“ä½œç¬¦: {self.comparison_operator}")
    
    def evaluate(self, value: float) -> bool:
        """è¯„ä¼°è§„åˆ™æ˜¯å¦è§¦å‘"""
        if not self.is_active:
            return False
        
        if self.comparison_operator == ">":
            return value > self.threshold_value
        elif self.comparison_operator == ">=":
            return value >= self.threshold_value
        elif self.comparison_operator == "<":
            return value < self.threshold_value
        elif self.comparison_operator == "<=":
            return value <= self.threshold_value
        elif self.comparison_operator == "==":
            return abs(value - self.threshold_value) < 1e-10
        elif self.comparison_operator == "!=":
            return abs(value - self.threshold_value) >= 1e-10
        
        return False
    
    def activate(self):
        """æ¿€æ´»è§„åˆ™"""
        self.is_active = True
    
    def deactivate(self):
        """åœç”¨è§„åˆ™"""
        self.is_active = False
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            'rule_id': self.rule_id,
            'metric_name': self.metric_name,
            'threshold_value': self.threshold_value,
            'comparison_operator': self.comparison_operator,
            'alert_level': self.alert_level.value,
            'description': self.description,
            'is_active': self.is_active
        }
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'AlertRule':
        """ä»å­—å…¸åˆ›å»º"""
        return cls(
            rule_id=data['rule_id'],
            metric_name=data['metric_name'],
            threshold_value=data['threshold_value'],
            comparison_operator=data['comparison_operator'],
            alert_level=AlertLevel(data['alert_level']),
            description=data.get('description', ''),
            is_active=data.get('is_active', True)
        )


class DynamicThresholdManager:
    """åŠ¨æ€é˜ˆå€¼ç®¡ç†å™¨"""
    
    def __init__(self, historical_data: pd.DataFrame, lookback_window: int = 60, 
                 update_frequency: str = 'daily'):
        """
        åˆå§‹åŒ–åŠ¨æ€é˜ˆå€¼ç®¡ç†å™¨
        
        Args:
            historical_data: å†å²æ•°æ®
            lookback_window: å›çœ‹çª—å£å¤§å°
            update_frequency: æ›´æ–°é¢‘ç‡
        """
        if historical_data.empty:
            raise ValueError("å†å²æ•°æ®ä¸èƒ½ä¸ºç©º")
        
        if lookback_window <= 0:
            raise ValueError("å›çœ‹çª—å£å¤§å°å¿…é¡»ä¸ºæ­£æ•°")
        
        self.historical_data = historical_data.copy()
        self.lookback_window = lookback_window
        self.update_frequency = update_frequency
        self.thresholds = {}
        self._lock = threading.Lock()
    
    def calculate_percentile_threshold(self, metric_name: str, percentile: float, 
                                     threshold_type: str = 'upper') -> float:
        """è®¡ç®—åŸºäºåˆ†ä½æ•°çš„é˜ˆå€¼"""
        if metric_name not in self.historical_data.columns:
            raise ValueError(f"æŒ‡æ ‡ {metric_name} ä¸å­˜åœ¨äºå†å²æ•°æ®ä¸­")
        
        if not (0 < percentile < 100):
            raise ValueError("åˆ†ä½æ•°å¿…é¡»åœ¨0-100ä¹‹é—´")
        
        data = self.historical_data[metric_name]
        
        if threshold_type.lower() == 'upper':
            threshold = data.quantile(percentile / 100.0)
        else:  # lower
            threshold = data.quantile(percentile / 100.0)
        
        return float(threshold)
    
    def calculate_rolling_threshold(self, metric_name: str, window_size: int, 
                                  percentile: float) -> pd.Series:
        """è®¡ç®—æ»šåŠ¨çª—å£é˜ˆå€¼"""
        if metric_name not in self.historical_data.columns:
            raise ValueError(f"æŒ‡æ ‡ {metric_name} ä¸å­˜åœ¨äºå†å²æ•°æ®ä¸­")
        
        data = self.historical_data[metric_name]
        rolling_thresholds = data.rolling(window=window_size).quantile(percentile / 100.0)
        
        return rolling_thresholds
    
    def update_threshold_with_new_data(self, metric_name: str, new_data: pd.DataFrame, 
                                     adaptation_factor: float = 0.1) -> float:
        """ä½¿ç”¨æ–°æ•°æ®æ›´æ–°é˜ˆå€¼"""
        if metric_name not in new_data.columns:
            raise ValueError(f"æ–°æ•°æ®ä¸­ä¸åŒ…å«æŒ‡æ ‡ {metric_name}")
        
        with self._lock:
            # æ·»åŠ æ–°æ•°æ®åˆ°å†å²æ•°æ®
            self.historical_data = pd.concat([self.historical_data, new_data], ignore_index=True)
            
            # ä¿æŒæ•°æ®é‡åœ¨åˆç†èŒƒå›´å†…
            if len(self.historical_data) > self.lookback_window * 5:
                self.historical_data = self.historical_data.tail(self.lookback_window * 3)
            
            # é‡æ–°è®¡ç®—é˜ˆå€¼
            new_threshold = self.calculate_percentile_threshold(metric_name, 90, 'upper')
            
            return new_threshold
    
    def calculate_multiple_thresholds(self, threshold_configs: Dict[str, Dict[str, Any]]) -> Dict[str, float]:
        """æ‰¹é‡è®¡ç®—å¤šä¸ªæŒ‡æ ‡çš„é˜ˆå€¼"""
        thresholds = {}
        
        for metric_name, config in threshold_configs.items():
            if metric_name in self.historical_data.columns:
                threshold = self.calculate_percentile_threshold(
                    metric_name=metric_name,
                    percentile=config['percentile'],
                    threshold_type=config['type']
                )
                thresholds[metric_name] = threshold
        
        return thresholds
    
    def validate_threshold_config(self, config: Dict[str, Any]) -> bool:
        """éªŒè¯é˜ˆå€¼é…ç½®æœ‰æ•ˆæ€§"""
        required_fields = ['metric_name', 'percentile', 'threshold_type']
        
        for field in required_fields:
            if field not in config:
                return False
        
        # æ£€æŸ¥æŒ‡æ ‡æ˜¯å¦å­˜åœ¨
        if config['metric_name'] not in self.historical_data.columns:
            return False
        
        # æ£€æŸ¥åˆ†ä½æ•°èŒƒå›´
        percentile = config['percentile']
        if not (0 < percentile < 100):
            return False
        
        # æ£€æŸ¥é˜ˆå€¼ç±»å‹
        if config['threshold_type'] not in ['upper', 'lower']:
            return False
        
        return True
    
    def save_thresholds(self, file_path: str):
        """ä¿å­˜é˜ˆå€¼åˆ°æ–‡ä»¶"""
        with self._lock:
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(self.thresholds, f, indent=2, ensure_ascii=False)
    
    def load_thresholds(self, file_path: str):
        """ä»æ–‡ä»¶åŠ è½½é˜ˆå€¼"""
        with self._lock:
            with open(file_path, 'r', encoding='utf-8') as f:
                self.thresholds = json.load(f)
    
    def is_statistical_outlier(self, metric_name: str, value: float, 
                             method: str = 'zscore', threshold: float = 3.0) -> bool:
        """æ£€æµ‹ç»Ÿè®¡å¼‚å¸¸å€¼"""
        if metric_name not in self.historical_data.columns:
            raise ValueError(f"æŒ‡æ ‡ {metric_name} ä¸å­˜åœ¨")
        
        data = self.historical_data[metric_name]
        
        if method == 'zscore':
            # æ‰‹åŠ¨è®¡ç®—z-score
            mean = data.mean()
            std = data.std()
            if std == 0:
                return False
            z_score = abs((value - mean) / std)
            return z_score > threshold
        elif method == 'iqr':
            q1 = data.quantile(0.25)
            q3 = data.quantile(0.75)
            iqr = q3 - q1
            lower_bound = q1 - 1.5 * iqr
            upper_bound = q3 + 1.5 * iqr
            return value < lower_bound or value > upper_bound
        
        return False
    
    def analyze_threshold_sensitivity(self, metric_name: str, 
                                    percentiles: List[float]) -> Dict[float, float]:
        """åˆ†æé˜ˆå€¼æ•æ„Ÿæ€§"""
        sensitivity_results = {}
        
        for percentile in percentiles:
            threshold = self.calculate_percentile_threshold(
                metric_name=metric_name,
                percentile=percentile,
                threshold_type='upper'
            )
            sensitivity_results[percentile] = threshold
        
        return sensitivity_results


class AlertAggregator:
    """å‘Šè­¦èšåˆå™¨"""
    
    def __init__(self, aggregation_window: int = 300, max_alerts_per_rule: int = 5,
                 similarity_threshold: float = 0.8):
        """
        åˆå§‹åŒ–å‘Šè­¦èšåˆå™¨
        
        Args:
            aggregation_window: èšåˆæ—¶é—´çª—å£ï¼ˆç§’ï¼‰
            max_alerts_per_rule: æ¯ä¸ªè§„åˆ™æœ€å¤§å‘Šè­¦æ•°
            similarity_threshold: ç›¸ä¼¼åº¦é˜ˆå€¼
        """
        self.aggregation_window = aggregation_window
        self.max_alerts_per_rule = max_alerts_per_rule
        self.similarity_threshold = similarity_threshold
        self.pending_alerts = []
        self._lock = threading.Lock()
    
    def add_alert(self, alert: Dict[str, Any]):
        """æ·»åŠ å‘Šè­¦åˆ°èšåˆé˜Ÿåˆ—"""
        with self._lock:
            alert['timestamp'] = alert.get('timestamp', datetime.now())
            self.pending_alerts.append(alert)
    
    def aggregate_alerts(self) -> List[Dict[str, Any]]:
        """æ‰§è¡Œå‘Šè­¦èšåˆ"""
        with self._lock:
            current_time = datetime.now()
            
            # æ¸…ç†è¿‡æœŸå‘Šè­¦
            self.pending_alerts = [
                alert for alert in self.pending_alerts
                if abs((current_time - alert['timestamp']).total_seconds()) < self.aggregation_window
            ]
            
            # æŒ‰è§„åˆ™åˆ†ç»„
            alerts_by_rule = defaultdict(list)
            for alert in self.pending_alerts:
                alerts_by_rule[alert['rule_id']].append(alert)
            
            aggregated_alerts = []
            
            for rule_id, rule_alerts in alerts_by_rule.items():
                # åº”ç”¨é¢‘ç‡é™åˆ¶
                if len(rule_alerts) > self.max_alerts_per_rule:
                    rule_alerts = rule_alerts[:self.max_alerts_per_rule]
                
                # èšåˆç›¸ä¼¼å‘Šè­¦
                if len(rule_alerts) > 1:
                    # æ£€æŸ¥æ˜¯å¦å¯ä»¥èšåˆ
                    similar_alerts = self._group_similar_alerts(rule_alerts)
                    for group in similar_alerts:
                        if len(group) > 1:
                            # åˆ›å»ºèšåˆå‘Šè­¦
                            aggregated_alert = group[0].copy()
                            aggregated_alert['count'] = len(group)
                            aggregated_alert['message'] += f" (èšåˆäº†{len(group)}æ¡ç›¸ä¼¼å‘Šè­¦)"
                            aggregated_alerts.append(aggregated_alert)
                        else:
                            aggregated_alerts.extend(group)
                else:
                    aggregated_alerts.extend(rule_alerts)
            
            # æ¸…ç©ºå·²å¤„ç†çš„å‘Šè­¦
            self.pending_alerts.clear()
            
            return aggregated_alerts
    
    def calculate_similarity(self, alert1: Dict[str, Any], alert2: Dict[str, Any]) -> float:
        """è®¡ç®—ä¸¤ä¸ªå‘Šè­¦çš„ç›¸ä¼¼åº¦"""
        similarity_score = 0.0
        total_weight = 0.0
        
        # è§„åˆ™IDç›¸ä¼¼åº¦æƒé‡: 40%
        if alert1.get('rule_id') == alert2.get('rule_id'):
            similarity_score += 0.4
        total_weight += 0.4
        
        # æŒ‡æ ‡åç§°ç›¸ä¼¼åº¦æƒé‡: 30%
        if alert1.get('metric_name') == alert2.get('metric_name'):
            similarity_score += 0.3
        total_weight += 0.3
        
        # å‘Šè­¦çº§åˆ«ç›¸ä¼¼åº¦æƒé‡: 20%
        if alert1.get('level') == alert2.get('level'):
            similarity_score += 0.2
        total_weight += 0.2
        
        # æ¶ˆæ¯ç›¸ä¼¼åº¦æƒé‡: 10%
        if alert1.get('message') == alert2.get('message'):
            similarity_score += 0.1
        total_weight += 0.1
        
        return similarity_score / total_weight if total_weight > 0 else 0.0
    
    def _group_similar_alerts(self, alerts: List[Dict[str, Any]]) -> List[List[Dict[str, Any]]]:
        """å°†ç›¸ä¼¼çš„å‘Šè­¦åˆ†ç»„"""
        groups = []
        processed = set()
        
        for i, alert1 in enumerate(alerts):
            if i in processed:
                continue
            
            group = [alert1]
            processed.add(i)
            
            for j, alert2 in enumerate(alerts):
                if j <= i or j in processed:
                    continue
                
                similarity = self.calculate_similarity(alert1, alert2)
                if similarity >= self.similarity_threshold:
                    group.append(alert2)
                    processed.add(j)
            
            groups.append(group)
        
        return groups


class NotificationManager:
    """é€šçŸ¥ç®¡ç†å™¨"""
    
    def __init__(self, notification_config: Dict[str, Dict[str, Any]]):
        """
        åˆå§‹åŒ–é€šçŸ¥ç®¡ç†å™¨
        
        Args:
            notification_config: é€šçŸ¥é…ç½®
        """
        self.channels = notification_config
        self.rate_limits = {}
        self.notification_history = defaultdict(deque)
        self._lock = threading.Lock()
    
    def send_email_notification(self, alert_data: Dict[str, Any], 
                              max_retries: int = 3, retry_delay: float = 1.0) -> bool:
        """å‘é€é‚®ä»¶é€šçŸ¥"""
        if not self.channels.get('email', {}).get('enabled', False):
            return False
        
        email_config = self.channels['email']
        
        # æ£€æŸ¥é¢‘ç‡é™åˆ¶
        if not self._check_rate_limit('email'):
            return False
        
        # æ ¼å¼åŒ–é‚®ä»¶å†…å®¹
        content = self.format_email_content(alert_data)
        
        # åˆ›å»ºé‚®ä»¶
        msg = MIMEMultipart()
        msg['From'] = email_config['username']
        msg['Subject'] = content['subject']
        
        body = MIMEText(content['body'], 'html', 'utf-8')
        msg.attach(body)
        
        # å‘é€é‚®ä»¶
        for attempt in range(max_retries):
            server = smtplib.SMTP(email_config['smtp_server'], email_config['smtp_port'])
            server.starttls()
            server.login(email_config['username'], email_config['password'])
            
            for recipient in email_config['recipients']:
                msg['To'] = recipient
                server.send_message(msg)
                del msg['To']
            
            server.quit()
            
            # è®°å½•å‘é€å†å²
            self._record_notification('email')
            return True
        
        return False
    
    def send_webhook_notification(self, alert_data: Dict[str, Any],
                                max_retries: int = 3, retry_delay: float = 1.0) -> bool:
        """å‘é€Webhooké€šçŸ¥"""
        if not self.channels.get('webhook', {}).get('enabled', False):
            return False
        
        webhook_config = self.channels['webhook']
        
        # æ£€æŸ¥é¢‘ç‡é™åˆ¶
        if not self._check_rate_limit('webhook'):
            return False
        
        # æ ¼å¼åŒ–Webhookå†…å®¹
        content = self.format_webhook_content(alert_data)
        
        # å‘é€Webhook
        for attempt in range(max_retries):
            response = requests.post(
                webhook_config['url'],
                json=content,
                timeout=webhook_config.get('timeout', 10)
            )
            
            if response.status_code == 200:
                self._record_notification('webhook')
                return True
            
            if attempt < max_retries - 1:
                time.sleep(retry_delay)
        
        return False
    
    def send_notification(self, alert_data: Dict[str, Any]) -> bool:
        """å‘é€é€šçŸ¥åˆ°æ‰€æœ‰æ¿€æ´»çš„æ¸ é“"""
        success = False
        
        for channel_name in self.get_active_channels():
            if channel_name == 'email':
                if self.send_email_notification(alert_data):
                    success = True
            elif channel_name == 'webhook':
                if self.send_webhook_notification(alert_data):
                    success = True
        
        return success
    
    def format_email_content(self, alert_data: Dict[str, Any]) -> Dict[str, str]:
        """æ ¼å¼åŒ–é‚®ä»¶å†…å®¹"""
        subject = f"[{alert_data.get('level', AlertLevel.INFO).value.upper()}] äº¤æ˜“ç³»ç»Ÿå‘Šè­¦ - {alert_data.get('rule_id', '')}"
        
        body = f"""
        <html>
        <body>
        <h2>äº¤æ˜“ç³»ç»Ÿå‘Šè­¦é€šçŸ¥</h2>
        <p><strong>è§„åˆ™ID:</strong> {alert_data.get('rule_id', 'N/A')}</p>
        <p><strong>æŒ‡æ ‡åç§°:</strong> {alert_data.get('metric_name', 'N/A')}</p>
        <p><strong>å½“å‰å€¼:</strong> {alert_data.get('value', 'N/A')}</p>
        <p><strong>é˜ˆå€¼:</strong> {alert_data.get('threshold', 'N/A')}</p>
        <p><strong>å‘Šè­¦çº§åˆ«:</strong> {alert_data.get('level', AlertLevel.INFO).value}</p>
        <p><strong>å‘Šè­¦æ¶ˆæ¯:</strong> {alert_data.get('message', '')}</p>
        <p><strong>æ—¶é—´:</strong> {alert_data.get('timestamp', datetime.now()).strftime('%Y-%m-%d %H:%M:%S')}</p>
        </body>
        </html>
        """
        
        return {'subject': subject, 'body': body}
    
    def format_webhook_content(self, alert_data: Dict[str, Any]) -> Dict[str, Any]:
        """æ ¼å¼åŒ–Webhookå†…å®¹"""
        return {
            'text': f"ğŸš¨ äº¤æ˜“ç³»ç»Ÿå‘Šè­¦",
            'attachments': [
                {
                    'color': self._get_color_for_level(alert_data.get('level', AlertLevel.INFO)),
                    'fields': [
                        {'title': 'è§„åˆ™ID', 'value': alert_data.get('rule_id', 'N/A'), 'short': True},
                        {'title': 'æŒ‡æ ‡', 'value': alert_data.get('metric_name', 'N/A'), 'short': True},
                        {'title': 'å½“å‰å€¼', 'value': str(alert_data.get('value', 'N/A')), 'short': True},
                        {'title': 'é˜ˆå€¼', 'value': str(alert_data.get('threshold', 'N/A')), 'short': True},
                        {'title': 'æ¶ˆæ¯', 'value': alert_data.get('message', ''), 'short': False}
                    ],
                    'timestamp': alert_data.get('timestamp', datetime.now()).isoformat()
                }
            ]
        }
    
    def _get_color_for_level(self, level: AlertLevel) -> str:
        """è·å–å‘Šè­¦çº§åˆ«å¯¹åº”çš„é¢œè‰²"""
        color_map = {
            AlertLevel.INFO: 'good',
            AlertLevel.WARNING: 'warning',
            AlertLevel.ERROR: 'danger',
            AlertLevel.CRITICAL: 'danger'
        }
        return color_map.get(level, 'good')
    
    def enable_channel(self, channel_name: str):
        """å¯ç”¨é€šçŸ¥æ¸ é“"""
        if channel_name in self.channels:
            self.channels[channel_name]['enabled'] = True
    
    def disable_channel(self, channel_name: str):
        """ç¦ç”¨é€šçŸ¥æ¸ é“"""
        if channel_name in self.channels:
            self.channels[channel_name]['enabled'] = False
    
    def get_active_channels(self) -> List[str]:
        """è·å–æ´»è·ƒçš„é€šçŸ¥æ¸ é“"""
        return [
            name for name, config in self.channels.items()
            if config.get('enabled', False)
        ]
    
    def set_rate_limit(self, channel: str, max_notifications: int, time_window: int):
        """è®¾ç½®é¢‘ç‡é™åˆ¶"""
        self.rate_limits[channel] = {
            'max_notifications': max_notifications,
            'time_window': time_window
        }
    
    def _check_rate_limit(self, channel: str) -> bool:
        """æ£€æŸ¥é¢‘ç‡é™åˆ¶"""
        if channel not in self.rate_limits:
            return True
        
        limit_config = self.rate_limits[channel]
        current_time = datetime.now()
        
        with self._lock:
            # æ¸…ç†è¿‡æœŸè®°å½•
            cutoff_time = current_time - timedelta(seconds=limit_config['time_window'])
            history = self.notification_history[channel]
            
            while history and history[0] < cutoff_time:
                history.popleft()
            
            # æ£€æŸ¥æ˜¯å¦è¶…è¿‡é™åˆ¶
            if len(history) >= limit_config['max_notifications']:
                return False
            
            return True
    
    def _record_notification(self, channel: str):
        """è®°å½•é€šçŸ¥å‘é€"""
        with self._lock:
            self.notification_history[channel].append(datetime.now())


class AlertLogger:
    """å‘Šè­¦æ—¥å¿—è®°å½•å™¨"""
    
    def __init__(self, log_file: str = None):
        """åˆå§‹åŒ–å‘Šè­¦æ—¥å¿—è®°å½•å™¨"""
        self.log_file = log_file
        self.logs = []
        self._lock = threading.Lock()
    
    def log_alert(self, alert: Dict[str, Any]):
        """è®°å½•å‘Šè­¦"""
        log_entry = {
            'timestamp': datetime.now().isoformat(),
            'rule_id': alert.get('rule_id'),
            'metric_name': alert.get('metric_name'),
            'value': alert.get('value'),
            'threshold': alert.get('threshold'),
            'level': alert.get('level', AlertLevel.INFO).value,
            'message': alert.get('message'),
            'status': 'triggered'
        }
        
        with self._lock:
            self.logs.append(log_entry)
            
            if self.log_file:
                with open(self.log_file, 'a', encoding='utf-8') as f:
                    f.write(json.dumps(log_entry, ensure_ascii=False) + '\n')
    
    def get_logs(self, limit: int = 100) -> List[Dict[str, Any]]:
        """è·å–å‘Šè­¦æ—¥å¿—"""
        with self._lock:
            return self.logs[-limit:] if limit < len(self.logs) else self.logs.copy()


class AlertSystem:
    """å®Œæ•´çš„å‘Šè­¦ç³»ç»Ÿ"""
    
    def __init__(self, historical_data: pd.DataFrame, 
                 notification_config: Dict[str, Dict[str, Any]]):
        """
        åˆå§‹åŒ–å‘Šè­¦ç³»ç»Ÿ
        
        Args:
            historical_data: å†å²æ•°æ®
            notification_config: é€šçŸ¥é…ç½®
        """
        self.threshold_manager = DynamicThresholdManager(historical_data)
        self.notification_manager = NotificationManager(notification_config)
        self.aggregator = AlertAggregator()
        self.logger = AlertLogger()
        
        self.rules = {}
        self.silenced_rules = {}
        self._lock = threading.Lock()
    
    def add_rule(self, rule: AlertRule):
        """æ·»åŠ å‘Šè­¦è§„åˆ™"""
        with self._lock:
            self.rules[rule.rule_id] = rule
    
    def remove_rule(self, rule_id: str):
        """åˆ é™¤å‘Šè­¦è§„åˆ™"""
        with self._lock:
            if rule_id in self.rules:
                del self.rules[rule_id]
    
    def get_rule(self, rule_id: str) -> Optional[AlertRule]:
        """è·å–å‘Šè­¦è§„åˆ™"""
        return self.rules.get(rule_id)
    
    def check_metrics(self, metrics: Dict[str, float]) -> List[Dict[str, Any]]:
        """æ£€æŸ¥æŒ‡æ ‡å¹¶ç”Ÿæˆå‘Šè­¦"""
        alerts = []
        
        with self._lock:
            for rule_id, rule in self.rules.items():
                if not rule.is_active:
                    continue
                
                if rule_id in self.silenced_rules:
                    silence_end = self.silenced_rules[rule_id]
                    if datetime.now() < silence_end:
                        continue
                    else:
                        # é™é»˜æœŸç»“æŸï¼Œåˆ é™¤é™é»˜è®°å½•
                        del self.silenced_rules[rule_id]
                
                if rule.metric_name in metrics:
                    value = metrics[rule.metric_name]
                    
                    if rule.evaluate(value):
                        alert = {
                            'rule_id': rule_id,
                            'metric_name': rule.metric_name,
                            'value': value,
                            'threshold': rule.threshold_value,
                            'level': rule.alert_level,
                            'message': rule.description or f"{rule.metric_name} è§¦å‘å‘Šè­¦é˜ˆå€¼",
                            'timestamp': datetime.now()
                        }
                        alerts.append(alert)
        
        return alerts
    
    def process_metrics(self, metrics: Dict[str, float]):
        """å¤„ç†æŒ‡æ ‡ï¼ˆæ£€æŸ¥ã€èšåˆã€é€šçŸ¥ï¼‰"""
        # æ£€æŸ¥å‘Šè­¦
        alerts = self.check_metrics(metrics)
        
        # æ·»åŠ åˆ°èšåˆå™¨
        for alert in alerts:
            self.aggregator.add_alert(alert)
        
        # æ‰§è¡Œèšåˆ
        aggregated_alerts = self.aggregator.aggregate_alerts()
        
        # å‘é€é€šçŸ¥å’Œè®°å½•æ—¥å¿—
        for alert in aggregated_alerts:
            self.notification_manager.send_notification(alert)
            self.logger.log_alert(alert)
    
    def silence_rule(self, rule_id: str, duration: int):
        """é™é»˜æŒ‡å®šè§„åˆ™"""
        with self._lock:
            silence_end = datetime.now() + timedelta(seconds=duration)
            self.silenced_rules[rule_id] = silence_end