"""
å¢å¼ºçš„å¼ºåŒ–å­¦ä¹ è®­ç»ƒå™¨

åœ¨åŸæœ‰è®­ç»ƒå™¨åŸºç¡€ä¸Šæ·»åŠ è¯¦ç»†çš„æŠ•èµ„ç»„åˆæŒ‡æ ‡ã€æ™ºèƒ½ä½“è¡Œä¸ºåˆ†æå’Œé£é™©æ§åˆ¶æŒ‡æ ‡ã€‚
"""

import numpy as np
import pandas as pd
from typing import Dict, List, Tuple, Any, Optional
from dataclasses import dataclass
from datetime import datetime
import logging

from .trainer import RLTrainer, TrainingConfig
from ..metrics.portfolio_metrics import (
    PortfolioMetricsCalculator,
    PortfolioMetrics,
    AgentBehaviorMetrics,
    RiskControlMetrics
)

logger = logging.getLogger(__name__)


@dataclass
class EnhancedTrainingConfig(TrainingConfig):
    """å¢å¼ºè®­ç»ƒé…ç½®"""
    # æŒ‡æ ‡è®¡ç®—å¼€å…³
    enable_portfolio_metrics: bool = True          # å¯ç”¨æŠ•èµ„ç»„åˆæŒ‡æ ‡è®¡ç®—
    enable_agent_behavior_metrics: bool = True     # å¯ç”¨æ™ºèƒ½ä½“è¡Œä¸ºæŒ‡æ ‡è®¡ç®—
    enable_risk_control_metrics: bool = True       # å¯ç”¨é£é™©æ§åˆ¶æŒ‡æ ‡è®¡ç®—
    
    # æŒ‡æ ‡è®¡ç®—é¢‘ç‡
    metrics_calculation_frequency: int = 10        # æ¯Nä¸ªepisodeè®¡ç®—ä¸€æ¬¡æŒ‡æ ‡
    
    # åŸºå‡†æ•°æ®é…ç½®
    benchmark_data_path: Optional[str] = None      # åŸºå‡†æ•°æ®è·¯å¾„
    risk_free_rate: float = 0.03                   # æ— é£é™©åˆ©ç‡
    
    # ç¯å¢ƒé…ç½®ï¼ˆç”¨äºæŒ‡æ ‡è®¡ç®—çš„é»˜è®¤å€¼ï¼‰
    initial_cash: float = 1000000.0                # åˆå§‹èµ„é‡‘ï¼ˆç”¨äºæŒ‡æ ‡è®¡ç®—é»˜è®¤å€¼ï¼‰
    
    # æ—¥å¿—é…ç½®
    detailed_metrics_logging: bool = True          # è¯¦ç»†æŒ‡æ ‡æ—¥å¿—
    metrics_log_level: str = 'INFO'                # æŒ‡æ ‡æ—¥å¿—çº§åˆ«
    
    def __post_init__(self):
        """é…ç½®éªŒè¯"""
        super().__post_init__()
        
        if self.metrics_calculation_frequency <= 0:
            raise ValueError("metrics_calculation_frequencyå¿…é¡»ä¸ºæ­£æ•°")
        
        if self.enable_portfolio_metrics and self.benchmark_data_path == "":
            raise ValueError("å¯ç”¨æŠ•èµ„ç»„åˆæŒ‡æ ‡æ—¶ï¼Œbenchmark_data_pathä¸èƒ½ä¸ºç©º")
        
        if self.risk_free_rate < 0:
            raise ValueError("risk_free_rateä¸èƒ½ä¸ºè´Ÿæ•°")


class EnhancedRLTrainer(RLTrainer):
    """
    å¢å¼ºçš„å¼ºåŒ–å­¦ä¹ è®­ç»ƒå™¨
    
    åœ¨åŸæœ‰è®­ç»ƒå™¨åŸºç¡€ä¸Šæ·»åŠ ï¼š
    1. æŠ•èµ„ç»„åˆä¸å¸‚åœºè¡¨ç°å¯¹æ¯”æŒ‡æ ‡ï¼ˆå¤æ™®æ¯”ç‡ã€æœ€å¤§å›æ’¤ã€Alphaã€Betaã€å¹´åŒ–æ”¶ç›Šç‡ï¼‰
    2. æ™ºèƒ½ä½“è¡Œä¸ºåˆ†ææŒ‡æ ‡ï¼ˆç†µã€å¹³å‡æŒä»“æƒé‡ã€æ¢æ‰‹ç‡ï¼‰
    3. é£é™©ä¸å›æ’¤æ§åˆ¶æ¨¡å—çš„è¯¦ç»†æ—¥å¿—
    """
    
    def __init__(self, config: EnhancedTrainingConfig, environment, agent, data_split):
        """
        åˆå§‹åŒ–å¢å¼ºè®­ç»ƒå™¨
        
        Args:
            config: å¢å¼ºè®­ç»ƒé…ç½®
            environment: äº¤æ˜“ç¯å¢ƒ
            agent: å¼ºåŒ–å­¦ä¹ æ™ºèƒ½ä½“
            data_split: æ•°æ®åˆ’åˆ†ç»“æœ
        """
        super().__init__(config, environment, agent, data_split)
        
        # æŒ‡æ ‡è®¡ç®—å™¨
        self.metrics_calculator = PortfolioMetricsCalculator()
        
        # å†å²æ•°æ®å­˜å‚¨
        self.portfolio_values_history: List[float] = []
        self.benchmark_values_history: List[float] = []
        self.dates_history: List[datetime] = []
        
        # æ™ºèƒ½ä½“è¡Œä¸ºæ•°æ®
        self.entropy_history: List[float] = []
        self.position_weights_history: List[np.ndarray] = []
        
        # é£é™©æ§åˆ¶æ•°æ®
        self.risk_budget_history: List[float] = []
        self.risk_usage_history: List[float] = []
        self.control_signals_history: List[Dict[str, Any]] = []
        self.market_regime_history: List[str] = []
        
        logger.info("å¢å¼ºè®­ç»ƒå™¨åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"æŒ‡æ ‡è®¡ç®—é…ç½®: æŠ•èµ„ç»„åˆæŒ‡æ ‡={config.enable_portfolio_metrics}, "
                   f"æ™ºèƒ½ä½“è¡Œä¸ºæŒ‡æ ‡={config.enable_agent_behavior_metrics}, "
                   f"é£é™©æ§åˆ¶æŒ‡æ ‡={config.enable_risk_control_metrics}")
    
    def _run_episode(self, episode_num: int, training: bool = True) -> Tuple[float, int]:
        """
        è¿è¡Œå•ä¸ªepisodeï¼ˆå¢å¼ºç‰ˆï¼‰
        
        Args:
            episode_num: episodeç¼–å·
            training: æ˜¯å¦ä¸ºè®­ç»ƒæ¨¡å¼
            
        Returns:
            Tuple[float, int]: episodeå¥–åŠ±å’Œé•¿åº¦
        """
        # è°ƒç”¨çˆ¶ç±»æ–¹æ³•è¿è¡Œepisode
        episode_reward, episode_length = super()._run_episode(episode_num, training)
        
        # å¦‚æœæ˜¯è®­ç»ƒæ¨¡å¼ä¸”åˆ°äº†æŒ‡æ ‡è®¡ç®—é¢‘ç‡ï¼Œè®¡ç®—å¹¶è®°å½•å¢å¼ºæŒ‡æ ‡
        if training and self._should_calculate_metrics(episode_num):
            self._calculate_and_log_enhanced_metrics(episode_num)
        
        return episode_reward, episode_length
    
    def _should_calculate_metrics(self, episode_num: int) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦åº”è¯¥è®¡ç®—æŒ‡æ ‡
        
        Args:
            episode_num: episodeç¼–å·
            
        Returns:
            æ˜¯å¦åº”è¯¥è®¡ç®—æŒ‡æ ‡
        """
        return episode_num % self.config.metrics_calculation_frequency == 0
    
    def _calculate_and_log_enhanced_metrics(self, episode_num: int):
        """
        è®¡ç®—å¹¶è®°å½•å¢å¼ºæŒ‡æ ‡
        
        Args:
            episode_num: episodeç¼–å·
        """
        try:
            # è®¡ç®—æŠ•èµ„ç»„åˆæŒ‡æ ‡
            portfolio_metrics = None
            if self.config.enable_portfolio_metrics:
                portfolio_metrics = self._calculate_portfolio_metrics()
            
            # è®¡ç®—æ™ºèƒ½ä½“è¡Œä¸ºæŒ‡æ ‡
            agent_metrics = None
            if self.config.enable_agent_behavior_metrics:
                agent_metrics = self._calculate_agent_behavior_metrics()
            
            # è®¡ç®—é£é™©æ§åˆ¶æŒ‡æ ‡
            risk_metrics = None
            if self.config.enable_risk_control_metrics:
                risk_metrics = self._calculate_risk_control_metrics()
            
            # è®°å½•æŒ‡æ ‡æ—¥å¿—
            if self.config.detailed_metrics_logging:
                self._log_enhanced_metrics(episode_num, portfolio_metrics, agent_metrics, risk_metrics)
            
        except Exception as e:
            logger.error(f"è®¡ç®—å¢å¼ºæŒ‡æ ‡æ—¶å‘ç”Ÿé”™è¯¯: {e}")
    
    def _calculate_portfolio_metrics(self) -> Optional[PortfolioMetrics]:
        """
        è®¡ç®—æŠ•èµ„ç»„åˆæŒ‡æ ‡
        
        Returns:
            æŠ•èµ„ç»„åˆæŒ‡æ ‡æˆ–Noneï¼ˆå¦‚æœæ•°æ®ä¸è¶³ï¼‰
        """
        if len(self.portfolio_values_history) <= 1:
            logger.debug("æŠ•èµ„ç»„åˆä»·å€¼å†å²æ•°æ®ä¸è¶³ï¼Œè·³è¿‡æŒ‡æ ‡è®¡ç®—")
            return None
        
        try:
            # ç¡®ä¿åŸºå‡†æ•°æ®é•¿åº¦åŒ¹é…
            if len(self.benchmark_values_history) != len(self.portfolio_values_history):
                logger.warning(f"åŸºå‡†æ•°æ®é•¿åº¦({len(self.benchmark_values_history)})ä¸æŠ•èµ„ç»„åˆæ•°æ®é•¿åº¦"
                             f"({len(self.portfolio_values_history)})ä¸åŒ¹é…")
                # æˆªå–åˆ°è¾ƒçŸ­çš„é•¿åº¦
                min_len = min(len(self.benchmark_values_history), len(self.portfolio_values_history))
                portfolio_values = self.portfolio_values_history[:min_len]
                benchmark_values = self.benchmark_values_history[:min_len]
                dates = self.dates_history[:min_len] if len(self.dates_history) >= min_len else [datetime.now()] * min_len
            else:
                portfolio_values = self.portfolio_values_history
                benchmark_values = self.benchmark_values_history
                dates = self.dates_history if len(self.dates_history) == len(portfolio_values) else [datetime.now()] * len(portfolio_values)
            
            metrics = self.metrics_calculator.calculate_portfolio_metrics(
                portfolio_values=portfolio_values,
                benchmark_values=benchmark_values,
                dates=dates,
                risk_free_rate=self.config.risk_free_rate
            )
            
            return metrics
            
        except Exception as e:
            logger.error(f"è®¡ç®—æŠ•èµ„ç»„åˆæŒ‡æ ‡å¤±è´¥: {e}")
            return None
    
    def _calculate_agent_behavior_metrics(self) -> Optional[AgentBehaviorMetrics]:
        """
        è®¡ç®—æ™ºèƒ½ä½“è¡Œä¸ºæŒ‡æ ‡
        
        Returns:
            æ™ºèƒ½ä½“è¡Œä¸ºæŒ‡æ ‡æˆ–Noneï¼ˆå¦‚æœæ•°æ®ä¸è¶³ï¼‰
        """
        if len(self.entropy_history) == 0:
            logger.debug("ç†µå€¼å†å²æ•°æ®ä¸ºç©ºï¼Œè·³è¿‡æ™ºèƒ½ä½“è¡Œä¸ºæŒ‡æ ‡è®¡ç®—")
            return None
        
        try:
            metrics = self.metrics_calculator.calculate_agent_behavior_metrics(
                entropy_values=self.entropy_history,
                position_weights_history=self.position_weights_history
            )
            
            return metrics
            
        except Exception as e:
            logger.error(f"è®¡ç®—æ™ºèƒ½ä½“è¡Œä¸ºæŒ‡æ ‡å¤±è´¥: {e}")
            return None
    
    def _calculate_risk_control_metrics(self) -> Optional[RiskControlMetrics]:
        """
        è®¡ç®—é£é™©æ§åˆ¶æŒ‡æ ‡
        
        Returns:
            é£é™©æ§åˆ¶æŒ‡æ ‡æˆ–Noneï¼ˆå¦‚æœæ•°æ®ä¸è¶³ï¼‰
        """
        # æ£€æŸ¥ç¯å¢ƒæ˜¯å¦æœ‰å›æ’¤æ§åˆ¶å™¨
        if not hasattr(self.environment, 'drawdown_controller') or self.environment.drawdown_controller is None:
            logger.debug("ç¯å¢ƒä¸­æ²¡æœ‰å›æ’¤æ§åˆ¶å™¨ï¼Œè·³è¿‡é£é™©æ§åˆ¶æŒ‡æ ‡è®¡ç®—")
            return None
        
        try:
            drawdown_controller = self.environment.drawdown_controller
            
            # ä»å›æ’¤æ§åˆ¶å™¨è·å–æ•°æ®
            risk_budget_history = getattr(drawdown_controller.adaptive_risk_budget, 'risk_budget_history', [])
            risk_usage_history = getattr(drawdown_controller.adaptive_risk_budget, 'risk_usage_history', [])
            control_signals = getattr(drawdown_controller, 'control_signal_queue', [])
            
            # è·å–å¸‚åœºçŠ¶æ€å†å²
            market_regime_history = []
            if hasattr(drawdown_controller, 'market_regime_detector') and drawdown_controller.market_regime_detector:
                market_regime_history = getattr(drawdown_controller.market_regime_detector, 'regime_history', [])
            
            # è½¬æ¢æ§åˆ¶ä¿¡å·ä¸ºå­—å…¸æ ¼å¼
            control_signals_dict = []
            for signal in control_signals:
                if hasattr(signal, 'to_dict'):
                    control_signals_dict.append(signal.to_dict())
                elif isinstance(signal, dict):
                    control_signals_dict.append(signal)
            
            metrics = self.metrics_calculator.calculate_risk_control_metrics(
                risk_budget_history=risk_budget_history,
                risk_usage_history=risk_usage_history,
                control_signals=control_signals_dict,
                market_regime_history=market_regime_history
            )
            
            return metrics
            
        except Exception as e:
            logger.error(f"è®¡ç®—é£é™©æ§åˆ¶æŒ‡æ ‡å¤±è´¥: {e}")
            return None
    
    def _log_enhanced_metrics(self, episode: int,
                            portfolio_metrics: Optional[PortfolioMetrics],
                            agent_metrics: Optional[AgentBehaviorMetrics],
                            risk_metrics: Optional[RiskControlMetrics]):
        """
        è®°å½•å¢å¼ºæŒ‡æ ‡æ—¥å¿—
        
        Args:
            episode: episodeç¼–å·
            portfolio_metrics: æŠ•èµ„ç»„åˆæŒ‡æ ‡
            agent_metrics: æ™ºèƒ½ä½“è¡Œä¸ºæŒ‡æ ‡
            risk_metrics: é£é™©æ§åˆ¶æŒ‡æ ‡
        """
        log_lines = [f"=== Episode {episode} å¢å¼ºæŒ‡æ ‡æŠ¥å‘Š ==="]
        
        # æŠ•èµ„ç»„åˆæŒ‡æ ‡
        if portfolio_metrics:
            log_lines.append("ğŸ“Š æŠ•èµ„ç»„åˆä¸å¸‚åœºè¡¨ç°å¯¹æ¯”æŒ‡æ ‡:")
            log_lines.append(f"  â€¢ å¤æ™®æ¯”ç‡ (Sharpe Ratio): {portfolio_metrics.sharpe_ratio:.4f}")
            log_lines.append(f"  â€¢ æœ€å¤§å›æ’¤ (Max Drawdown): {portfolio_metrics.max_drawdown:.4f}")
            log_lines.append(f"  â€¢ Alpha (ç›¸å¯¹åŸºå‡†è¶…é¢æ”¶ç›Š): {portfolio_metrics.alpha:.4f}")
            log_lines.append(f"  â€¢ Beta (ç³»ç»Ÿæ€§é£é™©): {portfolio_metrics.beta:.4f}")
            log_lines.append(f"  â€¢ å¹´åŒ–æ”¶ç›Šç‡ (Annualized Return): {portfolio_metrics.annualized_return:.4f}")
        else:
            log_lines.append("ğŸ“Š æŠ•èµ„ç»„åˆæŒ‡æ ‡: æ•°æ®ä¸è¶³ï¼Œè·³è¿‡è®¡ç®—")
        
        # æ™ºèƒ½ä½“è¡Œä¸ºæŒ‡æ ‡
        if agent_metrics:
            log_lines.append("ğŸ¤– æ™ºèƒ½ä½“è¡Œä¸ºåˆ†ææŒ‡æ ‡:")
            log_lines.append(f"  â€¢ å¹³å‡ç†µå€¼ (Mean Entropy): {agent_metrics.mean_entropy:.4f}")
            log_lines.append(f"  â€¢ ç†µå€¼è¶‹åŠ¿ (Entropy Trend): {agent_metrics.entropy_trend:.4f}")
            log_lines.append(f"  â€¢ å¹³å‡æŒä»“é›†ä¸­åº¦ (Position Concentration): {agent_metrics.mean_position_concentration:.4f}")
            log_lines.append(f"  â€¢ æ¢æ‰‹ç‡ (Turnover Rate): {agent_metrics.turnover_rate:.4f}")
        else:
            log_lines.append("ğŸ¤– æ™ºèƒ½ä½“è¡Œä¸ºæŒ‡æ ‡: æ•°æ®ä¸è¶³ï¼Œè·³è¿‡è®¡ç®—")
        
        # é£é™©æ§åˆ¶æŒ‡æ ‡
        if risk_metrics:
            log_lines.append("ğŸ›¡ï¸ é£é™©ä¸å›æ’¤æ§åˆ¶æŒ‡æ ‡:")
            log_lines.append(f"  â€¢ å¹³å‡é£é™©é¢„ç®—ä½¿ç”¨ç‡: {risk_metrics.avg_risk_budget_utilization:.4f}")
            log_lines.append(f"  â€¢ é£é™©é¢„ç®—æ•ˆç‡: {risk_metrics.risk_budget_efficiency:.4f}")
            log_lines.append(f"  â€¢ æ§åˆ¶ä¿¡å·é¢‘ç‡: {risk_metrics.control_signal_frequency:.4f}")
            log_lines.append(f"  â€¢ å¸‚åœºçŠ¶æ€ç¨³å®šæ€§: {risk_metrics.market_regime_stability:.4f}")
        else:
            log_lines.append("ğŸ›¡ï¸ é£é™©æ§åˆ¶æŒ‡æ ‡: å›æ’¤æ§åˆ¶å™¨æœªå¯ç”¨æˆ–æ•°æ®ä¸è¶³")
        
        log_lines.append("=" * 50)
        
        # è¾“å‡ºæ—¥å¿—
        for line in log_lines:
            logger.info(line)
    
    def _update_metrics_histories(self, episode_info: Dict[str, Any], update_info: Dict[str, Any]):
        """
        æ›´æ–°æŒ‡æ ‡å†å²æ•°æ®
        
        Args:
            episode_info: episodeä¿¡æ¯
            update_info: æ™ºèƒ½ä½“æ›´æ–°ä¿¡æ¯
        """
        # æ›´æ–°æŠ•èµ„ç»„åˆä»·å€¼å†å²
        if 'portfolio_value' in episode_info:
            self.portfolio_values_history.append(episode_info['portfolio_value'])
        
        # æ›´æ–°åŸºå‡†ä»·å€¼å†å²ï¼ˆå¦‚æœæœ‰ï¼‰
        if 'benchmark_value' in episode_info:
            self.benchmark_values_history.append(episode_info['benchmark_value'])
        elif len(self.portfolio_values_history) > len(self.benchmark_values_history):
            # å¦‚æœæ²¡æœ‰åŸºå‡†æ•°æ®ï¼Œä½¿ç”¨é»˜è®¤å¢é•¿ç‡
            if len(self.benchmark_values_history) == 0:
                self.benchmark_values_history.append(self.config.initial_cash)
            else:
                # å‡è®¾åŸºå‡†å¹´åŒ–æ”¶ç›Šç‡ä¸º8%
                daily_return = 0.08 / 252
                last_value = self.benchmark_values_history[-1]
                self.benchmark_values_history.append(last_value * (1 + daily_return))
        
        # æ›´æ–°æ—¥æœŸå†å²
        self.dates_history.append(datetime.now())
        
        # æ›´æ–°æ™ºèƒ½ä½“è¡Œä¸ºæ•°æ®
        if 'policy_entropy' in update_info:
            self.entropy_history.append(update_info['policy_entropy'])
        
        if 'positions' in episode_info:
            positions = episode_info['positions']
            if isinstance(positions, np.ndarray):
                self.position_weights_history.append(positions.copy())
    
    def _log_episode_stats(self, episode: int, reward: float, length: int,
                          update_info: Dict[str, float]):
        """
        è®°å½•episodeç»Ÿè®¡ä¿¡æ¯ï¼ˆå¢å¼ºç‰ˆï¼‰
        
        Args:
            episode: episodeç¼–å·
            reward: episodeå¥–åŠ±
            length: episodeé•¿åº¦
            update_info: æ›´æ–°ä¿¡æ¯
        """
        # è°ƒç”¨çˆ¶ç±»æ–¹æ³•è®°å½•åŸºç¡€ç»Ÿè®¡
        super()._log_episode_stats(episode, reward, length, update_info)
        
        # æ›´æ–°æŒ‡æ ‡å†å²æ•°æ®
        episode_info = {
            'portfolio_value': getattr(self.environment, 'total_value', self.config.initial_cash),
            'positions': getattr(self.environment, 'current_positions', np.zeros(5))
        }
        
        self._update_metrics_histories(episode_info, update_info)
    
    def get_enhanced_training_stats(self) -> Dict[str, Any]:
        """
        è·å–å¢å¼ºè®­ç»ƒç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            å¢å¼ºè®­ç»ƒç»Ÿè®¡ä¿¡æ¯
        """
        # è·å–åŸºç¡€ç»Ÿè®¡
        base_stats = self.get_training_stats() if hasattr(super(), 'get_training_stats') else {}
        
        # æ·»åŠ å¢å¼ºç»Ÿè®¡
        enhanced_stats = {
            'portfolio_values_count': len(self.portfolio_values_history),
            'entropy_values_count': len(self.entropy_history),
            'position_weights_count': len(self.position_weights_history),
            'latest_portfolio_value': self.portfolio_values_history[-1] if self.portfolio_values_history else 0,
            'latest_entropy': self.entropy_history[-1] if self.entropy_history else 0,
        }
        
        # å¦‚æœæœ‰è¶³å¤Ÿæ•°æ®ï¼Œè®¡ç®—æœ€æ–°æŒ‡æ ‡
        if len(self.portfolio_values_history) > 1:
            try:
                latest_portfolio_metrics = self._calculate_portfolio_metrics()
                if latest_portfolio_metrics:
                    enhanced_stats.update({
                        'latest_sharpe_ratio': latest_portfolio_metrics.sharpe_ratio,
                        'latest_max_drawdown': latest_portfolio_metrics.max_drawdown,
                        'latest_alpha': latest_portfolio_metrics.alpha,
                        'latest_beta': latest_portfolio_metrics.beta,
                        'latest_annualized_return': latest_portfolio_metrics.annualized_return
                    })
            except Exception as e:
                logger.debug(f"è®¡ç®—æœ€æ–°æŠ•èµ„ç»„åˆæŒ‡æ ‡å¤±è´¥: {e}")
        
        if len(self.entropy_history) > 0:
            try:
                latest_agent_metrics = self._calculate_agent_behavior_metrics()
                if latest_agent_metrics:
                    enhanced_stats.update({
                        'latest_mean_entropy': latest_agent_metrics.mean_entropy,
                        'latest_entropy_trend': latest_agent_metrics.entropy_trend,
                        'latest_position_concentration': latest_agent_metrics.mean_position_concentration,
                        'latest_turnover_rate': latest_agent_metrics.turnover_rate
                    })
            except Exception as e:
                logger.debug(f"è®¡ç®—æœ€æ–°æ™ºèƒ½ä½“è¡Œä¸ºæŒ‡æ ‡å¤±è´¥: {e}")
        
        # åˆå¹¶ç»Ÿè®¡ä¿¡æ¯
        base_stats.update(enhanced_stats)
        return base_stats
    
    def reset_enhanced_histories(self):
        """é‡ç½®å¢å¼ºå†å²æ•°æ®"""
        self.portfolio_values_history.clear()
        self.benchmark_values_history.clear()
        self.dates_history.clear()
        self.entropy_history.clear()
        self.position_weights_history.clear()
        self.risk_budget_history.clear()
        self.risk_usage_history.clear()
        self.control_signals_history.clear()
        self.market_regime_history.clear()
        
        logger.info("å¢å¼ºå†å²æ•°æ®å·²é‡ç½®")